[{
  "history_id" : "y3f70o9r5vb",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\nmodule load python                          # load the default python version\n                          # execute your python script\npython cmaq/text_to_csv_2021.py",
  "history_output" : "/bin/bash: ./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: No such file or directory\nrm: cannot remove './geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh': No such file or directory\n",
  "history_begin_time" : 1645747521119,
  "history_end_time" : 1645747530861,
  "history_notes" : null,
  "history_process" : "ol8aa4",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "05r9cmiayua",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\nmodule load python                          # load the default python version\n                          # execute your python script\npython cmaq/text_to_csv_2020.py",
  "history_output" : "bash: ./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: /bin/bash: bad interpreter: Text file busy\n",
  "history_begin_time" : 1645747520868,
  "history_end_time" : 1645747530851,
  "history_notes" : null,
  "history_process" : "r41da2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "1ncog2s57rz",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/pre_processing.py",
  "history_output" : "running_preprocess\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/pre_processing.py\", line 63, in <module>\n    df1 = pd.read_csv('/home/mislam25/cmaq/2020.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/2020.csv'\n",
  "history_begin_time" : 1645747531473,
  "history_end_time" : 1645747550601,
  "history_notes" : null,
  "history_process" : "ftn2kp",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "rl8lw1u450d",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/exploratory_data_analysis.py",
  "history_output" : "running_preprocess\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/exploratory_data_analysis.py\", line 34, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1645747551060,
  "history_end_time" : 1645747597107,
  "history_notes" : null,
  "history_process" : "wfd3c5",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "ilng8bxe3hy",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_xgboost.py",
  "history_output" : "running xgboost_training\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/training_xgboost.py\", line 12, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: line 20: st.py: command not found\n",
  "history_begin_time" : 1645747597430,
  "history_end_time" : 1645747654083,
  "history_notes" : null,
  "history_process" : "j7uo3v",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "495v8dgijmp",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_xgboost.py",
  "history_output" : "running prediction xgboost\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_xgboost.py\", line 8, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1645747654877,
  "history_end_time" : 1645747673290,
  "history_notes" : null,
  "history_process" : "zt10an",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "q2p1ajf1e1s",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_random_forest.py",
  "history_output" : "/bin/bash: ./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: No such file or directory\nrm: cannot remove './geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh': No such file or directory\n",
  "history_begin_time" : 1645747598004,
  "history_end_time" : 1645747606414,
  "history_notes" : null,
  "history_process" : "48iyth",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "3x1k4bu9zrd",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_random_forest.py",
  "history_output" : "running predicion autokeras\n2022-02-24 19:07:08.908885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/libs/hwloc/2.1.0/lib:/opt/ohpc/pub/mpi/libfabric/1.10.1/lib:/opt/ohpc/pub/mpi/ucx-ohpc/1.8.0/lib:/opt/ohpc/pub/mpi/openmpi4-gnu9/4.0.4/lib:/opt/ohpc/pub/compiler/gcc/9.3.0/lib64:/lib64\n2022-02-24 19:07:08.908907: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_autokeras.py\", line 20, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: line 20: .py: command not found\nrm: cannot remove './geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh': No such file or directory\n",
  "history_begin_time" : 1645747607401,
  "history_end_time" : 1645747797155,
  "history_notes" : null,
  "history_process" : "bembwt",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "o9li9ur1y2p",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_autokeras.py",
  "history_output" : "bash: ./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: /bin/bash: bad interpreter: Text file busy\n",
  "history_begin_time" : 1645747598005,
  "history_end_time" : 1645747606376,
  "history_notes" : null,
  "history_process" : "l0t844",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "jzbi27fzt34",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_autokeras.py",
  "history_output" : "running predicion autokeras\n2022-02-24 19:07:08.909104: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/libs/hwloc/2.1.0/lib:/opt/ohpc/pub/mpi/libfabric/1.10.1/lib:/opt/ohpc/pub/mpi/ucx-ohpc/1.8.0/lib:/opt/ohpc/pub/mpi/openmpi4-gnu9/4.0.4/lib:/opt/ohpc/pub/compiler/gcc/9.3.0/lib64:/lib64\n2022-02-24 19:07:08.909123: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_autokeras.py\", line 20, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n./geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh: line 20: .py: command not found\nrm: cannot remove './geoweaver-WB76vGubo9xIb3GX8j8sre3UkM.sh': No such file or directory\n",
  "history_begin_time" : 1645747607245,
  "history_end_time" : 1645747797126,
  "history_notes" : null,
  "history_process" : "zmy3vb",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "s3jt73bp8do",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/model_comparison.py",
  "history_output" : "[]\n",
  "history_begin_time" : 1645747798146,
  "history_end_time" : 1645747845681,
  "history_notes" : null,
  "history_process" : "z1t6b2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
}]
