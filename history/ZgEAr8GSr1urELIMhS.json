[{
  "history_id" : "ik08bdcesxw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213521,
  "history_end_time" : 1668158291239,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "k1901zlg90v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213539,
  "history_end_time" : 1668158291244,
  "history_notes" : null,
  "history_process" : "xpdg66",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "aeh5u7a13oj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213548,
  "history_end_time" : 1668158291249,
  "history_notes" : null,
  "history_process" : "xlayd5",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "wuojmeuy9cw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213555,
  "history_end_time" : 1668158291250,
  "history_notes" : null,
  "history_process" : "argv3i",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "tfmnphgmr1p",
  "history_input" : "# use the trained model to predict on the testing data and save the results to prediction_rf.csv\n\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\nimport glob, os\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom cmaq_ai_utils import *\n\ncreate_and_clean_folder(f\"{cmaq_folder}/prediction_files/\")\n\n# importing data\n# final=pd.read_csv(f\"{cmaq_folder}/testing_input_hourly/testing.csv\")\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\n\n# load the model from disk\n# filename = f'{cmaq_folder}/models/rf_pycaret.sav'\n\nfilename = f'{model_folder}/rf_pycaret_o3_one_year_good.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\n\nfor testing_df in df_from_each_hourly_file:\n  #print(testing_df['YYYYMMDDHH'].values[0])\n  file_dateTime = testing_df['YYYYMMDDHH'].values[0]\n  #X = testing_df.drop(['YYYYMMDDHH','Latitude','Longitude'],axis=1)\n  testing_df['time_of_day'] = (testing_df['hours'] % 24 + 4) // 4\n\n  # Make coords even more coarse by rounding to closest multiple of 5 \n  # (e.g., 40, 45, 85, 55)\n  #testing_df['Latitude_ExtraCoarse'] = 0.1 * round(testing_df['Latitude']/0.1)\n  #testing_df['Longitude_ExtraCoarse'] = 0.1 * round(testing_df['Longitude']/0.1)\n  X = testing_df.drop(['YYYYMMDDHH','Latitude','Longitude', 'CO(moles/s)'],axis=1)\n  \n  #print(X.columns)\n\n# # making prediction\n  pred = loaded_model.predict(X)\n\n# adding prediction values to test dataset\n  #testing_df['prediction'] = testing_df['CMAQ12KM_O3(ppb)'].tolist()\n  testing_df['prediction'] = pred\n\n  testing_df = testing_df[['Latitude', 'Longitude','YYYYMMDDHH','prediction']]\n# saving the dataset into local drive\n  print(f'Saving: {cmaq_folder}/prediction_files/prediction_rf_{file_dateTime}.csv')\n  testing_df.to_csv(f'{cmaq_folder}/prediction_files/prediction_rf_{file_dateTime}.csv',index=False)",
  "history_output" : "",
  "history_begin_time" : 1668158275438,
  "history_end_time" : 1668158661749,
  "history_notes" : null,
  "history_process" : "l8vlic",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "itys0i4bk1v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213633,
  "history_end_time" : 1668158292291,
  "history_notes" : null,
  "history_process" : "wny2dz",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "0twsuact4hv",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1668158292293,
  "history_notes" : null,
  "history_process" : "3asyzj",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "94ppm29ugq2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213647,
  "history_end_time" : 1668158292300,
  "history_notes" : null,
  "history_process" : "9xdvh6",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "q5t6xn0e2x4",
  "history_input" : "# get hourly CMAQ data into csv for prediction\n\nfrom cmaq_ai_utils import *\n\n\n#edate = datetime.today()\n#sdate = edate - timedelta(days=1)\ntoday = datetime.today()\nedate = today\nsdate = today - timedelta(days=7)\n\n#sdate = date(2022, 8, 6)   # start date\n#edate = date(2022, 8, 8)   # end date\ndays = get_days_list_for_prediction(sdate, edate)\n\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntest_folder = f\"{cmaq_folder}/testing_input_hourly/\"\ncreate_and_clean_folder(test_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  cmaq_file = \"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\"\n  if not os.path.exists(cmaq_file):\n    print(f\"CMAQ file {cmaq_file} doesn't exist\")\n    continue\n  \n  target_cdf_file = f'{cmaq_folder}/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+current_day+'_ML_extracted.nc'\n    \n  if os.path.exists(target_cdf_file):\n    print(f\"{target_cdf_file} already exists\")\n    continue\n  \n  df_cmaq = xr.open_dataset(cmaq_file)\n  \n  # read mcip results \n  mcip_file = \"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\"\n  df_mcip = xr.open_dataset(mcip_file)\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value<12:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    #print(\"df_cmaq.variables['O3'] shape: \", df_cmaq.variables['O3'].shape)\n    #print(\"df_cmaq.variables['O3'][:] shape: \", df_cmaq.variables['O3'][:].shape)\n    #print(\"df_cmaq.variables['O3'][:].values[k, 0].shape\", df_cmaq.variables['O3'][:].values[k, 0].shape)\n    # CMAQ data\n    # O3 variable\n    o3=df_cmaq.variables['O3'][:].values[k, 0]\n    cmaq_O3=list(np.ravel(o3).transpose())\n    #print(\"o3 shape: \", o3.shape)\n    #print(\"cmaq_O3 shape: \", np.ravel(o3).transpose().shape)\n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k, 0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k, 0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k, 0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k, 0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k, 0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k, 0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k, 0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k, 0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k, 0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k, 0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k, 0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    #print(\"lat shape\", lat.shape)\n    lat_flt=np.ravel(lat)\n    LAT=lat_flt #np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=lon_flt #np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    print(f'Saving file: test_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(f'{test_folder}/test_data_{day}_{turn_2_digits(real_hour_value)}.csv',index=False)\n\nprint('Done with preparing testing data!')",
  "history_output" : "",
  "history_begin_time" : 1668158214607,
  "history_end_time" : 1668158292301,
  "history_notes" : null,
  "history_process" : "ex3vh9",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "ishdom26iil",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668158230106,
  "history_end_time" : 1668158292303,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "gsucj1bwaql",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1668158292305,
  "history_notes" : null,
  "history_process" : "iicy7w",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "okdddvtpl18",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1668158292309,
  "history_notes" : null,
  "history_process" : "fsk7f2",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "aarwfuz1ozd",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1668158292314,
  "history_notes" : null,
  "history_process" : "is1w3m",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "g8bai9m0u34",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213673,
  "history_end_time" : 1668158292321,
  "history_notes" : null,
  "history_process" : "h76ld0",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "jg57npcaocl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213677,
  "history_end_time" : 1668158292322,
  "history_notes" : null,
  "history_process" : "s6hbic",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "p4tzg2mymjk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213680,
  "history_end_time" : 1668158292323,
  "history_notes" : null,
  "history_process" : "pvzabv",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "uaat23x202i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668158213695,
  "history_end_time" : 1668158292323,
  "history_notes" : null,
  "history_process" : "8i9ptn",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
}]
