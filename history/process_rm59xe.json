[{
  "history_id" : "rjypzwgzsxi",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\ntrainedModel = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\nlistOfModels = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\n\npickle.dump(ensemble, open(trainedModel, 'wb'))\npickle.dump(models, open(listOfModels, 'wb'))\nprint(f\"Model is trained and saved to {trainedModel}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\nModel is trained and saved to /Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav\n",
  "history_begin_time" : 1667526090347,
  "history_end_time" : 1667526094009,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r7whg68wdxd",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\ntrainedModel = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\nlistOfModels = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\n\npickle.dump(ensemble, open(trainedModel, 'wb'))\npickle.dump(models, open(listOfModels, 'wb'))\nprint(f\"Model is trained and saved to {trainedModel}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\nTraceback (most recent call last):\n  File \"train_xgboost.py\", line 31, in <module>\n    ensemble.fit(X, y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_voting.py\", line 459, in fit\n    return super().fit(X, y, sample_weight)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_voting.py\", line 73, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py\", line 40, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 772, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 312, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 256, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 236, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:AirNow_CO, AirNow_NO2, tropomi_O3.ppbV, CO_AVG, NO_AVG, NO2_AVG, SO2_AVG, CH2O_AVG, PM10_AVG, PM25_AVG, PM25_SO4_AVG, PM25_NO3_AVG, PM25_NH4_AVG, PM25_OC_AVG, PM25_EC_AVG\n",
  "history_begin_time" : 1667525583890,
  "history_end_time" : 1667525587282,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "00EwuZTJryuS",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\ntrainedModel = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\nlistOfModels = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\n\npickle.dump(ensemble, open(trainedModel, 'wb'))\npickle.dump(models, open(listOfModels, 'wb'))\nprint(f\"Model is trained and saved to {trainedModel}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\nModel is trained and saved to /Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav\n",
  "history_begin_time" : 1667525300106,
  "history_end_time" : 1667525303103,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ApQEOc6ygSRt",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\ntrainedModel = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\nlistOfModels = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\n\npickle.dump(ensemble, open(trainedModel, 'wb'))\npickle.dump(models, open(listOfModels, 'wb'))\nprint(f\"Model is trained and saved to {filename}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\nTraceback (most recent call last):\n  File \"train_xgboost.py\", line 40, in <module>\n    print(f\"Model is trained and saved to {filename}\")\nNameError: name 'filename' is not defined\n",
  "history_begin_time" : 1667525287948,
  "history_end_time" : 1667525290986,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bQyTpttgp8Lc",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\nfilename = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(ensemble, open(filename, 'wb'))\nprint(f\"Model is trained and saved to {filename}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\nModel is trained and saved to /Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav\n",
  "history_begin_time" : 1667524533018,
  "history_end_time" : 1667524535765,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "awRRM5rYL7k5",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\nfilename = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(rf, open(filename, 'wb'))\nprint(f\"Model is trained and saved to {filename}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\nTraceback (most recent call last):\n  File \"train_xgboost.py\", line 37, in <module>\n    pickle.dump(rf, open(filename, 'wb'))\nNameError: name 'rf' is not defined\n",
  "history_begin_time" : 1667524519624,
  "history_end_time" : 1667524523354,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "9hgupw5u5ns",
  "history_input" : "import pandas as pd\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Features to keep as predictors\nX = final.drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# The target feature to predict.\ny = final['AirNow_O3']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\n# make a prediction with a voting ensemble\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X_train, y_train)\n\n\nimport math\nimport sklearn\n\npred = ensemble.predict(X_test)\n\nmse = sklearn.metrics.mean_squared_error(pred, y_test)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\n\n\n\n# Get the equivalent rows of our test set from the main data frame for plotting\ndataset = final.iloc[21:].drop_duplicates(\"Date\")\n# Add the prediction result to the new dataframe\ndataset['prediction'] = pred.tolist()\n    \nimport matplotlib.pyplot as plt\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, pred.tolist(), color='tab:orange', label='prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='observed')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O₃')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left');\n\nfig.savefig('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/pred.png')",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n0.10678740565102392 0.32678342315825004\n",
  "history_begin_time" : 1667311157088,
  "history_end_time" : 1667311162432,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "DIJKiakXk0Gm",
  "history_input" : "import pandas as pd\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Features to keep as predictors\nX = final.drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# The target feature to predict.\ny = final['AirNow_O3']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\n# make a prediction with a voting ensemble\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X_train, y_train)\n\n\nimport math\nimport sklearn\n\npred = ensemble.predict(X_test)\n\nmse = sklearn.metrics.mean_squared_error(pred, y_test)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\n\n\n\n# Get the equivalent rows of our test set from the main data frame for plotting\ndataset = final.iloc[21:].drop_duplicates(\"Date\")\n# Add the prediction result to the new dataframe\ndataset['prediction'] = pred.tolist()\n    \nimport matplotlib.pyplot as plt\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, pred.tolist(), color='tab:orange', label='prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='observed')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O₃')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left');\n\nfig.savefig('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/pred.png')",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n0.10678740565102392 0.32678342315825004\n",
  "history_begin_time" : 1667311070562,
  "history_end_time" : 1667311076209,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "qzyhmxczc3p",
  "history_input" : "import pandas as pd\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Features to keep as predictors\nX = final.drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# The target feature to predict.\ny = final['AirNow_O3']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\n# make a prediction with a voting ensemble\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X_train, y_train)\n\n\nimport math\nimport sklearn\n\npred = ensemble.predict(X_test)\n\nmse = sklearn.metrics.mean_squared_error(pred, y_test)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\n\n\n\n# Get the equivalent rows of our test set from the main data frame for plotting\ndataset = final.iloc[21:].drop_duplicates(\"Date\")\n# Add the prediction result to the new dataframe\ndataset['prediction'] = pred.tolist()\n    \nimport matplotlib.pyplot as plt\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, pred.tolist(), color='tab:orange', label='prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='observed')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O₃')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left');\n",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\n/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n0.10678740565102392 0.32678342315825004\n",
  "history_begin_time" : 1667310976647,
  "history_end_time" : 1667310981524,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "eocymptyt58",
  "history_input" : "import pandas as pd\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Features to keep as predictors\nX = final.drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# The target feature to predict.\ny = final['AirNOW_O3']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\n# make a prediction with a voting ensemble\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X_train, y_train)\n\n\nimport math\nimport sklearn\n\npred = ensemble.predict(X_test)\n\nmse = sklearn.metrics.mean_squared_error(pred, y_test)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\n\n\n\n# Get the equivalent rows of our test set from the main data frame for plotting\ndataset = final.iloc[21:].drop_duplicates(\"Date\")\n# Add the prediction result to the new dataframe\ndataset['prediction'] = pred.tolist()\n    \nimport matplotlib.pyplot as plt\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, pred.tolist(), color='tab:orange', label='prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='observed')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O₃')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left');\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3800, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'AirNOW_O3'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"ch15_train_xgboost.py\", line 9, in <module>\n    y = final['AirNOW_O3']\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3805, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n    raise KeyError(key) from err\nKeyError: 'AirNOW_O3'\n",
  "history_begin_time" : 1667310903423,
  "history_end_time" : 1667310904701,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "30ym6zrdfb0",
  "history_input" : "import pandas as pd\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Features to keep as predictors\nX = final.drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# The target feature to predict.\ny = final['AirNOW_O3']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\n# make a prediction with a voting ensemble\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X_train, y_train)\n\n\nimport math\nimport sklearn\n\npred = ensemble.predict(X_test)\n\nmse = sklearn.metrics.mean_squared_error(pred, y_test)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\n\n\n\n# Get the equivalent rows of our test set from the main data frame for plotting\ndataset = final.iloc[21:].drop_duplicates(\"Date\")\n# Add the prediction result to the new dataframe\ndataset['prediction'] = pred.tolist()\n    \nimport matplotlib.pyplot as plt\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, pred.tolist(), color='tab:orange', label='prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='observed')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O₃')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left');\n",
  "history_output" : "Traceback (most recent call last):\n  File \"ch15_train_xgboost.py\", line 3, in <module>\n    final = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 317, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1729, in _make_engine\n    self.handles = get_handle(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 857, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv'\n",
  "history_begin_time" : 1667310731345,
  "history_end_time" : 1667310732141,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "agbd3k3ecpr",
  "history_input" : "import pandas as pd\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Features to keep as predictors\nX = final.drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# The target feature to predict.\ny = final['AirNOW_O3']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n\n# make a prediction with a voting ensemble\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X_train, y_train)\n\n\nimport math\nimport sklearn\n\npred = ensemble.predict(X_test)\n\nmse = sklearn.metrics.mean_squared_error(pred, y_test)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\n\n\n\n# Get the equivalent rows of our test set from the main data frame for plotting\ndataset = final.iloc[21:].drop_duplicates(\"Date\")\n# Add the prediction result to the new dataframe\ndataset['prediction'] = pred.tolist()\n    \nimport matplotlib.pyplot as plt\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, pred.tolist(), color='tab:orange', label='prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='observed')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O₃')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left');\n",
  "history_output" : "Traceback (most recent call last):\n  File \"ch15_train_xgboost.py\", line 3, in <module>\n    final = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 317, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1729, in _make_engine\n    self.handles = get_handle(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 857, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv'\n",
  "history_begin_time" : 1667310663165,
  "history_end_time" : 1667310664289,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Failed"
},]
