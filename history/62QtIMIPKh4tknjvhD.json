[{
  "history_id" : "if0dvdz9r6r",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n\npython cmaq/pre_processing.py\nexit",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/ahn8sM00jMKFM9d37eDjwUwRLW/cmaq/pre_processing.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646116036443,
  "history_end_time" : 1646116072238,
  "history_notes" : null,
  "history_process" : "ftn2kp",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "kfy6z0v53ar",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n\npython cmaq/exploratory_data_analysis.py\nexit",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/ahn8sM00jMKFM9d37eDjwUwRLW/cmaq/exploratory_data_analysis.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646116072736,
  "history_end_time" : 1646116107255,
  "history_notes" : null,
  "history_process" : "wfd3c5",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "bofy9wqmc4z",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_xgboost.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116107526,
  "history_end_time" : 1646116107959,
  "history_notes" : null,
  "history_process" : "j7uo3v",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "o9c5ouc4x6a",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_xgboost.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116108277,
  "history_end_time" : 1646116108710,
  "history_notes" : null,
  "history_process" : "zt10an",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "au71qon0q0q",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_random_forest.py",
  "history_output" : "Too many logins for 'mislam25'.\nLast login: Tue Mar  1 01:28:29 2022 from 71.191.159.128\n\n",
  "history_begin_time" : 1646116107273,
  "history_end_time" : 1646116122117,
  "history_notes" : null,
  "history_process" : "48iyth",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "5t6p4rttcmv",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_random_forest.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116122495,
  "history_end_time" : 1646116122932,
  "history_notes" : null,
  "history_process" : "bembwt",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "zgfpcq82zw5",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_autokeras.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116107635,
  "history_end_time" : 1646116107991,
  "history_notes" : null,
  "history_process" : "l0t844",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "6ly3tmpd2jd",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_autokeras.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116108984,
  "history_end_time" : 1646116109388,
  "history_notes" : null,
  "history_process" : "zmy3vb",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "j9yszxug2w3",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/model_comparison.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116123832,
  "history_end_time" : 1646116124188,
  "history_notes" : null,
  "history_process" : "z1t6b2",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "na1tls85iuq",
  "history_input" : null,
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646116124961,
  "history_end_time" : 1646116125322,
  "history_notes" : null,
  "history_process" : "uzx599",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
}]
