[{
  "history_id" : "iurjfdaslgl",
  "history_input" : "# NASA-GEOWEAVER: Environment setting\n\nimport os\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Required packages to run this process.\nrequired = {'pandas','pathlib','sklearn','numpy','keras','tensorflow','tensorflow-gpu','autokeras','kaleido','glob2'}\ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\nif missing:\n    print(\"Packages missing and will be installed: \", missing)\n    python = sys.executable\n    subprocess.check_call(\n        [python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n\n################################\n#  END OF PACKAGES Installation  #\n\n\n# Creating directoris \nfrom pathlib import Path\nhome = str(Path.home())\nfolders = ['cmaq/exploratory_analysis', 'cmaq/prediction_maps', 'cmaq/prediction_files','cmaq/models']\nfor folder in folders:\n  paths=Path(home+'/'+folder)\n  paths.mkdir(parents=True,exist_ok=True)\n  \n  ###############################\n  # END OF DIRECTORY CREATION #",
  "history_output" : "Packages missing and will be installed:  {'sklearn', 'pathlib'}\n  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n  \n  \u001B[31m×\u001B[0m \u001B[32mpython setup.py egg_info\u001B[0m did not run successfully.\n  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n  \u001B[31m╰─>\u001B[0m \u001B[31m[20 lines of output]\u001B[0m\n  \u001B[31m   \u001B[0m Traceback (most recent call last):\n  \u001B[31m   \u001B[0m   File \"<string>\", line 2, in <module>\n  \u001B[31m   \u001B[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001B[31m   \u001B[0m   File \"/tmp/pip-install-kf758sef/pathlib_9cca3e8318af444aab4c80c27784d344/setup.py\", line 6, in <module>\n  \u001B[31m   \u001B[0m     setup(\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 109, in setup\n  \u001B[31m   \u001B[0m     _setup_distribution = dist = klass(attrs)\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/dist.py\", line 456, in __init__\n  \u001B[31m   \u001B[0m     for ep in metadata.entry_points(group='distutils.setup_keywords'):\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 999, in entry_points\n  \u001B[31m   \u001B[0m     return SelectableGroups.load(eps).select(**params)\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 449, in load\n  \u001B[31m   \u001B[0m     ordered = sorted(eps, key=by_group)\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 997, in <genexpr>\n  \u001B[31m   \u001B[0m     dist.entry_points for dist in unique(distributions())\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 609, in entry_points\n  \u001B[31m   \u001B[0m     return EntryPoints._from_text_for(self.read_text('entry_points.txt'), self)\n  \u001B[31m   \u001B[0m   File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 917, in read_text\n  \u001B[31m   \u001B[0m     return self._path.joinpath(filename).read_text(encoding='utf-8')\n  \u001B[31m   \u001B[0m AttributeError: 'PosixPath' object has no attribute 'read_text'\n  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\n  \n  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\n\n\u001B[31m×\u001B[0m Encountered error while generating package metadata.\n\u001B[31m╰─>\u001B[0m See above for output.\n\n\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\n\u001B[1;36mhint\u001B[0m: See above for details.\nTraceback (most recent call last):\n  File \"environment_setting.py\", line 16, in <module>\n    subprocess.check_call(\n  File \"/opt/sw/spack/apps/linux-centos8-x86_64/gcc-9.3.0/python-3.8.6-ff/lib/python3.8/subprocess.py\", line 364, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['/home/aalnaim/CMAQAI/bin/python', '-m', 'pip', 'install', 'sklearn', 'pathlib']' returned non-zero exit status 1.\n",
  "history_begin_time" : 1646615004948,
  "history_end_time" : 1646615056002,
  "history_notes" : null,
  "history_process" : "9xdvh6",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "1wfbzezk8ri",
  "history_input" : "# NASA GEOWEAVER\n# CMAQ-AI Model: Poocessing the data - shifting columns of NO2\n\n# Import libraries\nimport pandas as pd\nimport datetime\nfrom pathlib import Path\nfrom time import sleep\nprint(\"preprocess\")\n# home directory\nhome = str(Path.home())\n\n# defining function for shifting data\nmonth_i=[1,2,3,4,5,6,7,8,9,10,11,12]\ndef shift(file):\n    station=file['Station.ID'].unique()\n    file['date']=pd.to_datetime(file[[\"year\", \"month\", \"day\",\"hours\"]]) # creating date\n    file['dayofyear'] = pd.to_datetime(file['date']).dt.dayofyear # converting monthly days to yearly dasy\n    dfs = dict(tuple(file.groupby('Station.ID'))) # grouping the data by station\n#    print(dfs)\n    list_final=[]\n    for site in station:\n        list1=dfs[site]  # selecting dataset for each station\n        o3_max=list1.loc[list1.groupby(\"dayofyear\")[\"AirNOW_O3\"].idxmax()] # daily max values\n        o3_month=pd.DataFrame(o3_max.groupby('month',as_index=False)['hours'].mean()) # monthly average hour\n        no2_max=list1.loc[list1.groupby(\"dayofyear\")[\"CMAQ12KM_NO2\"].idxmax()] # daily amx values\n        no2_month=pd.DataFrame(no2_max.groupby('month',as_index=False)['hours'].mean()) # montly average hour\n        merge_hour=pd.concat([o3_month,no2_month],axis = 1) # merging two table\n        merge_hour.columns = ['month1','hours1', 'month2','hours2'] # renaming column name\n        merge_hour['hours_diff']=merge_hour['hours1']-merge_hour['hours2']\n        merge_hour.hours_diff = merge_hour.hours_diff.astype(int) # converting hours_diff to int\n        months = dict(tuple(list1.groupby('month')))   # grouping the data by month\n        diff=merge_hour['hours_diff'] # extracting hours difference field\n        mon=merge_hour['month1'] # extracting month field\n\n        for (m,n) in zip(mon,diff):\n            list2= months[m] # selecting dataset for each month and for each station\n            list3=list2.loc[list2['month'] == m] # subsetting dataset for each month\n            list3['CMAQ12KM_NO2_new'] = list3['CMAQ12KM_NO2'].shift(n) # shifting rows for each month\n            list_final.append(list3)\n    return list_final\n\n  \n# Importing and merging 2020 and 2021 dataset\ndf1 = pd.read_csv(home+'/cmaq/daily_cmaq.csv')\n#df2 = pd.read_csv(home+'/cmaq/2021.csv')\n\n#merging two dataframe vertically\n#mrg=df1.append(df2, ignore_index=True)\n# Changing columns name with index number\nmapping = {df1.columns[0]: 'Station.ID', df1.columns[4]: 'AirNOW_O3',df1.columns[5]: 'AirNOW_NO2',df1.columns[6]: 'AirNOW_CO',df1.columns[8]: 'CMAQ12KM_NO2'}\nmrg_rename = df1.rename(columns=mapping)\n\n# dropping unnecessary columns\nmrg_rename.drop(mrg_rename.columns[[5,6]], axis = 1, inplace = True)\n\n# ignoring tropomi remote sensing data\n#df3_rs=pd.read_csv('/home/mislam25/cmaq/merged_rs.csv')\n\n#final=pd.merge(mrg,df3_rs, on=['year', 'month','day','hours','Station.ID'])\n\n#shifting CMAQ NO2\nshift_df=shift(mrg_rename)\nagg_data = pd.concat(shift_df) # concatening the list\n\n# droping no data from all column and AirNOW_O3)\ndata_new=agg_data.dropna() \nfinal_df = data_new[data_new.AirNOW_O3!= -999]\n\n# saving the file into local drive\nfinal_df.to_csv(home+'/cmaq/merged_2020_2021.csv',index=False)\nsleep(10)\n",
  "history_output" : "preprocess\nTraceback (most recent call last):\n  File \"pre_processing.py\", line 45, in <module>\n    df1 = pd.read_csv(home+'/cmaq/daily_cmaq.csv')\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/aalnaim/cmaq/daily_cmaq.csv'\n",
  "history_begin_time" : 1646615079091,
  "history_end_time" : 1646615100082,
  "history_notes" : null,
  "history_process" : "im9rct",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "yq1xm50x0pl",
  "history_input" : "# NASA GEOWEAVER\n# CMAQ-AI Model: Poocessing the data - shifting columns of NO2\n\n## importing necessary libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\nyear_2020=final.loc[final['year']==2020]\n\n# Processing training  data\nselected_vars = year_2020.drop(['Station.ID','YYYYMMDDHH','year','date','dayofyear'],axis=1)\n\n########################################################\n## Correlation matrix heatmap\n# Correlation between different variables\ncorr = selected_vars.corr()\n# Set up the matplotlib plot configuration\nf, ax = plt.subplots(figsize=(18, 10))\n# Generate a mask for upper traingle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n# Configure a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n# Draw the heatmap\nsns.heatmap(corr, annot=True, mask = mask, cmap=cmap)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top + 0.5)\n#ax.set(xlim=(0, 12))\nplt.savefig(home+'/cmaq/exploratory_analysis/correlation.png')\n########################################################\n\n# plotting r2 values of different variables vs AirNOW_O3\n########################################################\ncolumns=list(selected_vars)\nfor i in columns:\n  try:\n  \tsns.lmplot(x=i, y=\"AirNOW_O3\", data=selected_vars);\n  \tplt.savefig(home+'/cmaq/exploratory_analysis/'+i+'_AirNOW_O3.png')\n  except FileNotFoundError:\n    pass\n    \n########################################################\nsleep(10)",
  "history_output" : "Traceback (most recent call last):\n  File \"exploratory_data_analysis.py\", line 6, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1646615100971,
  "history_end_time" : 1646615115713,
  "history_notes" : null,
  "history_process" : "smwp7r",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "uyuq5nodryt",
  "history_input" : "# NASA GEOWEAVER\n# CMAQ-AI Model: Training Voting-XGBoost model\nprint(\"training_xgboost\")\n# Importing necessary libraries\nimport pandas as pd\nimport sklearn\nfrom sklearn.ensemble import VotingRegressor\nfrom xgboost.sklearn import XGBRegressor\nimport pickle\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\ntrain=final.loc[final['year']==2022]\n\n# Processing training  data\nX = train.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear'],axis=1)\ny = train['AirNOW_O3']\n\n# Defining voting-ensemble based xgboost model\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n# save the model to disk\nfilename = home+'/cmaq/models/xgboost.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(ensemble, open(filename, 'wb'))\n",
  "history_output" : "training_xgboost\nTraceback (most recent call last):\n  File \"training_xgboost.py\", line 8, in <module>\n    from xgboost.sklearn import XGBRegressor\nModuleNotFoundError: No module named 'xgboost'\n",
  "history_begin_time" : 1646615116146,
  "history_end_time" : 1646615169472,
  "history_notes" : null,
  "history_process" : "106i1i",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "7ocv4wykjk0",
  "history_input" : "# NASA Geoweaver\n# CMAQ-AI model: Prediction by Voting-XGBoost\nprint(\"prediction_xgboost\")\n# Importing necessary libraries\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining  testing variables\ntest=final.loc[final['year']==2022]\n# processing test data\ntest_X = test.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear'],axis=1)\ntest_y = test['AirNOW_O3']\ntest_X.head()\n\n# load the model from disk\nfilename = home+'/cmaq/models/xgboost.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\n\n# making prediction\npred = loaded_model.predict(test_X)\n\n# adding prediction values to test dataset\ntest['prediction'] = pred.tolist()\n\n# saving the dataset into local drive\ntest.to_csv(home+'/cmaq/prediction_files/prediction_xgboost.csv',index=False)\nsleep(10)",
  "history_output" : "prediction_xgboost\nTraceback (most recent call last):\n  File \"prediction_xgboost.py\", line 13, in <module>\n    final=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/aalnaim/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1646615169925,
  "history_end_time" : 1646615190301,
  "history_notes" : null,
  "history_process" : "mx09zi",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "3m8hr7ga4hn",
  "history_input" : "# NASA Geoweaver\n# CMAQ-AI Model: Voting-Random Forest\nprint(\"training_rf\")\n# Importing necessary libraries\nimport pandas as pd\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\ntrain=final.loc[final['year']==2022]\n\n# Processing training  data\nX = train.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear'],axis=1)\ny = train['AirNOW_O3']\n\n# define the voting-random forest model\nmodels = list()\nmodels.append(('cart1', RandomForestRegressor(max_depth=1)))\nmodels.append(('cart2', RandomForestRegressor(max_depth=2)))\nmodels.append(('cart3', RandomForestRegressor(max_depth=3)))\nmodels.append(('cart4', RandomForestRegressor(max_depth=4)))\nmodels.append(('cart5', RandomForestRegressor(max_depth=5)))\nmodels.append(('cart6', RandomForestRegressor(max_depth=6)))\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n# save the model to disk\nfilename = home+'/cmaq/models/rf.sav'\n#filename = 'D:/Research/CMAQ/local_test/rf.sav'\npickle.dump(ensemble, open(filename, 'wb'))\nsleep(10)",
  "history_output" : "training_rf\nTraceback (most recent call last):\n  File \"training_random_forest.py\", line 16, in <module>\n    final=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/aalnaim/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1646615116478,
  "history_end_time" : 1646615169472,
  "history_notes" : null,
  "history_process" : "q2io1w",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "md6g7wb1mbc",
  "history_input" : null,
  "history_output" : "/Users/uhhmed/gw-workspace/temp/ANIJtHfpnUG5XSCqfM7JcZHob2.tar is not a regular file or directory",
  "history_begin_time" : 1646615170481,
  "history_end_time" : 1646615171785,
  "history_notes" : null,
  "history_process" : "5o4fxj",
  "host_id" : "p6wvf2",
  "indicator" : "Failed"
},{
  "history_id" : "vw2y3x9jt6i",
  "history_input" : "## NASA GEOWEAVER##\n# CMAQ-AI Model: Autokeras prediction\nprint(\"prediction_autokeras\")\n# Importing necessariy libraries\nimport pandas as pd\nimport tensorflow as tf\nfrom keras.models import load_model\nimport autokeras as ak\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n\n# Import processed data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining and processing testing variables\ntest=final.loc[final['year']==2022]\ntest_X = test.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear'],axis=1)\ntest_y = test['AirNOW_O3']\ntext_X=test_X.values.astype('float32')\n\n# load the model from disk\nloaded_model =load_model(home+'/cmaq/models/autokeras',custom_objects=ak.CUSTOM_OBJECTS)\n#loaded_model =load_model('D:/Research/CMAQ/local_test/autokeras',custom_objects=ak.CUSTOM_OBJECTS)\n\n# Make prediction\npred = loaded_model.predict(test_X)\n# adding prediction values to test dataset and save the result\ntest['prediction'] = pred.tolist()\ntest['prediction'] = test['prediction'].str.get(0)\ntest.to_csv(home+'/cmaq/prediction_files/prediction_autokeras.csv',index=False)",
  "history_output" : "tar: /home/aalnaim/ANIJtHfpnUG5XSCqfM7JcZHob2.tar: Cannot open: No such file or directory\ntar: Error is not recoverable: exiting now\nprediction_autokeras\n",
  "history_begin_time" : 1646615172488,
  "history_end_time" : 1646615190305,
  "history_notes" : null,
  "history_process" : "2gxied",
  "host_id" : "p6wvf2",
  "indicator" : "Failed"
},{
  "history_id" : "kh105921tuk",
  "history_input" : "# NASA Geoweaver\n# CMAQ-AI Model: Prediction by random forest\nprint(\"predictin_rf\")\n# import necessary libraries\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n# import data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining  and processing test variables\ntest=final.loc[final['year']==2022]\n\ntest_X = test.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear'],axis=1)\ntest_y = test['AirNOW_O3']\n\n# load the model from disk\nfilename = home+'/cmaq/models/rf.sav'\n#filename = 'D:/Research/CMAQ/local_test/rf.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\n\n# making prediction\npred = loaded_model.predict(test_X)\n\n# adding prediction values to test dataset\ntest['prediction'] = pred.tolist()\ntest.to_csv(home+'/cmaq/prediction_files/prediction_rf.csv',index=False)",
  "history_output" : "predictin_rf\nTraceback (most recent call last):\n  File \"prediction_random_forest.py\", line 12, in <module>\n    final=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/aalnaim/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1646615169647,
  "history_end_time" : 1646615190299,
  "history_notes" : null,
  "history_process" : "oyz4io",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "cmayp8ov8n9",
  "history_input" : "# Write first python in Geoweaver\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nimport glob\nfrom time import sleep\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n\ndf=glob.glob(home+'/cmaq/prediction_files/*.csv')\nfor i in df:\n  file=pd.read_csv(i)\n  mse=mean_squared_error(file['AirNOW_O3'],file['prediction'])\n  print(i+\"- \"+\"MSE: \",mse)\n\nsleep(10)\n",
  "history_output" : "",
  "history_begin_time" : 1646615215374,
  "history_end_time" : 1646615289383,
  "history_notes" : null,
  "history_process" : "nuklx4",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "ipfocz2kzib",
  "history_input" : "\n## importing necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport glob\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n\n# importing data\npred=pd.read_csv(home+'/cmaq/prediction_files/prediction_xgboost.csv')\ntime_=pred['YYYYMMDDHH'].unique()\ndfs = dict(tuple(pred.groupby('YYYYMMDDHH'))) # grouping the data by YYMMDDHH\n\nfor t in time_:\n  subset=dfs[t]\n  fig = px.density_mapbox(subset, lat='Latitude', lon='Longitude', z='prediction', radius=10,\n                        center=dict(lat=32.777701, lon=-111.358871), zoom=6.5,\n                        mapbox_style=\"stamen-terrain\")\n  # Set figure title\n  fig.update_layout(title_text=\"Date-time: \"+str(t)+\"(YY:MM:DD:HH)\", title_x=0.5)\n  # saving figures\n  fig.write_image(home+\"/cmaq/maps/\"+\"pred\"+str(t)+\".png\")\n\nsleep(10)",
  "history_output" : "Traceback (most recent call last):\n  File \"prediction_visualization.py\", line 4, in <module>\n    import matplotlib.pyplot as plt\nModuleNotFoundError: No module named 'matplotlib'\n",
  "history_begin_time" : 1646615190853,
  "history_end_time" : 1646615215185,
  "history_notes" : null,
  "history_process" : "uzx599",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "s2h5e7owa64",
  "history_input" : "# NASA GEOWEAVER\n# CMAQ-AI Model: Poocessing the data - shifting columns of NO2\n\n# importing necessary libraries\nimport glob\nimport pandas as pd\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\nprint(home+'*.txt')\nfiles=glob.glob(home+'/*.txt')\nprint(files)\nmerged=[]\nfor file in files:\n\tdf=pd.read_csv(file)\n\tmerged.append(df)\ndata_frame = pd.concat(merged)\ndata_frame['YYYYMMDDHH'] = data_frame['YYYYMMDDHH'].map(str)\ndata_frame['year'] = data_frame['YYYYMMDDHH'].str[:4]\ndata_frame['month'] = data_frame['YYYYMMDDHH'].str[4:6]\ndata_frame['day'] = data_frame['YYYYMMDDHH'].str[6:8]\ndata_frame['hours'] = data_frame['YYYYMMDDHH'].str[8:10]\ndata_frame.to_csv(home+'/cmaq/daily_cmaq.csv',index=False)\n\nsleep(5) # Sleep for 5 secs to give time for .csv file to save and ensure next node picks it up",
  "history_output" : "/home/aalnaim*.txt\n['/home/aalnaim/hourly_cmaq12km_airnow_pollutants_20220304.txt']\nTraceback (most recent call last):\n  File \"text_to_csv_daily.py\", line 25, in <module>\n    data_frame.to_csv(home+'/cmaq/daily_cmaq.csv',index=False)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 241, in save\n    with get_handle(\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 697, in get_handle\n    check_parent_directory(str(handle))\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 571, in check_parent_directory\n    raise OSError(fr\"Cannot save file into a non-existent directory: '{parent}'\")\nOSError: Cannot save file into a non-existent directory: '/home/aalnaim/cmaq'\n",
  "history_begin_time" : 1646615056304,
  "history_end_time" : 1646615078888,
  "history_notes" : null,
  "history_process" : "tf0wia",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "iesukxp4470",
  "history_input" : "module load ncl\n\n\ndateYesterday=$(date -d \"2 day ago\" '+%-d')\ndateMonth=$(date -d \"yesterday\" '+%-m')\ncd\nncl dateMonth=$dateMonth dateYesterday=$dateYesterday /groups/ESS/aalnaim/cmaq12_airnow_O3.ncl\n",
  "history_output" : " Copyright (C) 1995-2019 - All Rights Reserved\n University Corporation for Atmospheric Research\n NCAR Command Language Version 6.6.2\n The use of this software is governed by a License Agreement.\n See http://www.ncl.ucar.edu/ for more details.\n\n\nVariable: sdate\nType: integer\nTotal Size: 4 bytes\n            1 values\nNumber of Dimensions: 1\nDimensions and sizes:\t[1]\nCoordinates: \nNumber Of Attributes: 1\n  calendar :\tstandard\n(0)\t20220304\n",
  "history_begin_time" : 1646614993463,
  "history_end_time" : 1646615004196,
  "history_notes" : null,
  "history_process" : "3ymzeo",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
}]
