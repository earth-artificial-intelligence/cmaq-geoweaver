[{
  "history_id" : "1lf1rjhl080",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001349,
  "history_end_time" : 1668494001349,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ancix4fwmc5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001498,
  "history_end_time" : 1668494001498,
  "history_notes" : null,
  "history_process" : "xpdg66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9gh4ccs2j5n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001510,
  "history_end_time" : 1668494001510,
  "history_notes" : null,
  "history_process" : "xlayd5",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uid5b0txqan",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001511,
  "history_end_time" : 1668494001511,
  "history_notes" : null,
  "history_process" : "argv3i",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hgfc08lf5x0",
  "history_input" : "# use the trained model to predict on the testing data and save the results to prediction_rf.csv\n\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\nimport glob, os\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom cmaq_ai_utils import *\n\ncreate_and_clean_folder(f\"{cmaq_folder}/prediction_files/\")\n\n# importing data\n# final=pd.read_csv(f\"{cmaq_folder}/testing_input_hourly/testing.csv\")\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\n\n# load the model from disk\n# filename = f'{cmaq_folder}/models/rf_pycaret.sav'\n\nfilename = f'{model_folder}/rf_pycaret_o3_one_year_good.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\n\nfor testing_df in df_from_each_hourly_file:\n  #print(testing_df['YYYYMMDDHH'].values[0])\n  file_dateTime = testing_df['YYYYMMDDHH'].values[0]\n  #X = testing_df.drop(['YYYYMMDDHH','Latitude','Longitude'],axis=1)\n  testing_df['time_of_day'] = (testing_df['hours'] % 24 + 4) // 4\n\n  # Make coords even more coarse by rounding to closest multiple of 5 \n  # (e.g., 40, 45, 85, 55)\n  #testing_df['Latitude_ExtraCoarse'] = 0.1 * round(testing_df['Latitude']/0.1)\n  #testing_df['Longitude_ExtraCoarse'] = 0.1 * round(testing_df['Longitude']/0.1)\n  X = testing_df.drop(['YYYYMMDDHH','Latitude','Longitude', 'CO(moles/s)'],axis=1)\n  \n  #print(X.columns)\n\n# # making prediction\n  pred = loaded_model.predict(X)\n\n# adding prediction values to test dataset\n  #testing_df['prediction'] = testing_df['CMAQ12KM_O3(ppb)'].tolist()\n  testing_df['prediction'] = pred\n\n  testing_df = testing_df[['Latitude', 'Longitude','YYYYMMDDHH','prediction']]\n# saving the dataset into local drive\n  print(f'Saving: {cmaq_folder}/prediction_files/prediction_rf_{file_dateTime}.csv')\n  testing_df.to_csv(f'{cmaq_folder}/prediction_files/prediction_rf_{file_dateTime}.csv',index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"rf_prediction.py\", line 9, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/hgfc08lf5x0/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668494072945,
  "history_end_time" : 1668494109255,
  "history_notes" : null,
  "history_process" : "l8vlic",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "najdcpnft5o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001539,
  "history_end_time" : 1668494001539,
  "history_notes" : null,
  "history_process" : "wny2dz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3a82yxgll0c",
  "history_input" : "# load the prediction_rf.csv into a NetCDF file for visualization\nfrom cmaq_ai_utils import *\n\n# end_date = datetime.today()\n# base = end_date - timedelta(days=2)\n#sdate = date(2022, 8, 6)   # start date\n#edate = date(2022, 8, 8)   # end date\n\nprediction_path = f\"{cmaq_folder}/prediction_files/\"\n\nall_hourly_files = sorted(glob.glob(os.path.join(prediction_path, \"*.csv\")))\n# print(\"overall hourly files: \", all_hourly_files)\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\nfor i in range(len(days)-1):\n  print(days[i])\n  current_day = days[i]\n  next_day = days[i+1]\n  \n  cmaq_cdf_file = \"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\"\n  \n  target_cdf_file = f'{cmaq_folder}/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+current_day+'_ML_extracted.nc'\n  \n  if not os.path.exists(cmaq_cdf_file):\n    print(f\"{cmaq_cdf_file} doesn't exist\")\n    continue\n    \n  if os.path.exists(target_cdf_file):\n    print(f\"{target_cdf_file} already exists\")\n    continue\n  \n  df_cdf = xr.open_dataset(cmaq_cdf_file)\n  daily_hourly_files = []\n  for k in real_hour_list:\n    real_hour_value = real_hour_list[k]\n    if real_hour_value<12:\n      day = next_day\n    else:\n      day = current_day\n    #daily_hourly_files.append(f'{test_folder}/test_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    daily_hourly_files.append(f'{cmaq_folder}/prediction_files/prediction_rf_{day}{turn_2_digits(real_hour_value)}.csv')\n  daily_hourly_files = sorted(daily_hourly_files)\n  #print(\"single day hourly files: \", all_hourly_files[i*24:(i+1)*24])\n  print(\"single day hourly files: \", daily_hourly_files)\n  df_from_each_hourly_file = (pd.read_csv(f) for f in daily_hourly_files)\n  \n  df_csv = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n  reshaped_prediction = df_csv['prediction'].to_numpy().reshape(24, 265, 442)\n  print(reshaped_prediction.shape)\n  \n  # Remove \"LAY\" Dimension in O3 variable already in nc file.\n  reduced_dim = df_cdf['O3'].sel(LAY=1, drop=True)\n\n  # Swap values from original nc file with new prediction data\n  reduced_dim.values = reshaped_prediction\n\n  # Apply changes to data variable in nc file\n  df_cdf['O3'] = (['TSTEP', 'ROW', 'COL'], reshaped_prediction)\n\n#   create_and_clean_folder(f\"{cmaq_folder}/prediction_nc_files\")\n  df_cdf.to_netcdf(target_cdf_file)\n\n  print(f'Saved updated netCDF file: {target_cdf_file}')",
  "history_output" : "Traceback (most recent call last):\n  File \"processing_test_netcdf.py\", line 2, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/3a82yxgll0c/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668494110976,
  "history_end_time" : 1668494137813,
  "history_notes" : null,
  "history_process" : "3asyzj",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "awpqy13kvxm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001551,
  "history_end_time" : 1668494001551,
  "history_notes" : null,
  "history_process" : "9xdvh6",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "umm66592jlm",
  "history_input" : "# get hourly CMAQ data into csv for prediction\n\nfrom cmaq_ai_utils import *\n\n\n#edate = datetime.today()\n#sdate = edate - timedelta(days=1)\n# today = datetime.today()\n# edate = today\n# sdate = today - timedelta(days=days_back)\n\n#sdate = date(2022, 8, 6)   # start date\n#edate = date(2022, 8, 8)   # end date\n# days = get_days_list_for_prediction(sdate, edate)\n\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntest_folder = f\"{cmaq_folder}/testing_input_hourly/\"\ncreate_and_clean_folder(test_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  cmaq_file = \"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\"\n  if not os.path.exists(cmaq_file):\n    print(f\"CMAQ file {cmaq_file} doesn't exist\")\n    continue\n  \n  target_cdf_file = f'{cmaq_folder}/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+current_day+'_ML_extracted.nc'\n    \n  if os.path.exists(target_cdf_file):\n    print(f\"{target_cdf_file} already exists\")\n    continue\n  \n  df_cmaq = xr.open_dataset(cmaq_file)\n  \n  # read mcip results \n  mcip_file = \"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\"\n  df_mcip = xr.open_dataset(mcip_file)\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value<12:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    #print(\"df_cmaq.variables['O3'] shape: \", df_cmaq.variables['O3'].shape)\n    #print(\"df_cmaq.variables['O3'][:] shape: \", df_cmaq.variables['O3'][:].shape)\n    #print(\"df_cmaq.variables['O3'][:].values[k, 0].shape\", df_cmaq.variables['O3'][:].values[k, 0].shape)\n    # CMAQ data\n    # O3 variable\n    o3=df_cmaq.variables['O3'][:].values[k, 0]\n    cmaq_O3=list(np.ravel(o3).transpose())\n    #print(\"o3 shape: \", o3.shape)\n    #print(\"cmaq_O3 shape: \", np.ravel(o3).transpose().shape)\n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k, 0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k, 0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k, 0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k, 0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k, 0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k, 0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k, 0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k, 0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k, 0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k, 0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k, 0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    #print(\"lat shape\", lat.shape)\n    lat_flt=np.ravel(lat)\n    LAT=lat_flt #np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=lon_flt #np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    print(f'Saving file: test_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(f'{test_folder}/test_data_{day}_{turn_2_digits(real_hour_value)}.csv',index=False)\n\nprint('Done with preparing testing data!')",
  "history_output" : "Traceback (most recent call last):\n  File \"processing_test_data.py\", line 3, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/umm66592jlm/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668494002038,
  "history_end_time" : 1668494042926,
  "history_notes" : null,
  "history_process" : "ex3vh9",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lrfvqw1qinq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/lrfvqw1qinq/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668494044043,
  "history_end_time" : 1668494070956,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "w3a6pl16avm",
  "history_input" : "#!/bin/bash\n# generate images and gif from the NetCDF files\n\ncmaq_folder=\"/groups/ESS/zsun/cmaq\"\npermanent_location=\"/groups/ESS3/zsun/cmaq/ai_results/\"\nmkdir $cmaq_folder\"/plots\"\n\n\nexport postdata_dir=$cmaq_folder\"/prediction_nc_files\"\nexport mcip_dir=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km\"\nexport dir_graph=$cmaq_folder\"/plots\"\n\necho \"Loading NCL\"\nmodule load ncl\necho \"Loaded NCL\"\n\nrm $cmaq_folder/geoweaver_plot_daily_O3.ncl\n\necho \"Drafting \"$cmaq_folder/geoweaver_plot_daily_O3.ncl\ncat <<EOF >> $cmaq_folder/geoweaver_plot_daily_O3.ncl\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\n\nprint(\"NCL script successfully begin: \")\n\ndate = getenv(\"YYYYMMDD_POST\")\nd1 = getenv(\"stdate_post\")\nd2 = getenv(\"eddate_post\")\n\ndFile1 = getenv(\"stdate_file\")\ndFile2 = getenv(\"eddate_file\")\n\n;print(\"Passed Date: \"+date)\n\n;aconc_dir = getenv(\"postdata_dir\")\ngrid_dir = getenv(\"mcip_dir\")\nplot_dir = getenv(\"dir_graph\")\n\nprint(\"/groups/ESS/zsun/cmaq/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+dFile1+\"_ML_extracted.nc\")\ncdf_file1 = addfile(\"/groups/ESS/zsun/cmaq/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+dFile1+\"_ML_extracted.nc\",\"r\")\ncdf_file= addfile(grid_dir+\"/GRIDCRO2D_\"+date+\".nc\",\"r\")\n\nptime = (/\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"00\",\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\"/)\n\ntime = cdf_file1->TFLAG(:,0,:)\no3 = cdf_file1->O3(:,:,:) ;ppb\n;pm25 = cdf_file1->PM25_TOT(:,0,:,:)\n\n\nnt = dimsizes(o3(:,0,0))\nny = dimsizes(o3(0,:,0))\nnx = dimsizes(o3(0,0,:))\n\nprint(nt+\" \"+ny+\" \"+nx)\nprint(max(o3))\nprint(min(o3))\nprint(avg(o3))\n\n;print(max(pm25))\n;print(min(pm25))\n;print(avg(pm25))\n\n;print(time)\n\nlat = cdf_file->LAT(0,0,:,:)\nlon = cdf_file->LON(0,0,:,:)\n\no3@lat2d = lat\no3@lon2d = lon\n\nres = True\nres@gsnMaximize = True                ; maximize pot in frame\nres@gsnFrame = False               ; don't advance frame\nres@gsnDraw = False\n;res@gsnSpreadColors = True\nres@lbLabelAutoStride = True\n;res@lbBoxLinesOn = False\nres@pmLabelBarHeightF = 0.1\nres@pmLabelBarWidthF = 0.5\nres@cnFillOn=True\n;res@cnMonoFillPattern=True\n;res@cnMonoLineColor=True\nres@cnLinesOn=False\n;res@pmLabelBarDisplayMode=\"never\"\nres@gsnLeftString  = \"\";\nres@gsnRightString = \"\"\n\nres@mpLimitMode = \"LatLon\"\nres@mpMinLonF = -120 ;min(lon)+0.2\nres@mpMaxLonF = -70 ;max(lon)-0.2\nres@mpMinLatF = 25 ;min(lat)+0.05\nres@mpMaxLatF = 50 ;max(lat)-0.05\nres@mpDataBaseVersion = \"MediumRes\"\n;res@tiMainString = times(it)\nres@mpDataBaseVersion       = \"MediumRes\"\nres@mpDataSetName           = \"Earth..4\"\nres@mpAreaMaskingOn         = True\nres@mpOutlineBoundarySets = \"GeophysicalAndUSStates\"\nres@mpOutlineSpecifiers=\"United States : States\"\nres@mpLandFillColor         = \"white\"\nres@mpInlandWaterFillColor  = \"white\"\nres@mpOceanFillColor        = \"white\"\nres@mpGeophysicalLineColor    = \"Black\"\nres@mpGeophysicalLineThicknessF = 1.5\n\n;res@gsnSpreadColors         = True\nres@lbLabelAutoStride       = True\nres@lbLabelFont             = 25\nres@tiXAxisFont             = 25\nres@pmTickMarkDisplayMode   = \"Always\"\nres@tmXBLabelFont           = 25\nres@tmXBLabelFontHeightF    = 0.013\nres@tmXBLabelDeltaF         = -0.5\nres@tmYLLabelFont           = 25\nres@tmYLLabelFontHeightF    = 0.013\nres@tmXBLabelDeltaF         = -0.5\nres@tmXTLabelsOn            = False\nres@tmXTLabelFont           = 25\nres@tmXTLabelFontHeightF    = 0.013\nres@tmYRLabelsOn            = False\nres@tmYRLabelFont           = 25\nres@tmYRLabelFontHeightF    = 0.013\n\n\nres@mpProjection           = \"LambertConformal\" ;\"CylindricalEquidistant\"\nres@mpLambertParallel1F    = 33.\nres@mpLambertParallel2F    = 45.\nres@mpLambertMeridianF     = -98.\n\nres@cnLevelSelectionMode = \"ManualLevels\"\nres@cnMinLevelValF          = 0.\nres@cnMaxLevelValF          = 80\nres@cnLevelSpacingF         = 4\n\nres@txFont   = \"times-roman\"\nres@tiMainFont   = \"times-roman\"\n\ndo it = 0, nt-1\n  if (it .lt. 12) then\n    pdate=d1\n  else\n    pdate=d2\n  end if\n\n  pname=plot_dir+\"/testPlot_\"+pdate+\"_\"+ptime(it)\n  wks = gsn_open_wks(\"png\",pname)\n  gsn_define_colormap(wks, \"WhiteBlueGreenYellowRed\")\n\n  res@tiMainString = pdate+\" \"+ptime(it)+\" UTC O~B~3~N~ Forecast (ppbV)\"\n  plot = gsn_csm_contour_map(wks,o3(it,:,:),res)\n  draw(plot)\n  frame(wks)\n  delete(wks)\n  system(\"composite -geometry 100x70+900+900 /groups/ESS/zsun/cmaq/mason-logo-green.png \"+pname+\".png \"+pname+\".png\")\nend do\ndelete(res)\n\nend\nexit\nEOF\n\necho \"Start to run the NCL script: \"$cmaq_folder\"/geoweaver_plot_daily_O3.ncl\"\n\necho \"ncl \"$cmaq_folder\"/geoweaver_plot_daily_O3.ncl\"\n\necho $(date -d '1 day ago' '+%Y%m%d')\n\ndays_back=30\n\nfor i in $(seq 1 $days_back)\ndo\n  end_day=$i\n  echo \"$end_day days ago\"\n  begin_day=$((i+1))\n  # Setting env variables\n  export YYYYMMDD_POST=$(date -d $begin_day' day ago' '+%Y%m%d') #This needs to be auto date `date -d \"-2 day ${1}\" +%Y%m%d`\n  #export YYYYMMDD_POST='20220806'\n  export stdate_post=$(date -d $begin_day' day ago' '+%Y-%m-%d') #This needs to be auto date\n  #export stdate_post='2022-08-06'\n  export eddate_post=$(date -d $end_day' day ago' '+%Y-%m-%d') #This needs to be auto date\n  #export eddate_post='2022-08-08'\n\n  export stdate_file=$(date -d $begin_day' day ago' '+%Y%m%d') #This needs to be auto date\n  #export stdate_file='20220806'\n  export eddate_file=$(date -d $end_day' day ago' '+%Y%m%d') #This needs to be auto date\n  #export eddate_file='20220808'\n  stdate_file=$(date -d $begin_day' day ago' '+%Y%m%d')\n  echo \"stdate_file=\"$stdate_file\n  # determine if the prediction netcdf is there\n  predict_nc_file=$cmaq_folder\"/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_\"$stdate_file\"_ML_extracted.nc\"\n  if [ -f \"$predict_nc_file\" ]; then\n    echo \"$predict_nc_file exists.\"\n  else\n    echo \"$predict_nc_file doesn't exist. Skipping...\"\n    continue\n  fi\n  \n  rm -rf $cmaq_folder/plots/* # clean everything in the folder first\n\n  ncl $cmaq_folder/geoweaver_plot_daily_O3.ncl\n\n  echo \"Finished \"$cmaq_folder\"/geoweaver_plot_daily_O3.ncl\"\n\n  # convert -delay 100 *.png 20220613_20220614.gif\n  convert -delay 100 $cmaq_folder/plots/testPlot*.png $cmaq_folder/plots/\"Map_\"$YYYYMMDD_POST.gif\n  echo \"Converted images to gif\"\n\n  # cp the results to permanent location\n  cp $predict_nc_file $permanent_location/netcdfs/\n  cp $cmaq_folder/plots/\"Map_\"$YYYYMMDD_POST.gif $permanent_location/gifs/\n  echo \"Moved the generated netcdfs and gifs to permanent locations\"\n  \ndone\n\n\n\nif [ $? -eq 0 ]; then\n    echo \"Generating images/gif Completed Successfully\"\nelse\n    echo \"Generating images/gif Failed!\"\nfi\n",
  "history_output" : "Running",
  "history_begin_time" : 1668494139500,
  "history_end_time" : 1668494139270,
  "history_notes" : null,
  "history_process" : "iicy7w",
  "host_id" : "100001",
  "indicator" : "Running"
},{
  "history_id" : "k5qif3e2x69",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001597,
  "history_end_time" : 1668494001597,
  "history_notes" : null,
  "history_process" : "h76ld0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yisejds9twr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001601,
  "history_end_time" : 1668494001601,
  "history_notes" : null,
  "history_process" : "s6hbic",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i8zhzonmgyi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001607,
  "history_end_time" : 1668494001607,
  "history_notes" : null,
  "history_process" : "pvzabv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jfh6awqxgg9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668494001610,
  "history_end_time" : 1668494001610,
  "history_notes" : null,
  "history_process" : "8i9ptn",
  "host_id" : "100001",
  "indicator" : "Skipped"
}]
