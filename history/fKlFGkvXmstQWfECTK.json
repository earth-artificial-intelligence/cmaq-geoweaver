[{
  "history_id" : "k385cgko6o0",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "",
  "history_begin_time" : 1663783472385,
  "history_end_time" : 1663783472734,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1s7efaqxp5l",
  "history_input" : "# get all the airnow station data and save to csvs as well\nimport glob, os\nimport numpy as np\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\ndays = get_days_list(sdate, edate)\n\nobservation_folder = f\"{cmaq_folder}/observation/\"\ncreate_and_clean_folder(observation_folder)\n\ntime = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in range(len(days)-1):\n  current_day = days[i]\n  next_day = days[i+1]\n  for x in range(len(time)):\n    if x >= 12:\n      i = next_day\n    else:\n      i = current_day\n    t = time[x]\n    files = \"/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X/\"+\"AQF5X_Hourly_\"+i+t+\".dat\"\n    \n    with open(files, 'r') as file:\n      text = file.read()\n      new_string = text.replace('\"', '')\n      out_file = f\"{observation_folder}/AQF5X_Hourly_{i}{t}.txt\"\n      print(\"Saving to :\", out_file)\n      outF = open(out_file, \"w\")\n      for line in new_string:\n        outF.write(line)\n      \n      outF.close()",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/1s7efaqxp5l/observation.py\", line 11, in <module>\n    create_and_clean_folder(observation_folder)\n  File \"/Users/joe/gw-workspace/1s7efaqxp5l/cmaq_ai_utils.py\", line 35, in create_and_clean_folder\n    os.makedirs(folder_path, exist_ok=True)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  [Previous line repeated 1 more time]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 225, in makedirs\n    mkdir(name, mode)\nOSError: [Errno 30] Read-only file system: '/groups'\n",
  "history_begin_time" : 1663783473009,
  "history_end_time" : 1663783474544,
  "history_notes" : null,
  "history_process" : "xpdg66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "c80kvo7vvph",
  "history_input" : "# take all the airnow observation csvs and merge into one observation.csv\n\nimport glob\nimport pandas as pd\nfrom pathlib import Path\nimport numpy as np\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\ndays = get_days_list(sdate, edate)\n    \ndata_frame = pd.DataFrame()\nmerged=[]\ndate_time=[]\n\ntime = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  for y in range(len(time)):\n    t = time[y]\n    if y>=12:\n      d = next_day\n    else:\n      d = current_day\n    files=glob.glob(f\"{cmaq_folder}/observation/AQF5X_Hourly_{d}{t}.txt\")\n    for file in files:\n      print(file)\n      data = np.loadtxt(file, skiprows=1,dtype='str')\n      dt=d+t\n      print(dt)\n      dt=np.tile(dt,len(data)) # constructs an array for each hour of each day with length of data from total stations available\n      date_time.append(dt)\n      merged.append(data)\n            \ndata_frame = np.concatenate(merged)\n\n# This gets the first 4 columns in the observation file (AQSID, Latitude, Longitude, OZONE(ppb))\ndata_frame = np.delete(data_frame, np.s_[4:9], axis=1) \n\ndf = pd.DataFrame(data_frame, columns = ['StationID','Latitude','Longitude','AirNOW_O3'])\ndff=df.replace(',','', regex=True)\n\ndt = np.concatenate(date_time)\ndff['YYYYMMDDHH'] = dt.tolist()\ndff.to_csv(f\"{cmaq_folder}/observation/observation.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/c80kvo7vvph/processing_observation_data.py\", line 38, in <module>\n    data_frame = np.concatenate(merged)\n  File \"<__array_function__ internals>\", line 5, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1663783476019,
  "history_end_time" : 1663783477480,
  "history_notes" : null,
  "history_process" : "xlayd5",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mag4nh5rs6c",
  "history_input" : "# combine cmaq and airnow into training.csv\nfrom cmaq_ai_utils import *\n\n# cmaq=pd.read_csv(home+\"/cmaq/training_data.csv\")\npath = f'{cmaq_folder}/training_input_hourly'\nall_hourly_files = sorted(glob.glob(os.path.join(path, \"*.csv\"))) \ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file)\n\nobs=pd.read_csv(f\"{cmaq_folder}/observation/observation.csv\")\nref_stations=pd.read_csv(f\"{cmaq_folder}/station_cmaq_location.csv\")\n\nnew_df = pd.merge(ref_stations, cmaq,  how='left', left_on=['Latitude_y','Longitude_y'], right_on = ['Latitude','Longitude'])\nnew_df.to_csv(f\"{cmaq_folder}/subset.csv\")\nfinal = pd.merge(obs, new_df,  how='left', left_on=['Latitude','Longitude','YYYYMMDDHH'], right_on = ['Latitude_x','Longitude_x','YYYYMMDDHH'])\n\nfinal=final.drop_duplicates(keep=False)\ntraining_data = final.loc[:,~final.columns.duplicated()]\n\ntraining_data['YYYYMMDDHH'] = training_data['YYYYMMDDHH'].map(str)\ntraining_data['month'] = training_data['YYYYMMDDHH'].str[4:6]\ntraining_data['day'] = training_data['YYYYMMDDHH'].str[6:8]\ntraining_data['hours'] = training_data['YYYYMMDDHH'].str[8:10]\n\nnew_df=training_data.drop(['YYYYMMDDHH'],axis=1)\nfinal_df = new_df[new_df.AirNOW_O3!= -999]\nfinal_df.to_csv(f\"{cmaq_folder}/trainingNew.csv\",index=False)\nprint(\"All records should be incorporated into :\", f\"{cmaq_folder}/training.csv\")\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/mag4nh5rs6c/merge_training_data.py\", line 8, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 294, in concat\n    op = _Concatenator(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 351, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1663783478563,
  "history_end_time" : 1663783480127,
  "history_notes" : null,
  "history_process" : "argv3i",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "wvpthnz9qsw",
  "history_input" : "# use the trained model to predict on the testing data and save the results to prediction_rf.csv\n\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\nimport glob, os\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom cmaq_ai_utils import *\n\ncreate_and_clean_folder(f\"{cmaq_folder}/prediction_files/\")\n\n# importing data\n# final=pd.read_csv(f\"{cmaq_folder}/testing_input_hourly/testing.csv\")\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\n\n# load the model from disk\n# filename = f'{cmaq_folder}/models/rf_pycaret.sav'\n\nfilename = f'{cmaq_folder}/models/rf_pycaret_o3_coarse_loc.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\n\nfor testing_df in df_from_each_hourly_file:\n  print(testing_df['YYYYMMDDHH'].values[0])\n  file_dateTime = testing_df['YYYYMMDDHH'].values[0]\n  #X = testing_df.drop(['YYYYMMDDHH','Latitude','Longitude'],axis=1)\n  testing_df['time_of_day'] = (testing_df['hours'] % 24 + 4) // 4\n\n  # Make coords even more coarse by rounding to closest multiple of 5 \n  # (e.g., 40, 45, 85, 55)\n  testing_df['Latitude_ExtraCoarse'] = 0.1 * round(testing_df['Latitude']/0.1)\n  testing_df['Longitude_ExtraCoarse'] = 0.1 * round(testing_df['Longitude']/0.1)\n  X = testing_df.drop(['YYYYMMDDHH','Latitude','Longitude','CMAQ12KM_NO2(ppb)', 'CMAQ12KM_CO(ppm)', 'CMAQ_OC(ug/m3)', 'CO(moles/s)', 'PRSFC(Pa)', 'PBL(m)', 'TEMP2(K)','WSPD10(m/s)', 'WDIR10(degree)', 'RGRND(W/m2)', 'CFRAC', 'month', 'day', 'hours',],axis=1)\n\n# # making prediction\n  pred = loaded_model.predict(X)\n\n# adding prediction values to test dataset\n  #testing_df['prediction'] = testing_df['CMAQ12KM_O3(ppb)'].tolist()\n  testing_df['prediction'] = pred\n\n  testing_df = testing_df[['Latitude', 'Longitude','YYYYMMDDHH','prediction']]\n# saving the dataset into local drive\n  print(f'Saving: {cmaq_folder}/prediction_files/prediction_rf_{file_dateTime}.csv')\n  testing_df.to_csv(f'{cmaq_folder}/prediction_files/prediction_rf_{file_dateTime}.csv',index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/wvpthnz9qsw/rf_prediction.py\", line 11, in <module>\n    create_and_clean_folder(f\"{cmaq_folder}/prediction_files/\")\n  File \"/Users/joe/gw-workspace/wvpthnz9qsw/cmaq_ai_utils.py\", line 35, in create_and_clean_folder\n    os.makedirs(folder_path, exist_ok=True)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  [Previous line repeated 1 more time]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 225, in makedirs\n    mkdir(name, mode)\nOSError: [Errno 30] Read-only file system: '/groups'\n",
  "history_begin_time" : 1663783492676,
  "history_end_time" : 1663783494456,
  "history_notes" : null,
  "history_process" : "l8vlic",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "tw6bgxcu6kq",
  "history_input" : "# Write first python in Geoweaver# NASA GEOWEAVER\n# CMAQ-AI Model: Training Voting-XGBoost model\n\n# Importing necessary libraries\nimport pandas as pd\nimport sklearn\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost.sklearn import XGBRegressor\nimport pickle\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv('/groups/ESS/zsu/cmaq/training.csv')\nprint(final.head())\nfinal=final.dropna()\n\n# Processing training  data\nX = final.drop(['AirNOW_O3','Latitude_x','Longitude_x'],axis=1)\ny = final['AirNOW_O3']\n\nrf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n                      max_samples=None, min_impurity_decrease=0.0,\n                      min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      n_estimators=100, n_jobs=-1, oob_score=False,\n                      random_state=3086, verbose=0, warm_start=False)\n\nrf.fit(X, y)\n\n# save the model to disk\nfilename = '/groups/ESS/zsun/cmaq/models/rf_from_hourly_fixed.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(rf, open(filename, 'wb'))",
  "history_output" : "/Users/joe/gw-workspace/tw6bgxcu6kq/gw-wB3v9thLphSxeLgJX96b3YsH4i-tw6bgxcu6kq.sh: line 5: import: command not found\n/Users/joe/gw-workspace/tw6bgxcu6kq/gw-wB3v9thLphSxeLgJX96b3YsH4i-tw6bgxcu6kq.sh: line 6: import: command not found\nfrom: can't read /var/mail/sklearn.ensemble\nfrom: can't read /var/mail/xgboost.sklearn\n/Users/joe/gw-workspace/tw6bgxcu6kq/gw-wB3v9thLphSxeLgJX96b3YsH4i-tw6bgxcu6kq.sh: line 9: import: command not found\nfrom: can't read /var/mail/pathlib\n/Users/joe/gw-workspace/tw6bgxcu6kq/gw-wB3v9thLphSxeLgJX96b3YsH4i-tw6bgxcu6kq.sh: line 13: syntax error near unexpected token `('\n/Users/joe/gw-workspace/tw6bgxcu6kq/gw-wB3v9thLphSxeLgJX96b3YsH4i-tw6bgxcu6kq.sh: line 13: `home = str(Path.home())'\n",
  "history_begin_time" : 1663783481504,
  "history_end_time" : 1663783482600,
  "history_notes" : null,
  "history_process" : "wny2dz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "wztkcu4q6x0",
  "history_input" : "# load the prediction_rf.csv into a NetCDF file for visualization\nfrom cmaq_ai_utils import *\n\n# end_date = datetime.today()\n# base = end_date - timedelta(days=2)\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\ndays = get_days_list(sdate, edate)\n\nprediction_path = f\"{cmaq_folder}/prediction_files/\"\n\nall_hourly_files = sorted(glob.glob(os.path.join(prediction_path, \"*.csv\")))\n# print(\"overall hourly files: \", all_hourly_files)\n\nfor i in range(len(days)-1):\n  print(days[i])\n  \n  df_cdf = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+days[i+1]+\"_extracted.nc\")\n  \n  print(\"single day hourly files: \", all_hourly_files[i*24:(i+1)*24])\n  df_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files[i*24:(i+1)*24])\n  \n  df_csv = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n  reshaped_prediction = df_csv['prediction'].to_numpy().reshape(24, 265, 442)\n  print(reshaped_prediction.shape)\n  \n  # Remove \"LAY\" Dimension in O3 variable already in nc file.\n  reduced_dim = df_cdf['O3'].sel(LAY=1, drop=True)\n\n  # Swap values from original nc file with new prediction data\n  reduced_dim.values = reshaped_prediction\n\n  # Apply changes to data variable in nc file\n  df_cdf['O3'] = (['TSTEP', 'ROW', 'COL'], reshaped_prediction)\n\n#   create_and_clean_folder(f\"{cmaq_folder}/prediction_nc_files\")\n  df_cdf.to_netcdf(f'{cmaq_folder}/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+days[i]+'_ML_extracted.nc')\n\n  print(f'Saved updated netCDF file: {cmaq_folder}/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+days[i]+'_ML_extracted.nc')",
  "history_output" : "20220805\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function _open_scipy_netcdf at 0x7f84622f0af0>, ('/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_20220806_extracted.nc',), 'r', (('mmap', None), ('version', 2))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/wztkcu4q6x0/processing_test_netcdf.py\", line 18, in <module>\n    df_cdf = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+days[i+1]+\"_extracted.nc\")\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/api.py\", line 495, in open_dataset\n    backend_ds = backend.open_dataset(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/scipy_.py\", line 282, in open_dataset\n    ds = store_entrypoint.open_dataset(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/store.py\", line 24, in open_dataset\n    vars, attrs = store.load()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/common.py\", line 123, in load\n    (_decode_variable_name(k), v) for k, v in self.get_variables().items()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/scipy_.py\", line 171, in get_variables\n    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/scipy_.py\", line 160, in ds\n    return self._manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/scipy_.py\", line 99, in _open_scipy_netcdf\n    return scipy.io.netcdf_file(filename, mode=mode, mmap=mmap, version=version)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/scipy/io/netcdf.py\", line 247, in __init__\n    self.fp = open(self.filename, '%sb' % omode)\nFileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_20220806_extracted.nc'\n",
  "history_begin_time" : 1663783496121,
  "history_end_time" : 1663783500705,
  "history_notes" : null,
  "history_process" : "3asyzj",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "93xbbwkmxh6",
  "history_input" : "# install all dependencies\n# NASA-GEOWEAVER: Environment setting\n\nimport os\nimport sys\nimport subprocess\nimport pkg_resources\n\nwith open('requirements.txt','w') as out:\n  out.write('''\nabsl-py==1.0.0\naffine==2.3.1\nasttokens==2.0.5\nastunparse==1.6.3\nattrs==21.4.0\nautokeras==1.0.18\nbackcall==0.2.0\ncachetools==5.0.0\ncertifi==2021.10.8\ncftime==1.6.0\ncharset-normalizer==2.0.12\nclick==8.1.3\nclick-plugins==1.1.1\ncligj==0.7.2\ncmaps==1.0.5\ncycler==0.11.0\ndecorator==5.1.1\nearthpy==0.9.4\nexecuting==0.8.3\nFiona==1.8.21\nflatbuffers==2.0\nfonttools==4.29.1\ngast==0.5.3\ngeopandas==0.10.2\nglob2==0.7\ngoogle-auth==2.6.0\ngoogle-auth-oauthlib==0.4.6\ngoogle-pasta==0.2.0\ngrpcio==1.44.0\nh5py==3.6.0\nidna==3.3\nimageio==2.19.0\nimageio-ffmpeg==0.4.7\nimportlib-metadata==4.11.2\nipython==8.1.1\njedi==0.18.1\njoblib==1.1.0\nkaleido==0.2.1\nkeras==2.8.0\nKeras-Preprocessing==1.1.2\nkeras-tuner==1.1.0\nkiwisolver==1.3.2\nkt-legacy==1.0.4\nlibclang==13.0.0\nMarkdown==3.3.6\nmatplotlib==3.5.1\nmatplotlib-inline==0.1.3\nmunch==2.5.0\nnetCDF4==1.5.8\nnetworkx==2.8\nnumpy==1.22.2\noauthlib==3.2.0\nopencv-python==4.5.5.64\nopt-einsum==3.3.0\npackaging==21.3\npandas==1.4.1\nparso==0.8.3\npathlib==1.0.1\npathlib2==2.3.7.post1\npexpect==4.8.0\npickleshare==0.7.5\nPillow==9.0.1\nplotly==5.7.0\nprompt-toolkit==3.0.28\nprotobuf==3.19.4\nptyprocess==0.7.0\npure-eval==0.2.2\npyasn1==0.4.8\npyasn1-modules==0.2.8\nPygments==2.11.2\npyparsing==3.0.7\npyproj==3.3.1\npython-dateutil==2.8.2\npytz==2021.3\nPyWavelets==1.3.0\nrasterio==1.2.10\nrequests==2.27.1\nrequests-oauthlib==1.3.1\nrsa==4.8\nscikit-image==0.19.2\nscikit-learn==1.0.2\nscipy==1.8.0\nseaborn==0.11.2\nShapely==1.8.2\nsix==1.16.0\nsklearn==0.0\nsnuggs==1.4.7\nstack-data==0.2.0\ntenacity==8.0.1\ntensorboard==2.8.0\ntensorboard-data-server==0.6.1\ntensorboard-plugin-wit==1.8.1\ntensorflow==2.8.0\ntensorflow-gpu==2.8.0\ntensorflow-io-gcs-filesystem==0.24.0\ntermcolor==1.1.0\ntf-estimator-nightly==2.8.0.dev2021122109\nthreadpoolctl==3.1.0\ntifffile==2022.5.4\ntraitlets==5.1.1\ntyping_extensions==4.1.1\nurllib3==1.26.8\nwcwidth==0.2.5\nWerkzeug==2.0.3\nwrapt==1.13.3\nxarray==2022.3.0\nxgboost==1.6.0\nzipp==3.7.0''')\n  \npython = sys.executable\nsubprocess.check_call([python, '-m', 'pip', 'install', '-r', 'requirements.txt'], stdout=subprocess.DEVNULL)\n    #subprocess.check_call(\n        #[python, '-m', 'conda', 'install', '-c','conda-forge','xgboost'],\n      #stdout=subprocess.DEVNULL)\n\n\n################################\n#  END OF PACKAGES Installation  #\n\n\n# Creating directoris \nfrom pathlib import Path\nhome = str(Path.home())\nfolders = ['cmaq/exploratory_analysis', 'cmaq/prediction_maps', 'cmaq/prediction_files','cmaq/models','cmaq/observation']\nfor folder in folders:\n  paths=Path(home+'/'+folder)\n  paths.mkdir(parents=True,exist_ok=True)\n  \n  ###############################\n  # END OF DIRECTORY CREATION #",
  "history_output" : "",
  "history_begin_time" : 1663783470821,
  "history_end_time" : 1663783472003,
  "history_notes" : null,
  "history_process" : "9xdvh6",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b620anzpshe",
  "history_input" : "# get hourly CMAQ data into csv for prediction\n\nfrom cmaq_ai_utils import *\n\n# end_date = datetime.today()\n# base = end_date - timedelta(days=2)\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\ndays = get_days_list(sdate, edate)\n\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntest_folder = f\"{cmaq_folder}/testing_input_hourly/\"\ncreate_and_clean_folder(test_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value<12:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    print(\"df_cmaq.variables['O3'] shape: \", df_cmaq.variables['O3'].shape)\n    print(\"df_cmaq.variables['O3'][:] shape: \", df_cmaq.variables['O3'][:].shape)\n    print(\"df_cmaq.variables['O3'][:].values[k, 0].shape\", df_cmaq.variables['O3'][:].values[k, 0].shape)\n    # CMAQ data\n    # O3 variable\n    o3=df_cmaq.variables['O3'][:].values[k, 0]\n    cmaq_O3=list(np.ravel(o3).transpose())\n    print(\"o3 shape: \", o3.shape)\n    print(\"cmaq_O3 shape: \", np.ravel(o3).transpose().shape)\n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k, 0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k, 0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k, 0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k, 0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k, 0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k, 0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k, 0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k, 0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k, 0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k, 0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k, 0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    print(\"lat shape\", lat.shape)\n    lat_flt=np.ravel(lat)\n    LAT=lat_flt #np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=lon_flt #np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    print(f'Saving file: test_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(f'{test_folder}/test_data_{day}_{turn_2_digits(real_hour_value)}.csv',index=False)\n\nprint('Done with preparing testing data!')",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/b620anzpshe/processing_test_data.py\", line 16, in <module>\n    create_and_clean_folder(test_folder)\n  File \"/Users/joe/gw-workspace/b620anzpshe/cmaq_ai_utils.py\", line 35, in create_and_clean_folder\n    os.makedirs(folder_path, exist_ok=True)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 215, in makedirs\n    makedirs(head, exist_ok=exist_ok)\n  [Previous line repeated 1 more time]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/os.py\", line 225, in makedirs\n    mkdir(name, mode)\nOSError: [Errno 30] Read-only file system: '/groups'\n",
  "history_begin_time" : 1663783486155,
  "history_end_time" : 1663783487655,
  "history_notes" : null,
  "history_process" : "ex3vh9",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o8jub3ujz1d",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/o8jub3ujz1d/test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 294, in concat\n    op = _Concatenator(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 351, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1663783489634,
  "history_end_time" : 1663783491101,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8rt3c3hlvbf",
  "history_input" : "#!/bin/bash\n# generate images and gif from the NetCDF files\n\ncmaq_folder=\"/groups/ESS/zsun/cmaq\"\n#cmaq_folder=\"/Users/uhhmed/localCMAQ\"\nmkdir $cmaq_folder\"/plots\"\nrm $cmaq_folder/plots/* # clean everything first\n\n# echo $(date -d '2 day ago' '+%Y%m%d')\n# Setting env variables\n#export YYYYMMDD_POST=$(date -d '2 day ago' '+%Y%m%d') #This needs to be auto date `date -d \"-2 day ${1}\" +%Y%m%d`\nexport YYYYMMDD_POST='20220805'\n#export stdate_post=$(date -d '2 day ago' '+%Y-%m-%d') #This needs to be auto date\nexport stdate_post='2022-08-05'\n#export eddate_post=$(date -d '1 day ago' '+%Y-%m-%d') #This needs to be auto date\nexport eddate_post='2022-08-06'\n\n#export stdate_file=$(date -d '2 day ago' '+%Y%m%d') #This needs to be auto date\nexport stdate_file='20220805'\n#export eddate_file=$(date -d '1 day ago' '+%Y%m%d') #This needs to be auto date\nexport eddate_file='20220806'\n\n\nexport postdata_dir=$cmaq_folder\"/prediction_nc_files\"\n# export mcip_dir=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km\"\nexport mcip_dir=$cmaq_folder\"/GRIDCRO2D\"\nexport dir_graph=$cmaq_folder\"/plots\"\n\n# module load ncl\n\nrm $cmaq_folder/geoweaver_plot_daily_O3.ncl\ncat <<EOF >> $cmaq_folder/geoweaver_plot_daily_O3.ncl\nload \"/opt/anaconda3/envs/ncl_stable/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/anaconda3/envs/ncl_stable/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/anaconda3/envs/ncl_stable/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\n\ndate = getenv(\"YYYYMMDD_POST\")\nd1 = getenv(\"stdate_post\")\nd2 = getenv(\"eddate_post\")\n\ndFile1 = getenv(\"stdate_file\")\ndFile2 = getenv(\"eddate_file\")\n\n;print(\"Passed Date: \"+date)\n\n;aconc_dir = getenv(\"postdata_dir\")\ngrid_dir = getenv(\"mcip_dir\")\nplot_dir = getenv(\"dir_graph\")\n\nprint(\"/groups/ESS/aalnaim/cmaq/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_20220805_ML_extracted.nc\")\ncdf_file1 = addfile(\"/Users/uhhmed/localCMAQ/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_20220805_ML_extracted.nc\",\"r\")\ncdf_file= addfile(grid_dir+\"/GRIDCRO2D_\"+date+\".nc\",\"r\")\n\nptime = (/\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"00\",\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\"/)\n\ntime = cdf_file1->TFLAG(:,0,:)\no3 = cdf_file1->O3(:,:,:) ;ppb\n;pm25 = cdf_file1->PM25_TOT(:,0,:,:)\n\n\nnt = dimsizes(o3(:,0,0))\nny = dimsizes(o3(0,:,0))\nnx = dimsizes(o3(0,0,:))\n\nprint(nt+\" \"+ny+\" \"+nx)\nprint(max(o3))\nprint(min(o3))\nprint(avg(o3))\n\n;print(max(pm25))\n;print(min(pm25))\n;print(avg(pm25))\n\n;print(time)\n\nlat = cdf_file->LAT(0,0,:,:)\nlon = cdf_file->LON(0,0,:,:)\n\no3@lat2d = lat\no3@lon2d = lon\n\nres = True\nres@gsnMaximize = True                ; maximize pot in frame\nres@gsnFrame = False               ; don't advance frame\nres@gsnDraw = False\n;res@gsnSpreadColors = True\nres@lbLabelAutoStride = True\n;res@lbBoxLinesOn = False\nres@pmLabelBarHeightF = 0.1\nres@pmLabelBarWidthF = 0.5\nres@cnFillOn=True\n;res@cnMonoFillPattern=True\n;res@cnMonoLineColor=True\nres@cnLinesOn=False\n;res@pmLabelBarDisplayMode=\"never\"\nres@gsnLeftString  = \"\";\nres@gsnRightString = \"\"\n\nres@mpLimitMode = \"LatLon\"\nres@mpMinLonF = -120 ;min(lon)+0.2\nres@mpMaxLonF = -70 ;max(lon)-0.2\nres@mpMinLatF = 25 ;min(lat)+0.05\nres@mpMaxLatF = 50 ;max(lat)-0.05\nres@mpDataBaseVersion = \"MediumRes\"\n;res@tiMainString = times(it)\nres@mpDataBaseVersion       = \"MediumRes\"\nres@mpDataSetName           = \"Earth..4\"\nres@mpAreaMaskingOn         = True\nres@mpOutlineBoundarySets = \"GeophysicalAndUSStates\"\nres@mpOutlineSpecifiers=\"United States : States\"\nres@mpLandFillColor         = \"white\"\nres@mpInlandWaterFillColor  = \"white\"\nres@mpOceanFillColor        = \"white\"\nres@mpGeophysicalLineColor    = \"Black\"\nres@mpGeophysicalLineThicknessF = 1.5\n\n;res@gsnSpreadColors         = True\nres@lbLabelAutoStride       = True\nres@lbLabelFont             = 25\nres@tiXAxisFont             = 25\nres@pmTickMarkDisplayMode   = \"Always\"\nres@tmXBLabelFont           = 25\nres@tmXBLabelFontHeightF    = 0.013\nres@tmXBLabelDeltaF         = -0.5\nres@tmYLLabelFont           = 25\nres@tmYLLabelFontHeightF    = 0.013\nres@tmXBLabelDeltaF         = -0.5\nres@tmXTLabelsOn            = False\nres@tmXTLabelFont           = 25\nres@tmXTLabelFontHeightF    = 0.013\nres@tmYRLabelsOn            = False\nres@tmYRLabelFont           = 25\nres@tmYRLabelFontHeightF    = 0.013\n\n\nres@mpProjection           = \"LambertConformal\" ;\"CylindricalEquidistant\"\nres@mpLambertParallel1F    = 33.\nres@mpLambertParallel2F    = 45.\nres@mpLambertMeridianF     = -98.\n\nres@cnLevelSelectionMode = \"ManualLevels\"\nres@cnMinLevelValF          = 0.\nres@cnMaxLevelValF          = 80\nres@cnLevelSpacingF         = 4\n\nres@txFont   = \"times-roman\"\nres@tiMainFont   = \"times-roman\"\n\ndo it = 0, nt-1\n  if (it .lt. 12) then\n    pdate=d1\n  else\n    pdate=d2\n  end if\n\n  pname=plot_dir+\"/testPlot_\"+pdate+\"_\"+ptime(it)\n  wks = gsn_open_wks(\"png\",pname)\n  gsn_define_colormap(wks, \"WhiteBlueGreenYellowRed\")\n\n  res@tiMainString = pdate+\" \"+ptime(it)+\" UTC O~B~3~N~ Forecast (ppbV)\"\n  plot = gsn_csm_contour_map(wks,o3(it,:,:),res)\n  draw(plot)\n  frame(wks)\n  delete(wks)\n  system(\"composite -geometry 100x70+900+900 /Users/uhhmed/localCMAQ/mason-logo-green.png \"+pname+\".png \"+pname+\".png\")\n  print(\"Saved: \"+pname+\".png\")\nend do\ndelete(res)\n\nend\nEOF\n\n\nsource activate ncl_stable && ncl $cmaq_folder/geoweaver_plot_daily_O3.ncl\n\n# convert -delay 100 *.png 20220613_20220614.gif\nconvert -delay 100 $cmaq_folder/plots/testPlot*.png $cmaq_folder/plots/\"Map_\"$YYYYMMDD_POST.gif\n\nif [ $? -eq 0 ]; then\n    echo \"Generating images/gif Completed Successfully\"\nelse\n    echo \"Generating images/gif Failed!\"\nfi\n",
  "history_output" : "mkdir: /groups/ESS/zsun/cmaq: No such file or directory\nrm: /groups/ESS/zsun/cmaq/plots/*: No such file or directory\nrm: /groups/ESS/zsun/cmaq/geoweaver_plot_daily_O3.ncl: No such file or directory\n/Users/joe/gw-workspace/8rt3c3hlvbf/gw-wB3v9thLphSxeLgJX96b3YsH4i-8rt3c3hlvbf.sh: line 32: /groups/ESS/zsun/cmaq/geoweaver_plot_daily_O3.ncl: No such file or directory\nCould not find conda environment: ncl_stable\nYou can list all discoverable environments with `conda info --envs`.\n/Users/joe/gw-workspace/8rt3c3hlvbf/gw-wB3v9thLphSxeLgJX96b3YsH4i-8rt3c3hlvbf.sh: line 183: convert: command not found\nGenerating images/gif Failed!\n",
  "history_begin_time" : 1663783502493,
  "history_end_time" : 1663783503906,
  "history_notes" : null,
  "history_process" : "iicy7w",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3t7yq6bzwry",
  "history_input" : "#!/bin/bash\n# evaluate the prediction accuracy\n\ncmaq_folder=\"/groups/ESS/zsun/cmaq\"\nmkdir -p $cmaq_folder/results/\nchmod +x $cmaq_folder/results/ -R\nrm $cmaq_folder/results/* # clean everything first\n# Setting env variables\n# export YYYYMMDD_POST=$(date -d '2 day ago' '+%Y%m%d')\n# export stdate_file=$(date -d '2 day ago' '+%Y%m%d') #This needs to be auto date\n# export eddate_file=$(date -d '1 day ago' '+%Y%m%d') #This needs to be auto date\nexport YYYYMMDD_POST='20220805'\nexport stdate_file='20220805'\nexport eddate_file='20220806'\n\nexport wfname=$cmaq_folder\"/results/geoweaver_evalution_\"$YYYYMMDD_POST\"_results.txt\"\n\nexport obs_dir_NCL=\"/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X\"\nexport ofname=\"/AQF5X_Hourly_\"\n\nexport postdata_dir=$cmaq_folder\"/prediction_nc_files/\"\n\nexport mfname=\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"$stdate_file\"_ML_extracted.nc\"\n\nexport grid_fname=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/GRIDCRO2D_\"$YYYYMMDD_POST\".nc\" #This needs to be auto date\n\nexport dx=12000\n\nmodule load ncl\n\nrm $cmaq_folder/geoweaver_eva_daily_O3.ncl\n\ncat <<EOF >> $cmaq_folder/geoweaver_eva_daily_O3.ncl\n\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\nsdate=getenv(\"YYYYMMDD_POST\")\nwfname=getenv(\"wfname\")\nobs_dir=getenv(\"obs_dir_NCL\")\nofname=getenv(\"ofname\")\nmod_dir=getenv(\"postdata_dir\")\nmfname=getenv(\"mfname\")\ndkm=tofloat(getenv(\"dx\"))\ngrid_fname=(getenv(\"grid_fname\"))\n\nmaxdist=dkm/90000.0*1.414\nmaxarea=0.25\nthd=70\n\n;-----read model lat lon------\n;read lat lon\nf1 = addfile(grid_fname,\"r\")\nmlat = f1->LAT(0,0,:,:)\nmlon = f1->LON(0,0,:,:)\ndelete(f1)\nmlat1d = ndtooned(mlat)\nmlon1d = ndtooned(mlon)\ndelete([/mlat,mlon/])\n\n;-----read cmaq results-----\nf2 = addfile(mod_dir+mfname,\"r\")\nmO3 = f2->O3(:,:,:) ;ppb\n\n\nnt = dimsizes(mO3(:,0,0))\nny = dimsizes(mO3(0,:,0))\nnx = dimsizes(mO3(0,0,:))\n\nm8O3 = new((/17,ny,nx/),\"double\")\nm8maxO3 = new((/ny,nx/),\"double\")\n\ndo ih=0,16\n  m8O3(ih,:,:)=dim_avg_n(mO3(ih:ih+7,:,:),0)\nend do\nm8maxO3 = dim_max_n(m8O3,0) ;type double\nmO31d_d=ndtooned(m8maxO3) ; type double\nmO31d=tofloat(mO31d_d)\n\ndelete([/f2,mO3,m8O3,m8maxO3/])\n\n;-----read obs-----\nsyyyy1=str_get_cols(sdate,0,3)\nsmm1=str_get_cols(sdate,4,5)\nsdd1=str_get_cols(sdate,6,7)\n\nymd=jul2greg(greg2jul(tointeger(syyyy1),tointeger(smm1),tointeger(sdd1),-1)+1)\nsyyyy2=tostring_with_format(ymd(0),\"%0.4i\")\nsmm2=tostring_with_format(ymd(1),\"%0.2i\")\nsdd2=tostring_with_format(ymd(2),\"%0.2i\")\n\ntolat=(/-999.0/) ;set the first data to 0\ntolon=tolat\ntoO3=tolat\n\ndo ih=12,35\n  if (ih.lt.24) then\n    shh=tostring_with_format(ih,\"%0.2i\")\n    syyyy=syyyy1\n    smm=smm1\n    sdd=sdd1\n  else\n    shh=tostring_with_format(ih-24,\"%0.2i\")\n    syyyy=syyyy2\n    smm=smm2\n    sdd=sdd2\n  end if\n  data=asciiread(obs_dir+ofname+syyyy+smm+sdd+shh+\".dat\",-1,\"string\")\n  xx=array_append_record(tolat,stringtofloat(str_get_field(data(1::), 2,\",\")),0)\n  yy=array_append_record(tolon,stringtofloat(str_get_field(data(1::), 3,\",\")),0)\n  zz=array_append_record(toO3,stringtofloat(str_get_field(data(1::), 4,\",\")),0)\n  delete([/tolat,tolon,toO3/])\n  tolat=xx\n  tolon=yy\n  toO3=zz\n  delete([/xx,yy,zz/])\n  delete(data)\nend do\n\ntoO3@_FillValue = -999.0\n\n;-----calculate max ave 8 hour o3-----\noflag=tolat*0+1\naa=ind((oflag.gt.0).and.(toO3.ge.0))\nii=0\nprint(\"8h start\")\nif (any(ismissing(aa))) then\n  iflag=0\nelse\n  iflag=1\n  olat=(/tolat(aa(0))/)\n  olon=(/tolon(aa(0))/)\n  oO3=(/-999.0/)\n  o8O3 = new(17,\"float\")\n  o8O3 = -999.0\nend if\ndelete(aa)\ndo while (iflag.gt.0)\n  aa=ind((tolat.eq.olat(ii)).and.(tolon.eq.olon(ii)).and.(toO3.ge.0))\n  oflag(aa)=0\n  if (dimsizes(aa).eq.24) then  ; calculate 24 h, so calculate 8hr ozone here\n    do ih = 0, 16\n      o8O3(ih) = avg(toO3(aa(ih:ih+7)))\n    end do\n    oO3(ii)=max(o8O3)\n  end if\n  o8O3 = -999.0\n  delete(aa)\n  aa=ind((oflag.gt.0).and.(toO3.ge.0))\n  if (any(ismissing(aa))) then\n    iflag=0\n  else\n    xx=array_append_record(olat,(/tolat(aa(0))/),0)\n    yy=array_append_record(olon,(/tolon(aa(0))/),0)\n    zz=array_append_record(oO3,(/-999.0/),0)\n    delete([/olat,olon,oO3/])\n    olat=xx\n    olon=yy\n    oO3=zz\n    delete([/xx,yy,zz/])\n    ii=ii+1\n  end if\n  delete(aa)\nend do\nprint(\"obs 8hour max end\")\naa=ind(oO3.ge.0)\nnobs=dimsizes(aa)\nolat24=olat(aa)\nolon24=olon(aa)\noO324=oO3(aa)\nprint(\"TYPE of oO324: \"+typeof(oO324))\ndelete([/aa,olat,olon,oO3/])\nmO324=oO324*0-999.0\nprint(\"TYPE of mO324: \"+typeof(mO324))\nprint(\"TYPE of mO31d: \"+typeof(mO31d))\nareaa=oO324*0-999.0\nareab=areaa\naread=areaa\n\n;-----find model point-----\ndo in=0,nobs-1\n  dis=sqrt((mlat1d-olat24(in))^2+(mlon1d-olon24(in))^2)\n  aa=minind(dis)\n ;print(in+\" \"+aa)\n  if (dis(aa).lt.maxdist) then\n    mO324(in)=mO31d(aa)\n    cc=ind((mlat1d.ge.(olat24(in)-maxarea)).and.(mlat1d.le.(olat24(in)+maxarea)).and.\\\n           (mlon1d.ge.(olon24(in)-maxarea)).and.(mlon1d.le.(olon24(in)+maxarea)))\n    areaa(in)=0\n    areab(in)=0\n    if (oO324(in).ge.thd) then\n      aread(in)=0\n      if (max(mO31d(cc)).ge.thd) then\n        areab(in)=1\n      else\n        aread(in)=1\n      end if\n    else\n      bb=ind((olat24.ge.(olat24(in)-maxarea)).and.(olat24.le.(olat24(in)+maxarea)).and.\\\n             (olon24.ge.(olon24(in)-maxarea)).and.(olon24.le.(olon24(in)+maxarea)))\n      if (max(mO31d(aa)).ge.thd) then\n        if (max(oO324(bb)).ge.thd) then\n          areaa(in)=0\n        else\n          areaa(in)=1\n        end if\n      else\n        areaa(in)=0\n      end if\n      delete(bb)\n    end if\n    delete(cc)\n  end if\n  delete(aa)\nend do\n\n;-----cal rmse corr nme nmb me mb-----\ntt=ind((mO324.ge.0).and.(oO324.ge.0))\n\nif (any(ismissing(tt))) then\n  rmse=-999.0\n  corr=-999.0\n  nmb=-999.0\n  nme=-999.0\n  me=-999.0\n  mb=-999.0\nelse\n  rmse=dim_rmsd_n(oO324(tt),mO324(tt),0)\n  corr=esccr(oO324(tt),mO324(tt),0)\n  nmb=sum((mO324(tt)-oO324(tt)))/sum(oO324(tt))\n  nme=sum(abs(oO324(tt)-mO324(tt)))/sum(oO324(tt))\n  me=avg(abs(oO324(tt)-mO324(tt)))\n  mb=avg((mO324(tt)-oO324(tt)))\nend if\n;-----cal ah afar-----\naa=ind((areaa+areab).gt.0)\nbb=ind((aread+areab).gt.0)\nif (any(ismissing(aa))) then\n  afar=0.\nelse\n  afar=tofloat(sum(areaa(aa)))/tofloat(sum(areab(aa))+sum(areaa(aa)))*100\nend if\ndelete(aa)\nif (any(ismissing(bb))) then\n  ah=-999.0\nelse\n  ah=tofloat(sum(areab(bb)))/tofloat(sum(areab(bb))+sum(aread(bb)))*100\nend if\ndelete(bb)\nwrite_table(wfname,\"a\",[/sdate,dimsizes(tt),avg(oO324(tt)),avg(mO324(tt)),rmse,corr,nmb,nme,mb,me,ah,afar/],\\\n            \"%s,%i,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f\")\ndelete(tt)\nend\n\nEOF\n\n\nncl $cmaq_folder/geoweaver_eva_daily_O3.ncl\n\nif [ $? -eq 0 ]; then\n    echo \"Evaluation Completed Successfully\"\n    cat $wfname\nelse\n    echo \"Evaluation Failed!\"\nfi\n",
  "history_output" : "mkdir: /groups: Read-only file system\nchmod: /groups/ESS/zsun/cmaq/results/: No such file or directory\nchmod: -R: No such file or directory\nrm: /groups/ESS/zsun/cmaq/results/*: No such file or directory\n/Users/joe/gw-workspace/3t7yq6bzwry/gw-wB3v9thLphSxeLgJX96b3YsH4i-3t7yq6bzwry.sh: line 29: module: command not found\nrm: /groups/ESS/zsun/cmaq/geoweaver_eva_daily_O3.ncl: No such file or directory\n/Users/joe/gw-workspace/3t7yq6bzwry/gw-wB3v9thLphSxeLgJX96b3YsH4i-3t7yq6bzwry.sh: line 33: /groups/ESS/zsun/cmaq/geoweaver_eva_daily_O3.ncl: No such file or directory\n/Users/joe/gw-workspace/3t7yq6bzwry/gw-wB3v9thLphSxeLgJX96b3YsH4i-3t7yq6bzwry.sh: line 264: ncl: command not found\nEvaluation Failed!\n",
  "history_begin_time" : 1663783504719,
  "history_end_time" : 1663783505947,
  "history_notes" : null,
  "history_process" : "fsk7f2",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ko14l77iy12",
  "history_input" : "#!/bin/bash\n# generate images and gif from the prediction NetCDF files and overlay the AirNow station observation on the top\n\ncmaq_folder=\"/groups/ESS/zsun/cmaq\"\nmkdir $cmaq_folder\"/plots\"\n# Setting env variables\n# export YYYYMMDD_POST=$(date -d '2 day ago' '+%Y%m%d')\n# export stdate_post=$(date -d '2 day ago' '+%Y-%m-%d') \n# export eddate_post=$(date -d '1 day ago' '+%Y-%m-%d')\n\n# export stdate_file=$(date -d '2 day ago' '+%Y%m%d') \n# export eddate_file=$(date -d '1 day ago' '+%Y%m%d') \nexport YYYYMMDD_POST='20220805'\nexport stdate_post='2022-08-05'\nexport eddate_post='2022-08-06'\nexport stdate_file='20220805'\nexport eddate_file='20220806'\n\n\nexport postdata_dir=$cmaq_folder\"/prediction_nc_files\"\nexport mcip_dir=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km\"\nexport graph_dir=\"/groups/ESS/aalnaim/cmaq/plots\"\n\nexport obs_dir_NCL=\"/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X\"\n\nmodule load ncl\n\nrm $cmaq_folder/geoweaver_plot_daily_O3_Airnow.ncl\ncat <<EOF >>$cmaq_folder/geoweaver_plot_daily_O3_Airnow.ncl\nload \"/opt/anaconda3/envs/ncl_stable/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/anaconda3/envs/ncl_stable/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/anaconda3/envs/ncl_stable/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\n\ndate = getenv(\"YYYYMMDD_POST\") \nd1 = getenv(\"stdate_post\") \nd2 = getenv(\"eddate_post\") \n\ndFile1 = getenv(\"stdate_file\")\ndFile2 = getenv(\"eddate_file\")\n\nobs_dir = getenv(\"obs_dir_NCL\")\nplot_dir = getenv(\"graph_dir\") \n\nhr=new(24,\"string\")\nhr=(/\"00\",\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"/)\n\nprint(plot_dir)\naconc_dir = getenv(\"postdata_dir\") \ngrid_dir = getenv(\"mcip_dir\")\n\nprint(aconc_dir+\"/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+dFile1+\"_ML_extracted.nc\")\n\ncdf_file1 = addfile(aconc_dir+\"/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+dFile1+\"_ML_extracted.nc\",\"r\")\ncdf_file= addfile(grid_dir+\"/GRIDCRO2D_\"+date+\".nc\",\"r\")\ncdf_file2= addfile(grid_dir+\"/METCRO2D_\"+date+\".nc\",\"r\")\n\ntime = cdf_file1->TFLAG(:,0,:)\no3 = cdf_file1->O3(:,:,:) ;ppb\nwspd10=cdf_file2->WSPD10(:,0,:,:)\nwdir10=cdf_file2->WDIR10(:,0,:,:)\n\ntemp = cdf_file2->TEMP2\n\nnt = dimsizes(o3(:,0,0))\nny = dimsizes(o3(0,:,0))\nnx = dimsizes(o3(0,0,:))\n\nprint(max(temp))\nprint(min(temp))\nprint(avg(temp))\n\n\n\nprint(nt+\" \"+ny+\" \"+nx)\nprint(max(o3))\nprint(min(o3))\nprint(avg(o3))\n\nlat = cdf_file->LAT(0,0,:,:)\nlon = cdf_file->LON(0,0,:,:)\n\no3@lat2d = lat\no3@lon2d = lon\no3@unit = \"ppbv\"\n\nUV10=wind_component(wspd10,wdir10,0)\nUV10@lat2d = lat\nUV10@lon2d = lon\n\n\nres = True\nres@gsnMaximize = True                ; maximize pot in frame\nres@gsnFrame = False               ; dont advance frame\nres@gsnDraw = False\nres@gsnLeftString  = \"\"\nres@gsnRightString = \"\"\nres@txFont   = \"times-roman\"\nres@tiMainFont   = \"times-roman\"\n;res@tiMainFontHeightF = 0.02\n;res@vpWidthF        = 0.7\n;res@vpHeightF       = 0.7\n\n;;set map;;\nmpres                             = res\nmpres@mpLimitMode = \"LatLon\"\nmpres@mpDataSetName               = \"Earth..4\"\nmpres@mpDataBaseVersion           = \"MediumRes\"\nmpres@mpOutlineOn                 = True\nmpres@mpGeophysicalLineThicknessF = 1.5\nmpres@mpFillDrawOrder             = \"PostDraw\"\nmpres@mpFillOn                    = False\nmpres@mpAreaMaskingOn         = True\nmpres@mpOutlineBoundarySets = \"GeophysicalAndUSStates\"\nmpres@mpOutlineSpecifiers         = \"United States:States\"\nmpres@mpProjection           = \"LambertConformal\"\nmpres@mpLambertParallel1F    = 33.\nmpres@mpLambertParallel2F    = 45.\nmpres@mpLambertMeridianF     = -98.\nmpres@mpMinLonF = -120 ;min(lon)+0.2\nmpres@mpMaxLonF = -70 ;max(lon)-0.2\nmpres@mpMinLatF = 25 ;min(lat)+0.05\nmpres@mpMaxLatF = 50 ;max(lat)-0.05\nmpres@pmTickMarkDisplayMode   = \"Always\"\nmpres@mpLandFillColor         = \"white\"\nmpres@mpInlandWaterFillColor  = \"white\"\nmpres@mpOceanFillColor        = \"white\"\nmpres@mpGeophysicalLineColor    = \"Black\"\n\n;mpres@lbLabelAutoStride       = True\nmpres@tiXAxisFont             = 25\nmpres@pmTickMarkDisplayMode   = \"Always\"\nmpres@tmXBLabelFont           = 25\nmpres@tmXBLabelFontHeightF    = 0.013\nmpres@tmXBLabelDeltaF         = -0.5\nmpres@tmYLLabelFont           = 25\nmpres@tmYLLabelFontHeightF    = 0.013\nmpres@tmXBLabelDeltaF         = -0.5\nmpres@tmXTLabelsOn            = False\nmpres@tmXTLabelFont           = 25\nmpres@tmXTLabelFontHeightF    = 0.013\nmpres@tmYRLabelsOn            = False\nmpres@tmYRLabelFont           = 25\nmpres@tmYRLabelFontHeightF    = 0.013\n\n;;set contour;;\ncnres                         = res\ncnres@cnFillDrawOrder         = \"PreDraw\"\ncnres@cnFillOn                = True\ncnres@cnLinesOn               = False\ncnres@cnLineLabelsOn          = False\ncnres@lbLabelFont             = 25\ncnres@lbLabelFontHeightF      = 0.013\ncnres@tiXAxisFont             = 25\ncnres@pmLabelBarWidthF        = 0.5\ncnres@pmLabelBarHeightF       = 0.1\n;cnres@pmLabelBarOrthogonalPosF = -0.02\ncnres@lbLabelAutoStride       = True\n\n;set vector;;\nres_vc                        = res\nres_vc@vcGlyphStyle           = \"LineArrow\"\nres_vc@vcLineArrowThicknessF  = 3\nres_vc@vcMinDistanceF         = 0.03\nres_vc@vcRefLengthF           = 0.03\nres_vc@vcRefAnnoOn            = True\nres_vc@vcRefMagnitudeF           = 16\nres_vc@vcRefAnnoString1          = \"16m/s\"\nres_vc@vcRefAnnoSide             = \"Top\"\nres_vc@vcRefAnnoString2On        = False\nres_vc@vcRefAnnoPerimOn          = False\nres_vc@vcRefAnnoOrthogonalPosF   = -0.02\nres_vc@vcRefAnnoParallelPosF     = 0.999\n;res_vc@vcRefAnnoBackgroundColor = \"White\"\nres_vc@vcVectorDrawOrder         = \"PostDraw\"\n\ndo it = 0, nt-1\n  if (it .lt. 12) then\n    pdate=d1\n  else\n    pdate=d2\n  end if\n\n  ;print(time(it,0)+\" \"+time(it,1))\n  rundate = yyyyddd_to_yyyymmdd( time(it,0) )\n  runtime = hr( tointeger(time(it,1)/10000) )\n\n  site = readAsciiTable(obs_dir+\"/AQF5X_Hourly_\"+rundate+runtime+\".dat\",1,\"string\",1)\n  nrows = dimsizes(site)\n  sitename = str_get_field(site,1,\",\")\n  sitelat = stringtofloat(str_get_field(site,2,\",\"))\n  sitelon = stringtofloat(str_get_field(site,3,\",\"))\n  O3_obs = stringtofloat(str_get_field(site,4,\",\"))\n\n  obslon = sitelon(:,0)\n  obslat = sitelat(:,0)\n  obsO3 = O3_obs(:,0)\n\n  npts = nrows(0)\n\n  obsO3@_FillValue = -999.\n\n;--- levels for dividing\n  levels_O3  = ispan(0,80,4)\n\n  nlevels = dimsizes(levels_O3)\n\n  colors  = span_color_rgba(\"WhiteBlueGreenYellowRed\",nlevels+1)\n\n  num_distinct_markers = nlevels+1        ; number of distinct markers\n  lat_O3 = new((/num_distinct_markers,npts/),float)\n  lon_O3 = new((/num_distinct_markers,npts/),float)\n  lat_O3 = -999\n  lon_O3 = -999\n\n\n;\n; Group the points according to which range they fall in. At the\n; same time, create the label that we will use later in the labelbar\n;\n  do i = 0, num_distinct_markers-1\n    if (i.eq.0) then\n      indexes_O3 = ind(obsO3(:).lt.levels_O3(0))\n    end if\n    if (i.eq.num_distinct_markers-1) then\n      indexes_O3 = ind(obsO3(:).ge.max(levels_O3))\n    end if\n    if (i.gt.0.and.i.lt.num_distinct_markers-1) then\n      indexes_O3 = ind(obsO3(:).ge.levels_O3(i-1).and.obsO3(:).lt.levels_O3(i))\n    end if\n\n;\n; Now that we have the set of indexes whose values fall within\n; the given range, take the corresponding lat/lon values and store\n; them, so later we can color this set of markers with the appropriate\n; color.\n;\n    if (.not.any(ismissing(indexes_O3))) then\n      npts_range_O3 = dimsizes(indexes_O3)   ; # of points in this range.\n\n      lat_O3(i,0:npts_range_O3-1) = obslat(indexes_O3)\n      lon_O3(i,0:npts_range_O3-1) = obslon(indexes_O3)\n  ;print(\"O3: \"+npts_range_O3)\n    end if\n\n\n    delete(indexes_O3)            ; Necessary b/c \"indexes\" may be a different\n  end do\n\n  lat_O3@_FillValue = -999\n  lon_O3@_FillValue = -999\n\n  gsres               = True\n  gsres@gsMarkerIndex = 16          ; Use filled dots for markers.\n\n  hollowres           = True\n  hollowres@gsMarkerIndex    = 4\n  hollowres@gsMarkerColor    = \"black\"\n  hollowres@gsMarkerSizeF    = 0.008\n\n;;;;;;;;;   Plot Ozone\n  pname=plot_dir+\"/OBS-FORECAST_O3_\"+rundate+runtime\n  wks = gsn_open_wks(\"png\",pname)\n  gsn_define_colormap(wks, \"WhiteBlueGreenYellowRed\")\n\n  pmid_O3 = new(num_distinct_markers,graphic)\n  hollow_O3 = new(num_distinct_markers,graphic)\n\n  cnres@tiMainString =  pdate+\" \"+runtime+\" UTC O~B~3~N~ (ppbV)\"\n  cnres@cnLevelSelectionMode = \"ManualLevels\"\n  cnres@cnMinLevelValF          = 0.\n  cnres@cnMaxLevelValF          = 80\n  cnres@cnLevelSpacingF         = 4\n\n  ;plot = gsn_csm_contour_map(wks,o3(it,:,:),res)\n  map = gsn_csm_map(wks,mpres)\n  contour = gsn_csm_contour(wks,o3(it,:,:),cnres)\n  vector  = gsn_csm_vector(wks,UV10(0,it,:,:),UV10(1,it,:,:),res_vc)\n  overlay(map,contour)\n  overlay(map,vector)\n\n  pmid = new(num_distinct_markers,graphic)\n  hollow = new(num_distinct_markers,graphic)\n  do i = 0, num_distinct_markers-1\n    if (.not.ismissing(lat_O3(i,0)))\n      gsres@gsMarkerColor      = colors(i,:)\n      gsres@gsMarkerSizeF      = 0.008\n      gsres@gsMarkerThicknessF = 1\n       pmid(i) = gsn_add_polymarker(wks,vector,lon_O3(i,:),lat_O3(i,:),gsres)\n       hollow(i) = gsn_add_polymarker(wks,vector,lon_O3(i,:),lat_O3(i,:),hollowres)\n    end if\n  end do\n\n  draw(map)\n  frame(wks)\n  delete(wks)\n  delete(pmid_O3)\n  delete(hollow_O3)\n  system(\"composite -geometry 100x70+900+900 mason-logo-green.png \"+pname+\".png \"+pname+\".png\")\n\n\n  delete(pmid)\n  delete(hollow)\n  delete(site)\n  delete(sitename)\n  delete(sitelat)\n  delete(sitelon)\n  delete(O3_obs)\n  delete(obslon)\n  delete(obslat)\n  delete(obsO3)\n  delete([/lon_O3,lat_O3/])\n\nend do\ndelete(res)\n\n;/\n\nend\nEOF\n\n\nncl $cmaq_folder/geoweaver_plot_daily_O3_Airnow.ncl\n\nconvert -delay 100 $cmaq_folder/plots/OBS*.png $cmaq_folder/plots/\"Airnow_\"$YYYYMMDD_POST.gif\n\nif [ $? -eq 0 ]; then\n    echo \"Generating AirNow images/gif Completed Successfully\"\n\techo \"Removing ncl file: geoweaver_plot_daily_O3_Airnow.ncl...\"\n\t#rm $cmaq_folder/geoweaver_plot_daily_O3_Airnow.ncl\nelse\n    echo \"Generating AirNow images/gif Failed!\"\n    echo \"Removing ncl file: geoweaver_plot_daily_O3_Airnow.ncl...\"\n\t#rm $cmaq_folder/geoweaver_plot_daily_O3_Airnow.ncl\nfi\n",
  "history_output" : "mkdir: /groups/ESS/zsun/cmaq: No such file or directory\n/Users/joe/gw-workspace/ko14l77iy12/gw-wB3v9thLphSxeLgJX96b3YsH4i-ko14l77iy12.sh: line 26: module: command not found\nrm: /groups/ESS/zsun/cmaq/geoweaver_plot_daily_O3_Airnow.ncl: No such file or directory\n/Users/joe/gw-workspace/ko14l77iy12/gw-wB3v9thLphSxeLgJX96b3YsH4i-ko14l77iy12.sh: line 29: /groups/ESS/zsun/cmaq/geoweaver_plot_daily_O3_Airnow.ncl: No such file or directory\n/Users/joe/gw-workspace/ko14l77iy12/gw-wB3v9thLphSxeLgJX96b3YsH4i-ko14l77iy12.sh: line 328: ncl: command not found\n/Users/joe/gw-workspace/ko14l77iy12/gw-wB3v9thLphSxeLgJX96b3YsH4i-ko14l77iy12.sh: line 330: convert: command not found\nGenerating AirNow images/gif Failed!\nRemoving ncl file: geoweaver_plot_daily_O3_Airnow.ncl...\n",
  "history_begin_time" : 1663783502319,
  "history_end_time" : 1663783503548,
  "history_notes" : null,
  "history_process" : "is1w3m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l4dec2jh39i",
  "history_input" : "# All the utility functions that most steps in CMAQ-AI need\n# this file should not contain any direct call of function\n# it should be dedicated to define functions or variables\n\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import date, datetime, timedelta\nimport matplotlib.pyplot as plt\n\n# home directory\nhome = str(Path.home())\ncmaq_folder = \"/groups/ESS/zsun/cmaq/\" # change if you want to use your own folder\n# cmaq_folder = \"/Users/uhhmed/localCMAQ\" # change if you want to use your own folder\n\ndef get_days_list(sdate, edate):\n  days=[]\n  \n  delta = edate - sdate       # as timedelta\n\n  for i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n  # add one more day\n  one_more_day = sdate + timedelta(days=delta.days + 1)\n  list_day=one_more_day.strftime('%Y%m%d')\n  days.append(list_day)\n  \n  return days\n\ndef create_and_clean_folder(folder_path):\n  os.makedirs(folder_path, exist_ok=True)\n  # clean all files inside the folder\n  for f in os.listdir(folder_path):\n    os.remove(os.path.join(folder_path, f))\n\ndef remove_file(file_path):\n  print(f'remove old files{file_path}')\n  if os.path.exists(file_path):\n    os.remove(file_path)\n    \ndef turn_2_digits(a):\n  return f\"{a:02}\"",
  "history_output" : "",
  "history_begin_time" : 1663783470346,
  "history_end_time" : 1663783472000,
  "history_notes" : null,
  "history_process" : "h76ld0",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "egpw3ac9j31",
  "history_input" : "# Write first python in Geoweaver# NASA GEOWEAVER\n# CMAQ-AI Model: Training Voting-XGBoost model\n\n# Importing necessary libraries\nimport pandas as pd\nimport sklearn\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost.sklearn import XGBRegressor\nimport pickle\nfrom cmaq_ai_utils import *\n\n# importing data\nfinal=pd.read_csv(f'{cmaq_folder}/training.csv')\nprint(final.head())\nfinal=final.dropna()\n#print(\"shape before: \", final.shape)\n#final = final.loc[(final['CMAQ12KM_O3(ppb)']-final['AirNOW_O3'])/final['AirNOW_O3']<0.05]\n#print(\"shape 1 after: \", final.shape)\n#final = final.loc[(final['CMAQ12KM_O3(ppb)']-final['AirNOW_O3'])/final['AirNOW_O3']>-0.05]\n#print(\"shape 2 after: \", final.shape)\n\nfinal['time_of_day'] = (final['hours'] % 24 + 4) // 4\n\n# Make coords even more coarse by rounding to closest multiple of 5 \n# (e.g., 40, 45, 85, 55)\nfinal['Latitude_ExtraCoarse'] = 0.1 * round(final['Latitude_x']/0.1)\nfinal['Longitude_ExtraCoarse'] = 0.1 * round(final['Longitude_x']/0.1)\n\n\n\ncreate_and_clean_folder(f\"{cmaq_folder}/models/\")\n\n# Processing training  data\nX = final.drop(['AirNOW_O3','Latitude_x','Longitude_x','CMAQ12KM_NO2(ppb)', 'CMAQ12KM_CO(ppm)', 'CMAQ_OC(ug/m3)', 'CO(moles/s)', 'PRSFC(Pa)', 'PBL(m)', 'TEMP2(K)','WSPD10(m/s)', 'WDIR10(degree)', 'RGRND(W/m2)', 'CFRAC', 'month', 'day', 'hours'],axis=1)\nprint(\"input shape:\", X.shape)\ny = final['AirNOW_O3']\n\nrf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n                      max_samples=None, min_impurity_decrease=0.0,\n                      min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      n_estimators=100, n_jobs=-1, oob_score=False,\n                      random_state=3086, verbose=0, warm_start=False)\n\nrf.fit(X, y)\n\n# save the model to disk\nfilename = f'{cmaq_folder}/models/rf_pycaret_o3_coarse_loc.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(rf, open(filename, 'wb'))",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/egpw3ac9j31/train_cmaq_directly_no_slurm.py\", line 13, in <module>\n    final=pd.read_csv(f'{cmaq_folder}/training.csv')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS/zsun/cmaq//training.csv'\n",
  "history_begin_time" : 1663783481770,
  "history_end_time" : 1663783484269,
  "history_notes" : null,
  "history_process" : "s6hbic",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "y2k5onu51bb",
  "history_input" : "{\"operation\":\"ShowResultMap\",\"params\":[{\"name\":\"FilePath\",\"value\":\"/groups/ESS/zsun/cmaq/plots/Map_20220810.gif\"}]}",
  "history_output" : "{\"ret\": \"failure\", \"reason\": \"/groups/ESS/zsun/cmaq/plots/Map_20220810.gif (No such file or directory)\"}",
  "history_begin_time" : 1663783505566,
  "history_end_time" : 1663783505588,
  "history_notes" : null,
  "history_process" : "pvzabv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ic5yunvxanb",
  "history_input" : "# use the trained model to predict on the testing data and save the results to prediction_rf.csv\n\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\nimport glob, os\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom cmaq_ai_utils import *\nfrom scipy import spatial\n\n# from geopy import distance\nfrom math import radians, cos, sin, asin, sqrt\nimport time\n\n\ndef match_closest_airnow_with_gridCell():\n  \"\"\"\n  Match all airnow stations to closest grid cell.\n  \"\"\"\n  print(\"Starting!\")\n  remove_file(f'{cmaq_folder}/updated_station_to_cell.csv')\n  testing_path = f'{cmaq_folder}/testing_input_hourly'\n  all_hourly_files = sorted(glob.glob(os.path.join(testing_path, \"test_data_*.csv\")))\n  print(\"reading stations csv\")\n  stations = pd.read_csv(f'{cmaq_folder}/AQF5X_Hourly_2022091304.dat', sep=', ', skiprows=1, names=['AQSID', 'Latitude', 'Longitude', 'OZONE(ppb)', 'NO2(ppb)', 'CO(ppm)', 'PM25(ug/m3)', 'SO2(ppb)', 'PM10(ug/m3)'])\n\n  # stations = stations.replace(',','', regex=True)\n  print(stations.columns)\n  print(stations[['Latitude', 'Longitude']])\n  station_locations = stations[['Latitude', 'Longitude']].astype(float).values\n  print(\"station_locations - \", station_locations)\n  print(\"station_locations.shape: \", station_locations.shape)\n  print(\"reading testing data csv\")\n\n  testing_df = pd.read_csv(all_hourly_files[0]) # just pick the first one to generate the mapping\n  print(testing_df['YYYYMMDDHH'].values[0])\n\n  closest_stations = []\n  cmaq_cell_array = []\n  final_mapping_array = []\n  for j, cmaq in testing_df.iterrows():\n    cmaq_location = [cmaq['Latitude'], cmaq['Longitude']]\n    cmaq_cell_array.append(cmaq_location)\n  \n  print(\"cmaq_cell_array.shape: \", len(cmaq_cell_array))\n  \n  for station_loc in station_locations:\n    distance,index = spatial.KDTree(cmaq_cell_array).query(station_loc)\n    if distance > 0.2:\n      continue\n    closest_cell = cmaq_cell_array[index]\n    new_row = [station_loc[0], station_loc[1], closest_cell[0], closest_cell[1]]\n    final_mapping_array.append(new_row)\n\n  print(\"final_mapping_array length: \", len(final_mapping_array))\n  closest = pd.DataFrame(final_mapping_array, columns=[\"Lat_airnow\", \"Lon_airnow\", \"Lat_cmaq\", \"Lon_cmaq\"])\n  #closest.drop_duplicates().reset_index(drop=True)\n  print(\"Saving fixed_station_cmaq_location.csv...\")\n  closest.to_csv(f'{cmaq_folder}/updated_station_to_cell.csv',index=False)\n\n  \n\ndef prepare_update_grid_cells_with_distance(station_distance=0.2):\n  \"\"\"\n  Get all grid cells within the specified distance around airnow stations\n  args: station_distance, default: 50km (0.2 degrees)\n  \"\"\"\n  print(\"Starting!\")\n  testing_path = f'{cmaq_folder}/testing_input_hourly'\n  all_hourly_files = sorted(glob.glob(os.path.join(testing_path, \"test_data_*.csv\")))\n  print(\"reading stations csv\")\n  airnow_obs_path = '/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X'\n  stations = pd.read_csv(f'{cmaq_folder}/station_cmaq_location.csv')\n  print(\"reading testing data csv\")\n\n  testing_df = pd.read_csv(all_hourly_files[0])\n  print(testing_df['YYYYMMDDHH'].values[0])\n  file_dateTime = testing_df['YYYYMMDDHH'].values[0]\n  print(\"copying testing_df to new_df\")\n  new_df = testing_df.copy()\n  new_df.drop(new_df.index, inplace=True)\n  print(testing_df.shape, new_df.shape)\n\n  for j, cmaq in testing_df.iterrows():\n    if j % 1000 == 0:\n  \t  print(\"Looping through: \", j)\n    for i, station in stations.iterrows():\n      #print(\"inner-Looping through: \", i)\n      airnow_stations = (station['Latitude_y'], station['Longitude_y'])\n      prediction_location = (cmaq['Latitude'], cmaq['Longitude'])\n        \n      if (station['Latitude_y'] < cmaq['Latitude'] + station_distance) and (station['Latitude_y'] > cmaq['Latitude'] - station_distance) and (station['Longitude_y'] < cmaq['Longitude'] + station_distance) and (station['Longitude_y'] > cmaq['Longitude'] - station_distance):\n        new_df.loc[j] = cmaq\n        break\n  new_df.to_csv(f'{cmaq_folder}/prediction_files/update_cell.csv',index=False)\n\ndef prepare_update_grid_cells_with_distance(station_distance=0.2):\n  \"\"\"\n  Get all grid cells within the specified distance around airnow stations\n  args: station_distance, default: 50km (0.2 degrees)\n  \"\"\"\n  print(\"Starting!\")\n  testing_path = f'{cmaq_folder}/testing_input_hourly'\n  all_hourly_files = sorted(glob.glob(os.path.join(testing_path, \"test_data_*.csv\")))\n  print(\"reading stations csv\")\n  stations = pd.read_csv(f'{cmaq_folder}/station_cmaq_location.csv')\n  print(\"reading testing data csv\")\n\n  testing_df = pd.read_csv(all_hourly_files[0])\n  print(testing_df['YYYYMMDDHH'].values[0])\n  file_dateTime = testing_df['YYYYMMDDHH'].values[0]\n  print(\"copying testing_df to new_df\")\n  new_df = testing_df.copy()\n  new_df.drop(new_df.index, inplace=True)\n  print(testing_df.shape, new_df.shape)\n\n  for j, cmaq in testing_df.iterrows():\n    if j % 1000 == 0:\n  \t  print(\"Looping through: \", j)\n    for i, station in stations.iterrows():\n      #print(\"inner-Looping through: \", i)\n      airnow_stations = (station['Latitude_y'], station['Longitude_y'])\n      prediction_location = (cmaq['Latitude'], cmaq['Longitude'])\n        \n      if (station['Latitude_y'] < cmaq['Latitude'] + station_distance) and (station['Latitude_y'] > cmaq['Latitude'] - station_distance) and (station['Longitude_y'] < cmaq['Longitude'] + station_distance) and (station['Longitude_y'] > cmaq['Longitude'] - station_distance):\n        new_df.loc[j] = cmaq\n        break\n  new_df.to_csv(f'{cmaq_folder}/prediction_files/update_cell.csv',index=False)\n  \n#prepare_update_grid_cells(0.2)\nmatch_closest_airnow_with_gridCell()",
  "history_output" : "/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n  return func(*args, **kwargs)\nStarting!\nremove old files/groups/ESS/zsun/cmaq//updated_station_to_cell.csv\nreading stations csv\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/ic5yunvxanb/prepare_update_cell_csv.py\", line 132, in <module>\n    match_closest_airnow_with_gridCell()\n  File \"/Users/joe/gw-workspace/ic5yunvxanb/prepare_update_cell_csv.py\", line 26, in match_closest_airnow_with_gridCell\n    stations = pd.read_csv(f'{cmaq_folder}/AQF5X_Hourly_2022091304.dat', sep=', ', skiprows=1, names=['AQSID', 'Latitude', 'Longitude', 'OZONE(ppb)', 'NO2(ppb)', 'CO(ppm)', 'PM25(ug/m3)', 'SO2(ppb)', 'PM10(ug/m3)'])\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/python_parser.py\", line 96, in __init__\n    self._open_handles(f, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/groups/ESS/zsun/cmaq//AQF5X_Hourly_2022091304.dat'\n",
  "history_begin_time" : 1663783470365,
  "history_end_time" : 1663783472730,
  "history_notes" : null,
  "history_process" : "8i9ptn",
  "host_id" : "100001",
  "indicator" : "Failed"
}]
