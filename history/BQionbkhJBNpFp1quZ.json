[{
  "history_id" : "6c25agqkanw",
  "history_input" : "from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nimport pandas as pd\ndf=pd.read_csv(\"/home/mislam25/vaccine.csv\")\n# Wordcloud with positive tweets\npositive_tweets = df['clean_text'][df[\"Sentiment\"] == 'POS']\nstop_words = [\"https\", \"co\", \"RT\"] + list(STOPWORDS)\npositive_wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords = stop_words).generate(str(positive_tweets))\nplt.figure()\nplt.title(\"Positive Tweets - Wordcloud\")\nplt.imshow(positive_wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.savefig('/home/mislam25/pos.png')\n \n# Wordcloud with negative tweets\nnegative_tweets = df['clean_text'][df[\"Sentiment\"] == 'NEG']\nstop_words = [\"https\", \"co\", \"RT\"] + list(STOPWORDS)\nnegative_wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords = stop_words).generate(str(negative_tweets))\nplt.figure()\nplt.title(\"Negative Tweets - Wordcloud\")\nplt.imshow(negative_wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.savefig('/home/mislam25/neg.png')",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'clean_text'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/mislam25/gw-workspace/6c25agqkanw/environment_setting.py\", line 6, in <module>\n    positive_tweets = df['clean_text'][df[\"Sentiment\"] == 'POS']\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3458, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n    raise KeyError(key) from err\nKeyError: 'clean_text'\n",
  "history_begin_time" : 1650388241629,
  "history_end_time" : 1650388313124,
  "history_notes" : null,
  "history_process" : "9xdvh6",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "k6wt3hlvdhb",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 9, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1650388332855,
  "history_end_time" : 1654318085485,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Stopped"
}]
