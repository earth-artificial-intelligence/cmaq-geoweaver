[{
  "history_id" : "b5aqg4xwu0u",
  "history_input" : "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndataset = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/prediction.csv')\n\nplt.rc('font', size=15)\nfig, ax = plt.subplots(figsize=(25, 4))\n\n# Specify how our lines should look\nax.plot(dataset.Date, dataset.prediction, color='tab:red',  label='Prediction')\nax.plot(dataset.Date, dataset.O3_AVG, color='tab:blue',\n        label='CMAQ')\n\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='tab:green',\n        label='AirNow',linestyle='--')\n\n# Same as above\nax.set_xlabel('Date',size=20)\nax.set_ylabel('O3 (ppbv)',size=20)\nax.set_title('February',fontsize=25)\nax.grid(True)\nplt.xticks(rotation=45)\nax.legend(loc='upper left')\nfig.savefig('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/pred_monthly.png')\n\n",
  "history_output" : "",
  "history_begin_time" : 1667525592304,
  "history_end_time" : 1667525593680,
  "history_notes" : null,
  "history_process" : "g00sya",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l6uk529jh98",
  "history_input" : "from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom numpy import mean\nfrom numpy import std\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\nfilename = f'/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\nmodels = pickle.load(open(filename, 'rb'))\n\n# evaluate a given model or set of models using cross-validation\ndef evaluate_model(model, X, y):\n    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n    return scores\n\n# Get the remaining rows after row 31 corresponding to the month of February as the testing set input.\nX = final[31:].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n# Get the remaining rows after row 31 corresponding to the month of February as the testing set target.\ny = final[31:]['AirNow_O3']\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in models:\n    scores = evaluate_model(model, X, y)\n    results.append(scores)\n    names.append(name)\n    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n    \n\n# plot model performance for comparison\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\nplt.boxplot(results, labels=names, showmeans=True)\nplt.suptitle(\"Voting-XGBoost\", size=16)\nplt.xlabel(\"XGBoost models\")\nplt.ylabel(\"neg_RMSE\")\nplt.grid()\n\nfig.savefig('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/boxPlot.png')",
  "history_output" : "Traceback (most recent call last):\n  File \"Kfold_eval_boxPlot.py\", line 13, in <module>\n    models = pickle.load(open(filename, 'rb'))\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\n",
  "history_begin_time" : 1667525594602,
  "history_end_time" : 1667525597616,
  "history_notes" : null,
  "history_process" : "tkwv1k",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bfa9w6nzol1",
  "history_input" : "from pyairnow.conv import aqi_to_concentration\nimport pandas as pd\nimport requests\nimport json\n\n\nlat = '32.047501'\nlon = '-110.773903'\nAPI_KEY = '9FF8FB8B-229C-424F-8882-3AF164DD8C17'\n\n# distance is used when no reporting area is associated with the latitude/longitude, \n# looks for an observation from a nearby reporting area within this distance (in miles).\ndistance = '50' \n\n# Construct a list of date string, each timed at midnight.\ndate_range_str = [date.strftime('%Y-%m-%dT00-0000') for date in pd.date_range('2021-01-01','2021-02-28')]\n\n# An empty list to save the O3 data returned.\nO3_data = []\nCO_data = []\nNO2_data = []\n\n# Loop through each date to intiate an API call for the duration specified above.\nfor dateStr in date_range_str:\n\n    # Construct URL to contact airnowapi.org and get the AQI (Air Quality Index) for our desired location.\n    url = f'https://www.airnowapi.org/aq/observation/latLong/historical/?format=application/json&latitude={lat}&longitude={lon}&date={dateStr}&distance={distance}&API_KEY={API_KEY}'\n\n    # Initiate the request to the API.\n    res = requests.get(url)\n    # Extract the AQI level for our location.\n    aqiData = json.loads(res.content)[0]['AQI']\n\n    # This function can be passed the AQI observations \n    # and return the corresponding O3 level in that area for the day.\n    O3_data.append(aqi_to_concentration(aqiData, 'O3'))\n    CO_data.append(aqi_to_concentration(aqiData, 'CO'))\n    NO2_data.append(aqi_to_concentration(aqiData, 'NO2'))\n\npd.DataFrame({\"Date\": date_range_str, \"Lat\": lat, \"Lon\": lon, \"AirNow_O3\": O3_data, \"AirNow_CO\": CO_data, \"AirNow_NO2\": NO2_data}).to_csv(\"/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/airnow_data.csv\", index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1667525476219,
  "history_end_time" : 1667525491548,
  "history_notes" : null,
  "history_process" : "di7md3",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5pxaj5tnrz9",
  "history_input" : "import json\nimport pandas as pd\nimport ee\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\n# identify a 500 meter buffer around our Point Of Interest (POI)\npoi = ee.Geometry.Point(32.047501, -110.773903).buffer(500)\n\n# Get TROPOMI NRTI Image Collection for GoogleEarth Engine\ntropomiCollection = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_O3\").filterDate('2019-01-01','2019-02-28')\n\ndef poi_mean(img):\n    # This function will reduce all the points in the area we specified in \"poi\" and average all the data into a single daily value\n    mean = img.reduceRegion(reducer=ee.Reducer.mean(), \n    geometry=poi,scale=250).get('O3_column_number_density')\n    return img.set('date', img.date().format()).set('mean',mean)\n    \n# Map function to our ImageCollection\npoi_reduced_imgs = tropomiCollection.map(poi_mean)\nnested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date','mean']).values().get(0)\n\n# we need to call the callback method \"getInfo\" to retrieve the data\ndf = pd.DataFrame(nested_list.getInfo(), columns=['Date','tropomi_O3_mean'])\n\n\n# Convert Date column to DateTime\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.set_index('Date')\n# convert tropomi_O3_mean to ppbV (parts-per-billion-volume)\ndf['tropomi_O3.ppbV'] = (df['tropomi_O3_mean']/3)*224\n\ndf.drop('tropomi_O3_mean', inplace=True, axis=1)\n# Save data to CSV file\ndf.to_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/tropomi_O3.csv')\n",
  "history_output" : "",
  "history_begin_time" : 1667525493270,
  "history_end_time" : 1667525499621,
  "history_notes" : null,
  "history_process" : "lz2spd",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uedjextsck1",
  "history_input" : "import pandas as pd\n\n# Read Airnow data extract from AirnowAPI and saved to system\nairnow = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/airnow_data.csv', parse_dates=[\"Date\"])\n\n# Scale data to match predictors scale\nairnow.AirNow_O3 = airnow.AirNow_O3 * 1000\nairnow.AirNow_CO = airnow.AirNow_CO * 10\n# Reformat date string\nairnow[\"Date\"] = airnow[\"Date\"].dt.strftime('%Y%m%d')\n\n\n# Read Tropomi extracted from Google Earth Engine and saved to system\ntropomi = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/tropomi_O3.csv', parse_dates=[\"Date\"])\ntropomi[\"Date\"] = tropomi[\"Date\"].dt.strftime('%Y%m%d')\ntropomiDaily = tropomi.groupby(\"Date\").max()\n# Make date match CMAQ and Airnow retrieved data. This is done only becuase TROPOMI doesn't have data before 2018, so making the data the same as the other source for merging later.\n# If the data retrieved for CMAQ and Airnow is after 2018, then this below line can be deleted.\ntropomiDaily[\"Date\"] = pd.date_range(\"20170101\", \"20170227\").strftime('%Y%m%d')\ntropomiDaily.reset_index(drop=True, inplace=True)\n\n# Read downloaded CMAQ data.\ncmaq = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/cmaq_2017_Jan_Feb.csv', parse_dates=[\"date\"])\n# Drop unnecessary columns\ncmaq.drop([\"column\", \"row\", \"Lambert_X\", \"LAMBERT_Y\", \"Unnamed: 0\"], axis=1, inplace=True)\n# Reformat date string\ncmaq['Date'] = cmaq[\"date\"].dt.strftime('%Y%m%d')\n\n# Merge all data frames together\nfinal = airnow.merge(tropomiDaily, on=\"Date\").merge(cmaq, on=\"Date\")\n# Drop any duplicated rows\nfinal = final.drop_duplicates(\"Date\")\n\nfinal.to_csv(\"/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv\", index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1667525501592,
  "history_end_time" : 1667525582539,
  "history_notes" : null,
  "history_process" : "b98i0m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r7whg68wdxd",
  "history_input" : "import pandas as pd\nimport pickle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n# Take the first 31 rows corresponding to the month of January as the training input (predictors)\nX = final[:31].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n\n# Take the first 31 rows corresponding to the month of January as the training target\ny = final[:31]['AirNow_O3']\n\n\n\n\n# define the base models\nmodels = list()\nmodels.append(('XGB1', XGBRegressor(max_depth=1)))\nmodels.append(('XGB2', XGBRegressor(max_depth=2)))\nmodels.append(('XGB3', XGBRegressor(max_depth=3)))\nmodels.append(('XGB4', XGBRegressor(max_depth=4)))\nmodels.append(('XGB5', XGBRegressor(max_depth=5)))\nmodels.append(('XGB6', XGBRegressor(max_depth=6)))\n\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n\n# save the model to disk\ntrainedModel = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\nlistOfModels = '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboostModels.sav'\n\npickle.dump(ensemble, open(trainedModel, 'wb'))\npickle.dump(models, open(listOfModels, 'wb'))\nprint(f\"Model is trained and saved to {trainedModel}\")",
  "history_output" : "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import MultiIndex, Int64Index\nTraceback (most recent call last):\n  File \"train_xgboost.py\", line 31, in <module>\n    ensemble.fit(X, y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_voting.py\", line 459, in fit\n    return super().fit(X, y, sample_weight)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_voting.py\", line 73, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py\", line 40, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 506, in inner_f\n    return f(**kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 772, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 312, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 256, in _transform_pandas_df\n    _invalid_dataframe_dtype(data)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\", line 236, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:AirNow_CO, AirNow_NO2, tropomi_O3.ppbV, CO_AVG, NO_AVG, NO2_AVG, SO2_AVG, CH2O_AVG, PM10_AVG, PM25_AVG, PM25_SO4_AVG, PM25_NO3_AVG, PM25_NH4_AVG, PM25_OC_AVG, PM25_EC_AVG\n",
  "history_begin_time" : 1667525583890,
  "history_end_time" : 1667525587282,
  "history_notes" : null,
  "history_process" : "rm59xe",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "n6rf5tmp3dx",
  "history_input" : "import pandas as pd\nimport pickle\nimport math\nimport sklearn\n\n\n\nfinal = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/final.csv')\n\n\n# Get the remaining rows after row 31 corresponding to the month of February as the testing set input.\nX = final[31:].drop(['Date', 'AirNow_O3', 'Lat', 'Lon', 'latitude', 'longitude', 'date', 'O3_MDA8', 'O3_AVG'],axis=1)\n# Get the remaining rows after row 31 corresponding to the month of February as the testing set target.\ny = final[31:]['AirNow_O3']\n\nfilename = f'/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\nensemble = pickle.load(open(filename, 'rb'))\n\npred = ensemble.predict(X)\ndataset = final.iloc[31:].copy()\ndataset['prediction'] = pred.tolist()\n\nmse = sklearn.metrics.mean_squared_error(pred, y)\nrmse = math.sqrt(mse)\n\nprint(mse, rmse)\n\ndataset.to_csv(\"/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/prediction.csv\", index=False)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"xgboost_prediction.py\", line 17, in <module>\n    ensemble = pickle.load(open(filename, 'rb'))\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/xgboost.sav'\n",
  "history_begin_time" : 1667525588572,
  "history_end_time" : 1667525590585,
  "history_notes" : null,
  "history_process" : "6esaq8",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rp2n6ix3c0n",
  "history_input" : "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndataset = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/prediction.csv')\n\n    \nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(20, 13))\n\n# Specify how our lines should look\nax.plot(dataset.Date, dataset.prediction, color='tab:orange', label='Prediction')\n# Use linestyle keyword to style our plot\nax.plot(dataset.Date, dataset.AirNow_O3, color='green', linestyle='--',\n        label='AirNow')\n\nax.plot(dataset.Date, dataset.O3_AVG, color='blue', linestyle='--',\n        label='CMAQ_O3')\n# Redisplay the legend to show our new wind gust line\nax.legend(loc='upper left')\n# Same as above\nax.set_xlabel('Time')\nplt.xticks(rotation=45)\nax.set_ylabel('Values')\nax.set_title('Compare Observed, Prediction, CMAQ Simulation')\nax.grid(True)\nax.legend(loc='upper left')\nfig.savefig('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/pred.png')\n",
  "history_output" : "Traceback (most recent call last):\n  File \"visualize_prediction.py\", line 4, in <module>\n    dataset = pd.read_csv('/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/prediction.csv')\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 317, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1729, in _make_engine\n    self.handles = get_handle(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 857, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/uhhmed/Desktop/CMAQ_Ch15_bookCode/prediction.csv'\n",
  "history_begin_time" : 1667525591641,
  "history_end_time" : 1667525593666,
  "history_notes" : null,
  "history_process" : "bz5tk5",
  "host_id" : "100001",
  "indicator" : "Failed"
}]
