[{
  "history_id" : "j3fxw3tc710",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027   \npython cmaq/text_to_csv_2021.py\nexit",
  "history_output" : "/bin/bash: ./geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh: No such file or directory\nrm: cannot remove './geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh': No such file or directory\n",
  "history_begin_time" : 1645820003222,
  "history_end_time" : 1645820011038,
  "history_notes" : null,
  "history_process" : "ol8aa4",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "tg8xt43llwz",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\npython cmaq/text_to_csv_2020.py\nexit",
  "history_output" : "bash: ./geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh: /bin/bash: bad interpreter: Text file busy\n",
  "history_begin_time" : 1645820003115,
  "history_end_time" : 1645820010979,
  "history_notes" : null,
  "history_process" : "r41da2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "k76xqmyh1ka",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n\npython cmaq/pre_processing.py\nexit",
  "history_output" : "running_preprocess\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/pre_processing.py\", line 63, in <module>\n    df1 = pd.read_csv('/home/mislam25/cmaq/2020.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/2020.csv'\n",
  "history_begin_time" : 1645820011997,
  "history_end_time" : 1645820027251,
  "history_notes" : null,
  "history_process" : "ftn2kp",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "itgc9tz5jl2",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n\npython cmaq/exploratory_data_analysis.py\nexit",
  "history_output" : "running_preprocess\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/exploratory_data_analysis.py\", line 34, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1645820028178,
  "history_end_time" : 1645820063610,
  "history_notes" : null,
  "history_process" : "wfd3c5",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "7yskiiev63u",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_xgboost.py",
  "history_output" : "running xgboost_training\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/training_xgboost.py\", line 12, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n./geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh: line 20: .py: command not found\nrm: cannot remove './geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh': No such file or directory\n",
  "history_begin_time" : 1645820064528,
  "history_end_time" : 1645820109432,
  "history_notes" : null,
  "history_process" : "j7uo3v",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "o651xl5k4t5",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_xgboost.py",
  "history_output" : "running prediction xgboost\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_xgboost.py\", line 8, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1645820110091,
  "history_end_time" : 1645820125745,
  "history_notes" : null,
  "history_process" : "zt10an",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "rpdb6th7paf",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_random_forest.py",
  "history_output" : "bash: ./geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh: /bin/bash: bad interpreter: Text file busy\n",
  "history_begin_time" : 1645820063972,
  "history_end_time" : 1645820071612,
  "history_notes" : null,
  "history_process" : "48iyth",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "6ppd39uygq3",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_random_forest.py",
  "history_output" : "running prediciton rf\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_random_forest.py\", line 8, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1645820071702,
  "history_end_time" : 1645820086970,
  "history_notes" : null,
  "history_process" : "bembwt",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "hlj3jkaltr1",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_autokeras.py",
  "history_output" : "/bin/bash: ./geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh: No such file or directory\nrm: cannot remove './geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh': No such file or directory\n",
  "history_begin_time" : 1645820063893,
  "history_end_time" : 1645820071623,
  "history_notes" : null,
  "history_process" : "l0t844",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "b5vwlfs0790",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_autokeras.py",
  "history_output" : "running predicion autokeras\n2022-02-25 15:14:49.106765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/libs/hwloc/2.1.0/lib:/opt/ohpc/pub/mpi/libfabric/1.10.1/lib:/opt/ohpc/pub/mpi/ucx-ohpc/1.8.0/lib:/opt/ohpc/pub/mpi/openmpi4-gnu9/4.0.4/lib:/opt/ohpc/pub/compiler/gcc/9.3.0/lib64:/lib64\n2022-02-25 15:14:49.106793: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_autokeras.py\", line 20, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\nrm: cannot remove './geoweaver-3uGhcMjC7AydI7rPipfiR9kMwy.sh': No such file or directory\n",
  "history_begin_time" : 1645820072632,
  "history_end_time" : 1645820197047,
  "history_notes" : null,
  "history_process" : "zmy3vb",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "i3y6ej2sgc8",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/model_comparison.py",
  "history_output" : "[]\n",
  "history_begin_time" : 1645820197600,
  "history_end_time" : 1645820237069,
  "history_notes" : null,
  "history_process" : "z1t6b2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
}]
