[{
  "history_id" : "4u9auub6lvb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667925180644,
  "history_end_time" : 1667925180644,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "wtelclc3p5o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667892170976,
  "history_end_time" : 1667892170976,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "eemrodq5z6m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666685317277,
  "history_end_time" : 1666685918667,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "440mw7q2kzf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666682218462,
  "history_end_time" : 1666683406418,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "rfat63ootox",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666681701590,
  "history_end_time" : 1666681701590,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "vtuh9stbkcu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666681684425,
  "history_end_time" : 1666681684425,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "zyqmg05au1a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666681592825,
  "history_end_time" : 1666681655017,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "k4wl6o92sh0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666678879038,
  "history_end_time" : 1666678879038,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "3bldxpn4kg5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666576238729,
  "history_end_time" : 1666577006576,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "7148xxus0a1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666553421623,
  "history_end_time" : 1666553446539,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "a7lfp19bt0f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666542247405,
  "history_end_time" : 1666553383565,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "230qjl7iqc1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665934797876,
  "history_end_time" : 1665935665884,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "nkwmhkhyr6n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665932107403,
  "history_end_time" : 1665934029257,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "6lyi8z35zpy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665930832266,
  "history_end_time" : 1665930832266,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "x69zh350lzi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665930614392,
  "history_end_time" : 1665930705186,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "jlkpqru60b1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665930050022,
  "history_end_time" : 1665930589608,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "ej7drubkk9d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665928489259,
  "history_end_time" : 1665928489259,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "t5y8ailekrp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665926308904,
  "history_end_time" : 1665926308904,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "d2wj2nz01zo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1665007808621,
  "history_end_time" : 1665007808621,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "hsl8gw8np2j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664983201422,
  "history_end_time" : 1665009008621,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "2yzn9voggi4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664949775840,
  "history_end_time" : 1664949775840,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "esnyoyul6m9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664505829060,
  "history_end_time" : 1664505829060,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "o8f0se6c1so",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664428239152,
  "history_end_time" : 1664428239152,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "72r2sh4pafv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664427014296,
  "history_end_time" : 1664427014296,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "9blreipi53o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664426709278,
  "history_end_time" : 1664426992818,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "zzu9xizh0uq",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220801\n",
  "history_begin_time" : 1664422793735,
  "history_end_time" : 1664422877558,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "k385cgko6o0",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "",
  "history_begin_time" : 1663783472385,
  "history_end_time" : 1663783472734,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uDHZAdPlqQ4f",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220807_00.csv\nSaving file: train_data_20220807_01.csv\nSaving file: train_data_20220807_02.csv\nSaving file: train_data_20220807_03.csv\nSaving file: train_data_20220807_04.csv\nSaving file: train_data_20220807_05.csv\nSaving file: train_data_20220807_06.csv\nSaving file: train_data_20220807_07.csv\nSaving file: train_data_20220807_08.csv\nSaving file: train_data_20220807_09.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nDone!\n",
  "history_begin_time" : 1661385374631,
  "history_end_time" : 1661385762588,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "IVcpLj7jNsU9",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\n",
  "history_begin_time" : 1661385077107,
  "history_end_time" : 1661385767584,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "Cb0gajjqlKV0",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_00.csv\nSaving file: train_data_20220704_01.csv\nSaving file: train_data_20220704_02.csv\nSaving file: train_data_20220704_03.csv\nSaving file: train_data_20220704_04.csv\nSaving file: train_data_20220704_05.csv\nSaving file: train_data_20220704_06.csv\nSaving file: train_data_20220704_07.csv\nSaving file: train_data_20220704_08.csv\nSaving file: train_data_20220704_09.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_00.csv\nSaving file: train_data_20220705_01.csv\nSaving file: train_data_20220705_02.csv\nSaving file: train_data_20220705_03.csv\nSaving file: train_data_20220705_04.csv\nSaving file: train_data_20220705_05.csv\nSaving file: train_data_20220705_06.csv\nSaving file: train_data_20220705_07.csv\nSaving file: train_data_20220705_08.csv\nSaving file: train_data_20220705_09.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_00.csv\nSaving file: train_data_20220706_01.csv\nSaving file: train_data_20220706_02.csv\nSaving file: train_data_20220706_03.csv\nSaving file: train_data_20220706_04.csv\nSaving file: train_data_20220706_05.csv\nSaving file: train_data_20220706_06.csv\nSaving file: train_data_20220706_07.csv\nSaving file: train_data_20220706_08.csv\nSaving file: train_data_20220706_09.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220707_00.csv\nSaving file: train_data_20220707_01.csv\nSaving file: train_data_20220707_02.csv\nSaving file: train_data_20220707_03.csv\nSaving file: train_data_20220707_04.csv\nSaving file: train_data_20220707_05.csv\nSaving file: train_data_20220707_06.csv\nSaving file: train_data_20220707_07.csv\nSaving file: train_data_20220707_08.csv\nSaving file: train_data_20220707_09.csv\nSaving file: train_data_20220707_10.csv\nSaving file: train_data_20220707_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220708_00.csv\nSaving file: train_data_20220708_01.csv\nSaving file: train_data_20220708_02.csv\nSaving file: train_data_20220708_03.csv\nSaving file: train_data_20220708_04.csv\nSaving file: train_data_20220708_05.csv\nSaving file: train_data_20220708_06.csv\nSaving file: train_data_20220708_07.csv\nSaving file: train_data_20220708_08.csv\nSaving file: train_data_20220708_09.csv\nSaving file: train_data_20220708_10.csv\nSaving file: train_data_20220708_11.csv\nGetting data for: 20220708\nSaving file: train_data_20220708_12.csv\nSaving file: train_data_20220708_13.csv\nSaving file: train_data_20220708_14.csv\nSaving file: train_data_20220708_15.csv\nSaving file: train_data_20220708_16.csv\nSaving file: train_data_20220708_17.csv\nSaving file: train_data_20220708_18.csv\nSaving file: train_data_20220708_19.csv\nSaving file: train_data_20220708_20.csv\nSaving file: train_data_20220708_21.csv\nSaving file: train_data_20220708_22.csv\nSaving file: train_data_20220708_23.csv\nSaving file: train_data_20220709_00.csv\nSaving file: train_data_20220709_01.csv\nSaving file: train_data_20220709_02.csv\nSaving file: train_data_20220709_03.csv\nSaving file: train_data_20220709_04.csv\nSaving file: train_data_20220709_05.csv\nSaving file: train_data_20220709_06.csv\nSaving file: train_data_20220709_07.csv\nSaving file: train_data_20220709_08.csv\nSaving file: train_data_20220709_09.csv\nSaving file: train_data_20220709_10.csv\nSaving file: train_data_20220709_11.csv\nGetting data for: 20220709\nSaving file: train_data_20220709_12.csv\nSaving file: train_data_20220709_13.csv\nSaving file: train_data_20220709_14.csv\nSaving file: train_data_20220709_15.csv\nSaving file: train_data_20220709_16.csv\nSaving file: train_data_20220709_17.csv\nSaving file: train_data_20220709_18.csv\nSaving file: train_data_20220709_19.csv\nSaving file: train_data_20220709_20.csv\nSaving file: train_data_20220709_21.csv\nSaving file: train_data_20220709_22.csv\nSaving file: train_data_20220709_23.csv\nSaving file: train_data_20220710_00.csv\nSaving file: train_data_20220710_01.csv\nSaving file: train_data_20220710_02.csv\nSaving file: train_data_20220710_03.csv\nSaving file: train_data_20220710_04.csv\nSaving file: train_data_20220710_05.csv\nSaving file: train_data_20220710_06.csv\nSaving file: train_data_20220710_07.csv\nSaving file: train_data_20220710_08.csv\nSaving file: train_data_20220710_09.csv\nSaving file: train_data_20220710_10.csv\nSaving file: train_data_20220710_11.csv\nGetting data for: 20220710\nSaving file: train_data_20220710_12.csv\nSaving file: train_data_20220710_13.csv\nSaving file: train_data_20220710_14.csv\nSaving file: train_data_20220710_15.csv\nSaving file: train_data_20220710_16.csv\nSaving file: train_data_20220710_17.csv\nSaving file: train_data_20220710_18.csv\nSaving file: train_data_20220710_19.csv\nSaving file: train_data_20220710_20.csv\nSaving file: train_data_20220710_21.csv\nSaving file: train_data_20220710_22.csv\nSaving file: train_data_20220710_23.csv\nSaving file: train_data_20220711_00.csv\nSaving file: train_data_20220711_01.csv\nSaving file: train_data_20220711_02.csv\nSaving file: train_data_20220711_03.csv\nSaving file: train_data_20220711_04.csv\nSaving file: train_data_20220711_05.csv\nSaving file: train_data_20220711_06.csv\nSaving file: train_data_20220711_07.csv\nSaving file: train_data_20220711_08.csv\nSaving file: train_data_20220711_09.csv\nSaving file: train_data_20220711_10.csv\nSaving file: train_data_20220711_11.csv\nGetting data for: 20220711\nSaving file: train_data_20220711_12.csv\nSaving file: train_data_20220711_13.csv\nSaving file: train_data_20220711_14.csv\nSaving file: train_data_20220711_15.csv\nSaving file: train_data_20220711_16.csv\nSaving file: train_data_20220711_17.csv\nSaving file: train_data_20220711_18.csv\nSaving file: train_data_20220711_19.csv\nSaving file: train_data_20220711_20.csv\nSaving file: train_data_20220711_21.csv\nSaving file: train_data_20220711_22.csv\nSaving file: train_data_20220711_23.csv\nSaving file: train_data_20220712_00.csv\nSaving file: train_data_20220712_01.csv\nSaving file: train_data_20220712_02.csv\nSaving file: train_data_20220712_03.csv\nSaving file: train_data_20220712_04.csv\nSaving file: train_data_20220712_05.csv\nSaving file: train_data_20220712_06.csv\nSaving file: train_data_20220712_07.csv\nSaving file: train_data_20220712_08.csv\nSaving file: train_data_20220712_09.csv\nSaving file: train_data_20220712_10.csv\nSaving file: train_data_20220712_11.csv\nGetting data for: 20220712\nSaving file: train_data_20220712_12.csv\nSaving file: train_data_20220712_13.csv\nSaving file: train_data_20220712_14.csv\nSaving file: train_data_20220712_15.csv\nSaving file: train_data_20220712_16.csv\nSaving file: train_data_20220712_17.csv\nSaving file: train_data_20220712_18.csv\nSaving file: train_data_20220712_19.csv\nSaving file: train_data_20220712_20.csv\nSaving file: train_data_20220712_21.csv\nSaving file: train_data_20220712_22.csv\nSaving file: train_data_20220712_23.csv\nSaving file: train_data_20220713_00.csv\nSaving file: train_data_20220713_01.csv\nSaving file: train_data_20220713_02.csv\nSaving file: train_data_20220713_03.csv\nSaving file: train_data_20220713_04.csv\nSaving file: train_data_20220713_05.csv\nSaving file: train_data_20220713_06.csv\nSaving file: train_data_20220713_07.csv\nSaving file: train_data_20220713_08.csv\nSaving file: train_data_20220713_09.csv\nSaving file: train_data_20220713_10.csv\nSaving file: train_data_20220713_11.csv\nGetting data for: 20220713\nSaving file: train_data_20220713_12.csv\nSaving file: train_data_20220713_13.csv\nSaving file: train_data_20220713_14.csv\nSaving file: train_data_20220713_15.csv\nSaving file: train_data_20220713_16.csv\nSaving file: train_data_20220713_17.csv\nSaving file: train_data_20220713_18.csv\nSaving file: train_data_20220713_19.csv\nSaving file: train_data_20220713_20.csv\nSaving file: train_data_20220713_21.csv\nSaving file: train_data_20220713_22.csv\nSaving file: train_data_20220713_23.csv\nSaving file: train_data_20220714_00.csv\nSaving file: train_data_20220714_01.csv\nSaving file: train_data_20220714_02.csv\nSaving file: train_data_20220714_03.csv\nSaving file: train_data_20220714_04.csv\nSaving file: train_data_20220714_05.csv\nSaving file: train_data_20220714_06.csv\nSaving file: train_data_20220714_07.csv\nSaving file: train_data_20220714_08.csv\nSaving file: train_data_20220714_09.csv\nSaving file: train_data_20220714_10.csv\nSaving file: train_data_20220714_11.csv\nGetting data for: 20220714\nSaving file: train_data_20220714_12.csv\nSaving file: train_data_20220714_13.csv\nSaving file: train_data_20220714_14.csv\nSaving file: train_data_20220714_15.csv\nSaving file: train_data_20220714_16.csv\nSaving file: train_data_20220714_17.csv\nSaving file: train_data_20220714_18.csv\nSaving file: train_data_20220714_19.csv\nSaving file: train_data_20220714_20.csv\nSaving file: train_data_20220714_21.csv\nSaving file: train_data_20220714_22.csv\nSaving file: train_data_20220714_23.csv\nSaving file: train_data_20220715_00.csv\nSaving file: train_data_20220715_01.csv\nSaving file: train_data_20220715_02.csv\nSaving file: train_data_20220715_03.csv\nSaving file: train_data_20220715_04.csv\nSaving file: train_data_20220715_05.csv\nSaving file: train_data_20220715_06.csv\nSaving file: train_data_20220715_07.csv\nSaving file: train_data_20220715_08.csv\nSaving file: train_data_20220715_09.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220716_00.csv\nSaving file: train_data_20220716_01.csv\nSaving file: train_data_20220716_02.csv\nSaving file: train_data_20220716_03.csv\nSaving file: train_data_20220716_04.csv\nSaving file: train_data_20220716_05.csv\nSaving file: train_data_20220716_06.csv\nSaving file: train_data_20220716_07.csv\nSaving file: train_data_20220716_08.csv\nSaving file: train_data_20220716_09.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220717_00.csv\nSaving file: train_data_20220717_01.csv\nSaving file: train_data_20220717_02.csv\nSaving file: train_data_20220717_03.csv\nSaving file: train_data_20220717_04.csv\nSaving file: train_data_20220717_05.csv\nSaving file: train_data_20220717_06.csv\nSaving file: train_data_20220717_07.csv\nSaving file: train_data_20220717_08.csv\nSaving file: train_data_20220717_09.csv\nSaving file: train_data_20220717_10.csv\nSaving file: train_data_20220717_11.csv\nGetting data for: 20220717\nSaving file: train_data_20220717_12.csv\nSaving file: train_data_20220717_13.csv\nSaving file: train_data_20220717_14.csv\nSaving file: train_data_20220717_15.csv\nSaving file: train_data_20220717_16.csv\nSaving file: train_data_20220717_17.csv\nSaving file: train_data_20220717_18.csv\nSaving file: train_data_20220717_19.csv\nSaving file: train_data_20220717_20.csv\nSaving file: train_data_20220717_21.csv\nSaving file: train_data_20220717_22.csv\nSaving file: train_data_20220717_23.csv\nSaving file: train_data_20220718_00.csv\nSaving file: train_data_20220718_01.csv\nSaving file: train_data_20220718_02.csv\nSaving file: train_data_20220718_03.csv\nSaving file: train_data_20220718_04.csv\nSaving file: train_data_20220718_05.csv\nSaving file: train_data_20220718_06.csv\nSaving file: train_data_20220718_07.csv\nSaving file: train_data_20220718_08.csv\nSaving file: train_data_20220718_09.csv\nSaving file: train_data_20220718_10.csv\nSaving file: train_data_20220718_11.csv\nGetting data for: 20220718\nSaving file: train_data_20220718_12.csv\nSaving file: train_data_20220718_13.csv\nSaving file: train_data_20220718_14.csv\nSaving file: train_data_20220718_15.csv\nSaving file: train_data_20220718_16.csv\nSaving file: train_data_20220718_17.csv\nSaving file: train_data_20220718_18.csv\nSaving file: train_data_20220718_19.csv\nSaving file: train_data_20220718_20.csv\nSaving file: train_data_20220718_21.csv\nSaving file: train_data_20220718_22.csv\nSaving file: train_data_20220718_23.csv\nSaving file: train_data_20220719_00.csv\nSaving file: train_data_20220719_01.csv\nSaving file: train_data_20220719_02.csv\nSaving file: train_data_20220719_03.csv\nSaving file: train_data_20220719_04.csv\nSaving file: train_data_20220719_05.csv\nSaving file: train_data_20220719_06.csv\nSaving file: train_data_20220719_07.csv\nSaving file: train_data_20220719_08.csv\nSaving file: train_data_20220719_09.csv\nSaving file: train_data_20220719_10.csv\nSaving file: train_data_20220719_11.csv\nGetting data for: 20220719\nSaving file: train_data_20220719_12.csv\nSaving file: train_data_20220719_13.csv\nSaving file: train_data_20220719_14.csv\nSaving file: train_data_20220719_15.csv\nSaving file: train_data_20220719_16.csv\nSaving file: train_data_20220719_17.csv\nSaving file: train_data_20220719_18.csv\nSaving file: train_data_20220719_19.csv\nSaving file: train_data_20220719_20.csv\nSaving file: train_data_20220719_21.csv\nSaving file: train_data_20220719_22.csv\nSaving file: train_data_20220719_23.csv\nSaving file: train_data_20220720_00.csv\nSaving file: train_data_20220720_01.csv\nSaving file: train_data_20220720_02.csv\nSaving file: train_data_20220720_03.csv\nSaving file: train_data_20220720_04.csv\nSaving file: train_data_20220720_05.csv\nSaving file: train_data_20220720_06.csv\nSaving file: train_data_20220720_07.csv\nSaving file: train_data_20220720_08.csv\nSaving file: train_data_20220720_09.csv\nSaving file: train_data_20220720_10.csv\nSaving file: train_data_20220720_11.csv\nGetting data for: 20220720\nSaving file: train_data_20220720_12.csv\nSaving file: train_data_20220720_13.csv\nSaving file: train_data_20220720_14.csv\nSaving file: train_data_20220720_15.csv\nSaving file: train_data_20220720_16.csv\nSaving file: train_data_20220720_17.csv\nSaving file: train_data_20220720_18.csv\nSaving file: train_data_20220720_19.csv\nSaving file: train_data_20220720_20.csv\nSaving file: train_data_20220720_21.csv\nSaving file: train_data_20220720_22.csv\nSaving file: train_data_20220720_23.csv\nSaving file: train_data_20220721_00.csv\nSaving file: train_data_20220721_01.csv\nSaving file: train_data_20220721_02.csv\nSaving file: train_data_20220721_03.csv\nSaving file: train_data_20220721_04.csv\nSaving file: train_data_20220721_05.csv\nSaving file: train_data_20220721_06.csv\nSaving file: train_data_20220721_07.csv\nSaving file: train_data_20220721_08.csv\nSaving file: train_data_20220721_09.csv\nSaving file: train_data_20220721_10.csv\nSaving file: train_data_20220721_11.csv\nGetting data for: 20220721\nSaving file: train_data_20220721_12.csv\nSaving file: train_data_20220721_13.csv\nSaving file: train_data_20220721_14.csv\nSaving file: train_data_20220721_15.csv\nSaving file: train_data_20220721_16.csv\nSaving file: train_data_20220721_17.csv\nSaving file: train_data_20220721_18.csv\nSaving file: train_data_20220721_19.csv\nSaving file: train_data_20220721_20.csv\nSaving file: train_data_20220721_21.csv\nSaving file: train_data_20220721_22.csv\nSaving file: train_data_20220721_23.csv\nSaving file: train_data_20220722_00.csv\nSaving file: train_data_20220722_01.csv\nSaving file: train_data_20220722_02.csv\nSaving file: train_data_20220722_03.csv\nSaving file: train_data_20220722_04.csv\nSaving file: train_data_20220722_05.csv\nSaving file: train_data_20220722_06.csv\nSaving file: train_data_20220722_07.csv\nSaving file: train_data_20220722_08.csv\nSaving file: train_data_20220722_09.csv\nSaving file: train_data_20220722_10.csv\nSaving file: train_data_20220722_11.csv\nGetting data for: 20220722\nSaving file: train_data_20220722_12.csv\nSaving file: train_data_20220722_13.csv\nSaving file: train_data_20220722_14.csv\nSaving file: train_data_20220722_15.csv\nSaving file: train_data_20220722_16.csv\nSaving file: train_data_20220722_17.csv\nSaving file: train_data_20220722_18.csv\nSaving file: train_data_20220722_19.csv\nSaving file: train_data_20220722_20.csv\nSaving file: train_data_20220722_21.csv\nSaving file: train_data_20220722_22.csv\nSaving file: train_data_20220722_23.csv\nSaving file: train_data_20220723_00.csv\nSaving file: train_data_20220723_01.csv\nSaving file: train_data_20220723_02.csv\nSaving file: train_data_20220723_03.csv\nSaving file: train_data_20220723_04.csv\nSaving file: train_data_20220723_05.csv\nSaving file: train_data_20220723_06.csv\nSaving file: train_data_20220723_07.csv\nSaving file: train_data_20220723_08.csv\nSaving file: train_data_20220723_09.csv\nSaving file: train_data_20220723_10.csv\nSaving file: train_data_20220723_11.csv\nGetting data for: 20220723\nSaving file: train_data_20220723_12.csv\nSaving file: train_data_20220723_13.csv\nSaving file: train_data_20220723_14.csv\nSaving file: train_data_20220723_15.csv\nSaving file: train_data_20220723_16.csv\nSaving file: train_data_20220723_17.csv\nSaving file: train_data_20220723_18.csv\nSaving file: train_data_20220723_19.csv\nSaving file: train_data_20220723_20.csv\nSaving file: train_data_20220723_21.csv\nSaving file: train_data_20220723_22.csv\nSaving file: train_data_20220723_23.csv\nSaving file: train_data_20220724_00.csv\nSaving file: train_data_20220724_01.csv\nSaving file: train_data_20220724_02.csv\nSaving file: train_data_20220724_03.csv\nSaving file: train_data_20220724_04.csv\nSaving file: train_data_20220724_05.csv\nSaving file: train_data_20220724_06.csv\nSaving file: train_data_20220724_07.csv\nSaving file: train_data_20220724_08.csv\nSaving file: train_data_20220724_09.csv\nSaving file: train_data_20220724_10.csv\nSaving file: train_data_20220724_11.csv\nGetting data for: 20220724\nSaving file: train_data_20220724_12.csv\nSaving file: train_data_20220724_13.csv\nSaving file: train_data_20220724_14.csv\nSaving file: train_data_20220724_15.csv\nSaving file: train_data_20220724_16.csv\nSaving file: train_data_20220724_17.csv\nSaving file: train_data_20220724_18.csv\nSaving file: train_data_20220724_19.csv\nSaving file: train_data_20220724_20.csv\nSaving file: train_data_20220724_21.csv\nSaving file: train_data_20220724_22.csv\nSaving file: train_data_20220724_23.csv\nSaving file: train_data_20220725_00.csv\nSaving file: train_data_20220725_01.csv\nSaving file: train_data_20220725_02.csv\nSaving file: train_data_20220725_03.csv\nSaving file: train_data_20220725_04.csv\nSaving file: train_data_20220725_05.csv\nSaving file: train_data_20220725_06.csv\nSaving file: train_data_20220725_07.csv\nSaving file: train_data_20220725_08.csv\nSaving file: train_data_20220725_09.csv\nSaving file: train_data_20220725_10.csv\nSaving file: train_data_20220725_11.csv\nGetting data for: 20220725\nSaving file: train_data_20220725_12.csv\nSaving file: train_data_20220725_13.csv\nSaving file: train_data_20220725_14.csv\nSaving file: train_data_20220725_15.csv\nSaving file: train_data_20220725_16.csv\nSaving file: train_data_20220725_17.csv\nSaving file: train_data_20220725_18.csv\nSaving file: train_data_20220725_19.csv\nSaving file: train_data_20220725_20.csv\nSaving file: train_data_20220725_21.csv\nSaving file: train_data_20220725_22.csv\nSaving file: train_data_20220725_23.csv\nSaving file: train_data_20220726_00.csv\nSaving file: train_data_20220726_01.csv\nSaving file: train_data_20220726_02.csv\nSaving file: train_data_20220726_03.csv\nSaving file: train_data_20220726_04.csv\nSaving file: train_data_20220726_05.csv\nSaving file: train_data_20220726_06.csv\nSaving file: train_data_20220726_07.csv\nSaving file: train_data_20220726_08.csv\nSaving file: train_data_20220726_09.csv\nSaving file: train_data_20220726_10.csv\nSaving file: train_data_20220726_11.csv\nGetting data for: 20220726\nSaving file: train_data_20220726_12.csv\nSaving file: train_data_20220726_13.csv\nSaving file: train_data_20220726_14.csv\nSaving file: train_data_20220726_15.csv\nSaving file: train_data_20220726_16.csv\nSaving file: train_data_20220726_17.csv\nSaving file: train_data_20220726_18.csv\nSaving file: train_data_20220726_19.csv\nSaving file: train_data_20220726_20.csv\nSaving file: train_data_20220726_21.csv\nSaving file: train_data_20220726_22.csv\nSaving file: train_data_20220726_23.csv\nSaving file: train_data_20220727_00.csv\nSaving file: train_data_20220727_01.csv\nSaving file: train_data_20220727_02.csv\nSaving file: train_data_20220727_03.csv\nSaving file: train_data_20220727_04.csv\nSaving file: train_data_20220727_05.csv\nSaving file: train_data_20220727_06.csv\nSaving file: train_data_20220727_07.csv\nSaving file: train_data_20220727_08.csv\nSaving file: train_data_20220727_09.csv\nSaving file: train_data_20220727_10.csv\nSaving file: train_data_20220727_11.csv\nGetting data for: 20220727\nSaving file: train_data_20220727_12.csv\nSaving file: train_data_20220727_13.csv\nSaving file: train_data_20220727_14.csv\nSaving file: train_data_20220727_15.csv\nSaving file: train_data_20220727_16.csv\nSaving file: train_data_20220727_17.csv\nSaving file: train_data_20220727_18.csv\nSaving file: train_data_20220727_19.csv\nSaving file: train_data_20220727_20.csv\nSaving file: train_data_20220727_21.csv\nSaving file: train_data_20220727_22.csv\nSaving file: train_data_20220727_23.csv\nSaving file: train_data_20220728_00.csv\nSaving file: train_data_20220728_01.csv\nSaving file: train_data_20220728_02.csv\nSaving file: train_data_20220728_03.csv\nSaving file: train_data_20220728_04.csv\nSaving file: train_data_20220728_05.csv\nSaving file: train_data_20220728_06.csv\nSaving file: train_data_20220728_07.csv\nSaving file: train_data_20220728_08.csv\nSaving file: train_data_20220728_09.csv\nSaving file: train_data_20220728_10.csv\nSaving file: train_data_20220728_11.csv\nGetting data for: 20220728\nSaving file: train_data_20220728_12.csv\nSaving file: train_data_20220728_13.csv\nSaving file: train_data_20220728_14.csv\nSaving file: train_data_20220728_15.csv\nSaving file: train_data_20220728_16.csv\nSaving file: train_data_20220728_17.csv\nSaving file: train_data_20220728_18.csv\nSaving file: train_data_20220728_19.csv\nSaving file: train_data_20220728_20.csv\nSaving file: train_data_20220728_21.csv\nSaving file: train_data_20220728_22.csv\nSaving file: train_data_20220728_23.csv\nSaving file: train_data_20220729_00.csv\nSaving file: train_data_20220729_01.csv\nSaving file: train_data_20220729_02.csv\nSaving file: train_data_20220729_03.csv\nSaving file: train_data_20220729_04.csv\nSaving file: train_data_20220729_05.csv\nSaving file: train_data_20220729_06.csv\nSaving file: train_data_20220729_07.csv\nSaving file: train_data_20220729_08.csv\nSaving file: train_data_20220729_09.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220730_00.csv\nSaving file: train_data_20220730_01.csv\nSaving file: train_data_20220730_02.csv\nSaving file: train_data_20220730_03.csv\nSaving file: train_data_20220730_04.csv\nSaving file: train_data_20220730_05.csv\nSaving file: train_data_20220730_06.csv\nSaving file: train_data_20220730_07.csv\nSaving file: train_data_20220730_08.csv\nSaving file: train_data_20220730_09.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220731_00.csv\nSaving file: train_data_20220731_01.csv\nSaving file: train_data_20220731_02.csv\nSaving file: train_data_20220731_03.csv\nSaving file: train_data_20220731_04.csv\nSaving file: train_data_20220731_05.csv\nSaving file: train_data_20220731_06.csv\nSaving file: train_data_20220731_07.csv\nSaving file: train_data_20220731_08.csv\nSaving file: train_data_20220731_09.csv\nSaving file: train_data_20220731_10.csv\nSaving file: train_data_20220731_11.csv\nGetting data for: 20220731\nSaving file: train_data_20220731_12.csv\nSaving file: train_data_20220731_13.csv\nSaving file: train_data_20220731_14.csv\nSaving file: train_data_20220731_15.csv\nSaving file: train_data_20220731_16.csv\nSaving file: train_data_20220731_17.csv\nSaving file: train_data_20220731_18.csv\nSaving file: train_data_20220731_19.csv\nSaving file: train_data_20220731_20.csv\nSaving file: train_data_20220731_21.csv\nSaving file: train_data_20220731_22.csv\nSaving file: train_data_20220731_23.csv\nSaving file: train_data_20220801_00.csv\nSaving file: train_data_20220801_01.csv\nSaving file: train_data_20220801_02.csv\nSaving file: train_data_20220801_03.csv\nSaving file: train_data_20220801_04.csv\nSaving file: train_data_20220801_05.csv\nSaving file: train_data_20220801_06.csv\nSaving file: train_data_20220801_07.csv\nSaving file: train_data_20220801_08.csv\nSaving file: train_data_20220801_09.csv\nSaving file: train_data_20220801_10.csv\nSaving file: train_data_20220801_11.csv\nDone!\n",
  "history_begin_time" : 1661137419357,
  "history_end_time" : 1661385225466,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "ltgugig2yhq",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Running",
  "history_begin_time" : 1660854013393,
  "history_end_time" : 1660854222305,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "9p8xuhmfcdw",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "bash: python: command not found\n",
  "history_begin_time" : 1660853983355,
  "history_end_time" : 1660853992763,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "Wm0dSAcaT9aB",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220807_00.csv\nSaving file: train_data_20220807_01.csv\nSaving file: train_data_20220807_02.csv\nSaving file: train_data_20220807_03.csv\nSaving file: train_data_20220807_04.csv\nSaving file: train_data_20220807_05.csv\nSaving file: train_data_20220807_06.csv\nSaving file: train_data_20220807_07.csv\nSaving file: train_data_20220807_08.csv\nSaving file: train_data_20220807_09.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nDone!\n",
  "history_begin_time" : 1660805259418,
  "history_end_time" : 1661385224731,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "1MGbsRugqu2C",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220807_00.csv\nSaving file: train_data_20220807_01.csv\nSaving file: train_data_20220807_02.csv\nSaving file: train_data_20220807_03.csv\nSaving file: train_data_20220807_04.csv\nSaving file: train_data_20220807_05.csv\nSaving file: train_data_20220807_06.csv\nSaving file: train_data_20220807_07.csv\nSaving file: train_data_20220807_08.csv\nSaving file: train_data_20220807_09.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nDone!\n",
  "history_begin_time" : 1660787002084,
  "history_end_time" : 1661385224172,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "bn79y1gladp",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\n",
  "history_begin_time" : 1660786928049,
  "history_end_time" : 1660786974130,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "3rg6zw92wvd",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\n",
  "history_begin_time" : 1660786748107,
  "history_end_time" : 1660786902446,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "DRf0kYtV7F9z",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220807_00.csv\nSaving file: train_data_20220807_01.csv\nSaving file: train_data_20220807_02.csv\nSaving file: train_data_20220807_03.csv\nSaving file: train_data_20220807_04.csv\nSaving file: train_data_20220807_05.csv\nSaving file: train_data_20220807_06.csv\nSaving file: train_data_20220807_07.csv\nSaving file: train_data_20220807_08.csv\nSaving file: train_data_20220807_09.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nDone!\n",
  "history_begin_time" : 1660784000715,
  "history_end_time" : 1661385223512,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "BkuE9RQQ7Yjn",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220807_00.csv\nSaving file: train_data_20220807_01.csv\nSaving file: train_data_20220807_02.csv\nSaving file: train_data_20220807_03.csv\nSaving file: train_data_20220807_04.csv\nSaving file: train_data_20220807_05.csv\nSaving file: train_data_20220807_06.csv\nSaving file: train_data_20220807_07.csv\nSaving file: train_data_20220807_08.csv\nSaving file: train_data_20220807_09.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nDone!\n",
  "history_begin_time" : 1660782498260,
  "history_end_time" : 1661385223060,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "2rWZFNthUmIf",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 6)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220807_00.csv\nSaving file: train_data_20220807_01.csv\nSaving file: train_data_20220807_02.csv\nSaving file: train_data_20220807_03.csv\nSaving file: train_data_20220807_04.csv\nSaving file: train_data_20220807_05.csv\nSaving file: train_data_20220807_06.csv\nSaving file: train_data_20220807_07.csv\nSaving file: train_data_20220807_08.csv\nSaving file: train_data_20220807_09.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nDone!\n",
  "history_begin_time" : 1660782228516,
  "history_end_time" : 1661385230806,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "wu7d7a615kc",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 5)   # start date\nedate = date(2022, 8, 5)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220806_00.csv\nSaving file: train_data_20220806_01.csv\nSaving file: train_data_20220806_02.csv\nSaving file: train_data_20220806_03.csv\nSaving file: train_data_20220806_04.csv\nSaving file: train_data_20220806_05.csv\nSaving file: train_data_20220806_06.csv\nSaving file: train_data_20220806_07.csv\nSaving file: train_data_20220806_08.csv\nSaving file: train_data_20220806_09.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nDone!\n",
  "history_begin_time" : 1660777334919,
  "history_end_time" : 1660778171056,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "H1R78k5iXHOj",
  "history_input" : "# get all of the cmaq model output variables and save to hourly csvs\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_00.csv\nSaving file: train_data_20220704_01.csv\nSaving file: train_data_20220704_02.csv\nSaving file: train_data_20220704_03.csv\nSaving file: train_data_20220704_04.csv\nSaving file: train_data_20220704_05.csv\nSaving file: train_data_20220704_06.csv\nSaving file: train_data_20220704_07.csv\nSaving file: train_data_20220704_08.csv\nSaving file: train_data_20220704_09.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_00.csv\nSaving file: train_data_20220705_01.csv\nSaving file: train_data_20220705_02.csv\nSaving file: train_data_20220705_03.csv\nSaving file: train_data_20220705_04.csv\nSaving file: train_data_20220705_05.csv\nSaving file: train_data_20220705_06.csv\nSaving file: train_data_20220705_07.csv\nSaving file: train_data_20220705_08.csv\nSaving file: train_data_20220705_09.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_00.csv\nSaving file: train_data_20220706_01.csv\nSaving file: train_data_20220706_02.csv\nSaving file: train_data_20220706_03.csv\nSaving file: train_data_20220706_04.csv\nSaving file: train_data_20220706_05.csv\nSaving file: train_data_20220706_06.csv\nSaving file: train_data_20220706_07.csv\nSaving file: train_data_20220706_08.csv\nSaving file: train_data_20220706_09.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220707_00.csv\nSaving file: train_data_20220707_01.csv\nSaving file: train_data_20220707_02.csv\nSaving file: train_data_20220707_03.csv\nSaving file: train_data_20220707_04.csv\nSaving file: train_data_20220707_05.csv\nSaving file: train_data_20220707_06.csv\nSaving file: train_data_20220707_07.csv\nSaving file: train_data_20220707_08.csv\nSaving file: train_data_20220707_09.csv\nSaving file: train_data_20220707_10.csv\nSaving file: train_data_20220707_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220708_00.csv\nSaving file: train_data_20220708_01.csv\nSaving file: train_data_20220708_02.csv\nSaving file: train_data_20220708_03.csv\nSaving file: train_data_20220708_04.csv\nSaving file: train_data_20220708_05.csv\nSaving file: train_data_20220708_06.csv\nSaving file: train_data_20220708_07.csv\nSaving file: train_data_20220708_08.csv\nSaving file: train_data_20220708_09.csv\nSaving file: train_data_20220708_10.csv\nSaving file: train_data_20220708_11.csv\nGetting data for: 20220708\nSaving file: train_data_20220708_12.csv\nSaving file: train_data_20220708_13.csv\nSaving file: train_data_20220708_14.csv\nSaving file: train_data_20220708_15.csv\nSaving file: train_data_20220708_16.csv\nSaving file: train_data_20220708_17.csv\nSaving file: train_data_20220708_18.csv\nSaving file: train_data_20220708_19.csv\nSaving file: train_data_20220708_20.csv\nSaving file: train_data_20220708_21.csv\nSaving file: train_data_20220708_22.csv\nSaving file: train_data_20220708_23.csv\nSaving file: train_data_20220709_00.csv\nSaving file: train_data_20220709_01.csv\nSaving file: train_data_20220709_02.csv\nSaving file: train_data_20220709_03.csv\nSaving file: train_data_20220709_04.csv\nSaving file: train_data_20220709_05.csv\nSaving file: train_data_20220709_06.csv\nSaving file: train_data_20220709_07.csv\nSaving file: train_data_20220709_08.csv\nSaving file: train_data_20220709_09.csv\nSaving file: train_data_20220709_10.csv\nSaving file: train_data_20220709_11.csv\nGetting data for: 20220709\nSaving file: train_data_20220709_12.csv\nSaving file: train_data_20220709_13.csv\nSaving file: train_data_20220709_14.csv\nSaving file: train_data_20220709_15.csv\nSaving file: train_data_20220709_16.csv\nSaving file: train_data_20220709_17.csv\nSaving file: train_data_20220709_18.csv\nSaving file: train_data_20220709_19.csv\nSaving file: train_data_20220709_20.csv\nSaving file: train_data_20220709_21.csv\nSaving file: train_data_20220709_22.csv\nSaving file: train_data_20220709_23.csv\nSaving file: train_data_20220710_00.csv\nSaving file: train_data_20220710_01.csv\nSaving file: train_data_20220710_02.csv\nSaving file: train_data_20220710_03.csv\nSaving file: train_data_20220710_04.csv\nSaving file: train_data_20220710_05.csv\nSaving file: train_data_20220710_06.csv\nSaving file: train_data_20220710_07.csv\nSaving file: train_data_20220710_08.csv\nSaving file: train_data_20220710_09.csv\nSaving file: train_data_20220710_10.csv\nSaving file: train_data_20220710_11.csv\nGetting data for: 20220710\nSaving file: train_data_20220710_12.csv\nSaving file: train_data_20220710_13.csv\nSaving file: train_data_20220710_14.csv\nSaving file: train_data_20220710_15.csv\nSaving file: train_data_20220710_16.csv\nSaving file: train_data_20220710_17.csv\nSaving file: train_data_20220710_18.csv\nSaving file: train_data_20220710_19.csv\nSaving file: train_data_20220710_20.csv\nSaving file: train_data_20220710_21.csv\nSaving file: train_data_20220710_22.csv\nSaving file: train_data_20220710_23.csv\nSaving file: train_data_20220711_00.csv\nSaving file: train_data_20220711_01.csv\nSaving file: train_data_20220711_02.csv\nSaving file: train_data_20220711_03.csv\nSaving file: train_data_20220711_04.csv\nSaving file: train_data_20220711_05.csv\nSaving file: train_data_20220711_06.csv\nSaving file: train_data_20220711_07.csv\nSaving file: train_data_20220711_08.csv\nSaving file: train_data_20220711_09.csv\nSaving file: train_data_20220711_10.csv\nSaving file: train_data_20220711_11.csv\nGetting data for: 20220711\nSaving file: train_data_20220711_12.csv\nSaving file: train_data_20220711_13.csv\nSaving file: train_data_20220711_14.csv\nSaving file: train_data_20220711_15.csv\nSaving file: train_data_20220711_16.csv\nSaving file: train_data_20220711_17.csv\nSaving file: train_data_20220711_18.csv\nSaving file: train_data_20220711_19.csv\nSaving file: train_data_20220711_20.csv\nSaving file: train_data_20220711_21.csv\nSaving file: train_data_20220711_22.csv\nSaving file: train_data_20220711_23.csv\nSaving file: train_data_20220712_00.csv\nSaving file: train_data_20220712_01.csv\nSaving file: train_data_20220712_02.csv\nSaving file: train_data_20220712_03.csv\nSaving file: train_data_20220712_04.csv\nSaving file: train_data_20220712_05.csv\nSaving file: train_data_20220712_06.csv\nSaving file: train_data_20220712_07.csv\nSaving file: train_data_20220712_08.csv\nSaving file: train_data_20220712_09.csv\nSaving file: train_data_20220712_10.csv\nSaving file: train_data_20220712_11.csv\nGetting data for: 20220712\nSaving file: train_data_20220712_12.csv\nSaving file: train_data_20220712_13.csv\nSaving file: train_data_20220712_14.csv\nSaving file: train_data_20220712_15.csv\nSaving file: train_data_20220712_16.csv\nSaving file: train_data_20220712_17.csv\nSaving file: train_data_20220712_18.csv\nSaving file: train_data_20220712_19.csv\nSaving file: train_data_20220712_20.csv\nSaving file: train_data_20220712_21.csv\nSaving file: train_data_20220712_22.csv\nSaving file: train_data_20220712_23.csv\nSaving file: train_data_20220713_00.csv\nSaving file: train_data_20220713_01.csv\nSaving file: train_data_20220713_02.csv\nSaving file: train_data_20220713_03.csv\nSaving file: train_data_20220713_04.csv\nSaving file: train_data_20220713_05.csv\nSaving file: train_data_20220713_06.csv\nSaving file: train_data_20220713_07.csv\nSaving file: train_data_20220713_08.csv\nSaving file: train_data_20220713_09.csv\nSaving file: train_data_20220713_10.csv\nSaving file: train_data_20220713_11.csv\nGetting data for: 20220713\nSaving file: train_data_20220713_12.csv\nSaving file: train_data_20220713_13.csv\nSaving file: train_data_20220713_14.csv\nSaving file: train_data_20220713_15.csv\nSaving file: train_data_20220713_16.csv\nSaving file: train_data_20220713_17.csv\nSaving file: train_data_20220713_18.csv\nSaving file: train_data_20220713_19.csv\nSaving file: train_data_20220713_20.csv\nSaving file: train_data_20220713_21.csv\nSaving file: train_data_20220713_22.csv\nSaving file: train_data_20220713_23.csv\nSaving file: train_data_20220714_00.csv\nSaving file: train_data_20220714_01.csv\nSaving file: train_data_20220714_02.csv\nSaving file: train_data_20220714_03.csv\nSaving file: train_data_20220714_04.csv\nSaving file: train_data_20220714_05.csv\nSaving file: train_data_20220714_06.csv\nSaving file: train_data_20220714_07.csv\nSaving file: train_data_20220714_08.csv\nSaving file: train_data_20220714_09.csv\nSaving file: train_data_20220714_10.csv\nSaving file: train_data_20220714_11.csv\nGetting data for: 20220714\nSaving file: train_data_20220714_12.csv\nSaving file: train_data_20220714_13.csv\nSaving file: train_data_20220714_14.csv\nSaving file: train_data_20220714_15.csv\nSaving file: train_data_20220714_16.csv\nSaving file: train_data_20220714_17.csv\nSaving file: train_data_20220714_18.csv\nSaving file: train_data_20220714_19.csv\nSaving file: train_data_20220714_20.csv\nSaving file: train_data_20220714_21.csv\nSaving file: train_data_20220714_22.csv\nSaving file: train_data_20220714_23.csv\nSaving file: train_data_20220715_00.csv\nSaving file: train_data_20220715_01.csv\nSaving file: train_data_20220715_02.csv\nSaving file: train_data_20220715_03.csv\nSaving file: train_data_20220715_04.csv\nSaving file: train_data_20220715_05.csv\nSaving file: train_data_20220715_06.csv\nSaving file: train_data_20220715_07.csv\nSaving file: train_data_20220715_08.csv\nSaving file: train_data_20220715_09.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220716_00.csv\nSaving file: train_data_20220716_01.csv\nSaving file: train_data_20220716_02.csv\nSaving file: train_data_20220716_03.csv\nSaving file: train_data_20220716_04.csv\nSaving file: train_data_20220716_05.csv\nSaving file: train_data_20220716_06.csv\nSaving file: train_data_20220716_07.csv\nSaving file: train_data_20220716_08.csv\nSaving file: train_data_20220716_09.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220717_00.csv\nSaving file: train_data_20220717_01.csv\nSaving file: train_data_20220717_02.csv\nSaving file: train_data_20220717_03.csv\nSaving file: train_data_20220717_04.csv\nSaving file: train_data_20220717_05.csv\nSaving file: train_data_20220717_06.csv\nSaving file: train_data_20220717_07.csv\nSaving file: train_data_20220717_08.csv\nSaving file: train_data_20220717_09.csv\nSaving file: train_data_20220717_10.csv\nSaving file: train_data_20220717_11.csv\nGetting data for: 20220717\nSaving file: train_data_20220717_12.csv\nSaving file: train_data_20220717_13.csv\nSaving file: train_data_20220717_14.csv\nSaving file: train_data_20220717_15.csv\nSaving file: train_data_20220717_16.csv\nSaving file: train_data_20220717_17.csv\nSaving file: train_data_20220717_18.csv\nSaving file: train_data_20220717_19.csv\nSaving file: train_data_20220717_20.csv\nSaving file: train_data_20220717_21.csv\nSaving file: train_data_20220717_22.csv\nSaving file: train_data_20220717_23.csv\nSaving file: train_data_20220718_00.csv\nSaving file: train_data_20220718_01.csv\nSaving file: train_data_20220718_02.csv\nSaving file: train_data_20220718_03.csv\nSaving file: train_data_20220718_04.csv\nSaving file: train_data_20220718_05.csv\nSaving file: train_data_20220718_06.csv\nSaving file: train_data_20220718_07.csv\nSaving file: train_data_20220718_08.csv\nSaving file: train_data_20220718_09.csv\nSaving file: train_data_20220718_10.csv\nSaving file: train_data_20220718_11.csv\nGetting data for: 20220718\nSaving file: train_data_20220718_12.csv\nSaving file: train_data_20220718_13.csv\nSaving file: train_data_20220718_14.csv\nSaving file: train_data_20220718_15.csv\nSaving file: train_data_20220718_16.csv\nSaving file: train_data_20220718_17.csv\nSaving file: train_data_20220718_18.csv\nSaving file: train_data_20220718_19.csv\nSaving file: train_data_20220718_20.csv\nSaving file: train_data_20220718_21.csv\nSaving file: train_data_20220718_22.csv\nSaving file: train_data_20220718_23.csv\nSaving file: train_data_20220719_00.csv\nSaving file: train_data_20220719_01.csv\nSaving file: train_data_20220719_02.csv\nSaving file: train_data_20220719_03.csv\nSaving file: train_data_20220719_04.csv\nSaving file: train_data_20220719_05.csv\nSaving file: train_data_20220719_06.csv\nSaving file: train_data_20220719_07.csv\nSaving file: train_data_20220719_08.csv\nSaving file: train_data_20220719_09.csv\nSaving file: train_data_20220719_10.csv\nSaving file: train_data_20220719_11.csv\nGetting data for: 20220719\nSaving file: train_data_20220719_12.csv\nSaving file: train_data_20220719_13.csv\nSaving file: train_data_20220719_14.csv\nSaving file: train_data_20220719_15.csv\nSaving file: train_data_20220719_16.csv\nSaving file: train_data_20220719_17.csv\nSaving file: train_data_20220719_18.csv\nSaving file: train_data_20220719_19.csv\nSaving file: train_data_20220719_20.csv\nSaving file: train_data_20220719_21.csv\nSaving file: train_data_20220719_22.csv\nSaving file: train_data_20220719_23.csv\nSaving file: train_data_20220720_00.csv\nSaving file: train_data_20220720_01.csv\nSaving file: train_data_20220720_02.csv\nSaving file: train_data_20220720_03.csv\nSaving file: train_data_20220720_04.csv\nSaving file: train_data_20220720_05.csv\nSaving file: train_data_20220720_06.csv\nSaving file: train_data_20220720_07.csv\nSaving file: train_data_20220720_08.csv\nSaving file: train_data_20220720_09.csv\nSaving file: train_data_20220720_10.csv\nSaving file: train_data_20220720_11.csv\nGetting data for: 20220720\nSaving file: train_data_20220720_12.csv\nSaving file: train_data_20220720_13.csv\nSaving file: train_data_20220720_14.csv\nSaving file: train_data_20220720_15.csv\nSaving file: train_data_20220720_16.csv\nSaving file: train_data_20220720_17.csv\nSaving file: train_data_20220720_18.csv\nSaving file: train_data_20220720_19.csv\nSaving file: train_data_20220720_20.csv\nSaving file: train_data_20220720_21.csv\nSaving file: train_data_20220720_22.csv\nSaving file: train_data_20220720_23.csv\nSaving file: train_data_20220721_00.csv\nSaving file: train_data_20220721_01.csv\nSaving file: train_data_20220721_02.csv\nSaving file: train_data_20220721_03.csv\nSaving file: train_data_20220721_04.csv\nSaving file: train_data_20220721_05.csv\nSaving file: train_data_20220721_06.csv\nSaving file: train_data_20220721_07.csv\nSaving file: train_data_20220721_08.csv\nSaving file: train_data_20220721_09.csv\nSaving file: train_data_20220721_10.csv\nSaving file: train_data_20220721_11.csv\nGetting data for: 20220721\nSaving file: train_data_20220721_12.csv\nSaving file: train_data_20220721_13.csv\nSaving file: train_data_20220721_14.csv\nSaving file: train_data_20220721_15.csv\nSaving file: train_data_20220721_16.csv\nSaving file: train_data_20220721_17.csv\nSaving file: train_data_20220721_18.csv\nSaving file: train_data_20220721_19.csv\nSaving file: train_data_20220721_20.csv\nSaving file: train_data_20220721_21.csv\nSaving file: train_data_20220721_22.csv\nSaving file: train_data_20220721_23.csv\nSaving file: train_data_20220722_00.csv\nSaving file: train_data_20220722_01.csv\nSaving file: train_data_20220722_02.csv\nSaving file: train_data_20220722_03.csv\nSaving file: train_data_20220722_04.csv\nSaving file: train_data_20220722_05.csv\nSaving file: train_data_20220722_06.csv\nSaving file: train_data_20220722_07.csv\nSaving file: train_data_20220722_08.csv\nSaving file: train_data_20220722_09.csv\nSaving file: train_data_20220722_10.csv\nSaving file: train_data_20220722_11.csv\nGetting data for: 20220722\nSaving file: train_data_20220722_12.csv\nSaving file: train_data_20220722_13.csv\nSaving file: train_data_20220722_14.csv\nSaving file: train_data_20220722_15.csv\nSaving file: train_data_20220722_16.csv\nSaving file: train_data_20220722_17.csv\nSaving file: train_data_20220722_18.csv\nSaving file: train_data_20220722_19.csv\nSaving file: train_data_20220722_20.csv\nSaving file: train_data_20220722_21.csv\nSaving file: train_data_20220722_22.csv\nSaving file: train_data_20220722_23.csv\nSaving file: train_data_20220723_00.csv\nSaving file: train_data_20220723_01.csv\nSaving file: train_data_20220723_02.csv\nSaving file: train_data_20220723_03.csv\nSaving file: train_data_20220723_04.csv\nSaving file: train_data_20220723_05.csv\nSaving file: train_data_20220723_06.csv\nSaving file: train_data_20220723_07.csv\nSaving file: train_data_20220723_08.csv\nSaving file: train_data_20220723_09.csv\nSaving file: train_data_20220723_10.csv\nSaving file: train_data_20220723_11.csv\nGetting data for: 20220723\nSaving file: train_data_20220723_12.csv\nSaving file: train_data_20220723_13.csv\nSaving file: train_data_20220723_14.csv\nSaving file: train_data_20220723_15.csv\nSaving file: train_data_20220723_16.csv\nSaving file: train_data_20220723_17.csv\nSaving file: train_data_20220723_18.csv\nSaving file: train_data_20220723_19.csv\nSaving file: train_data_20220723_20.csv\nSaving file: train_data_20220723_21.csv\nSaving file: train_data_20220723_22.csv\nSaving file: train_data_20220723_23.csv\nSaving file: train_data_20220724_00.csv\nSaving file: train_data_20220724_01.csv\nSaving file: train_data_20220724_02.csv\nSaving file: train_data_20220724_03.csv\nSaving file: train_data_20220724_04.csv\nSaving file: train_data_20220724_05.csv\nSaving file: train_data_20220724_06.csv\nSaving file: train_data_20220724_07.csv\nSaving file: train_data_20220724_08.csv\nSaving file: train_data_20220724_09.csv\nSaving file: train_data_20220724_10.csv\nSaving file: train_data_20220724_11.csv\nGetting data for: 20220724\nSaving file: train_data_20220724_12.csv\nSaving file: train_data_20220724_13.csv\nSaving file: train_data_20220724_14.csv\nSaving file: train_data_20220724_15.csv\nSaving file: train_data_20220724_16.csv\nSaving file: train_data_20220724_17.csv\nSaving file: train_data_20220724_18.csv\nSaving file: train_data_20220724_19.csv\nSaving file: train_data_20220724_20.csv\nSaving file: train_data_20220724_21.csv\nSaving file: train_data_20220724_22.csv\nSaving file: train_data_20220724_23.csv\nSaving file: train_data_20220725_00.csv\nSaving file: train_data_20220725_01.csv\nSaving file: train_data_20220725_02.csv\nSaving file: train_data_20220725_03.csv\nSaving file: train_data_20220725_04.csv\nSaving file: train_data_20220725_05.csv\nSaving file: train_data_20220725_06.csv\nSaving file: train_data_20220725_07.csv\nSaving file: train_data_20220725_08.csv\nSaving file: train_data_20220725_09.csv\nSaving file: train_data_20220725_10.csv\nSaving file: train_data_20220725_11.csv\nGetting data for: 20220725\nSaving file: train_data_20220725_12.csv\nSaving file: train_data_20220725_13.csv\nSaving file: train_data_20220725_14.csv\nSaving file: train_data_20220725_15.csv\nSaving file: train_data_20220725_16.csv\nSaving file: train_data_20220725_17.csv\nSaving file: train_data_20220725_18.csv\nSaving file: train_data_20220725_19.csv\nSaving file: train_data_20220725_20.csv\nSaving file: train_data_20220725_21.csv\nSaving file: train_data_20220725_22.csv\nSaving file: train_data_20220725_23.csv\nSaving file: train_data_20220726_00.csv\nSaving file: train_data_20220726_01.csv\nSaving file: train_data_20220726_02.csv\nSaving file: train_data_20220726_03.csv\nSaving file: train_data_20220726_04.csv\nSaving file: train_data_20220726_05.csv\nSaving file: train_data_20220726_06.csv\nSaving file: train_data_20220726_07.csv\nSaving file: train_data_20220726_08.csv\nSaving file: train_data_20220726_09.csv\nSaving file: train_data_20220726_10.csv\nSaving file: train_data_20220726_11.csv\nGetting data for: 20220726\nSaving file: train_data_20220726_12.csv\nSaving file: train_data_20220726_13.csv\nSaving file: train_data_20220726_14.csv\nSaving file: train_data_20220726_15.csv\nSaving file: train_data_20220726_16.csv\nSaving file: train_data_20220726_17.csv\nSaving file: train_data_20220726_18.csv\nSaving file: train_data_20220726_19.csv\nSaving file: train_data_20220726_20.csv\nSaving file: train_data_20220726_21.csv\nSaving file: train_data_20220726_22.csv\nSaving file: train_data_20220726_23.csv\nSaving file: train_data_20220727_00.csv\nSaving file: train_data_20220727_01.csv\nSaving file: train_data_20220727_02.csv\nSaving file: train_data_20220727_03.csv\nSaving file: train_data_20220727_04.csv\nSaving file: train_data_20220727_05.csv\nSaving file: train_data_20220727_06.csv\nSaving file: train_data_20220727_07.csv\nSaving file: train_data_20220727_08.csv\nSaving file: train_data_20220727_09.csv\nSaving file: train_data_20220727_10.csv\nSaving file: train_data_20220727_11.csv\nGetting data for: 20220727\nSaving file: train_data_20220727_12.csv\nSaving file: train_data_20220727_13.csv\nSaving file: train_data_20220727_14.csv\nSaving file: train_data_20220727_15.csv\nSaving file: train_data_20220727_16.csv\nSaving file: train_data_20220727_17.csv\nSaving file: train_data_20220727_18.csv\nSaving file: train_data_20220727_19.csv\nSaving file: train_data_20220727_20.csv\nSaving file: train_data_20220727_21.csv\nSaving file: train_data_20220727_22.csv\nSaving file: train_data_20220727_23.csv\nSaving file: train_data_20220728_00.csv\nSaving file: train_data_20220728_01.csv\nSaving file: train_data_20220728_02.csv\nSaving file: train_data_20220728_03.csv\nSaving file: train_data_20220728_04.csv\nSaving file: train_data_20220728_05.csv\nSaving file: train_data_20220728_06.csv\nSaving file: train_data_20220728_07.csv\nSaving file: train_data_20220728_08.csv\nSaving file: train_data_20220728_09.csv\nSaving file: train_data_20220728_10.csv\nSaving file: train_data_20220728_11.csv\nGetting data for: 20220728\nSaving file: train_data_20220728_12.csv\nSaving file: train_data_20220728_13.csv\nSaving file: train_data_20220728_14.csv\nSaving file: train_data_20220728_15.csv\nSaving file: train_data_20220728_16.csv\nSaving file: train_data_20220728_17.csv\nSaving file: train_data_20220728_18.csv\nSaving file: train_data_20220728_19.csv\nSaving file: train_data_20220728_20.csv\nSaving file: train_data_20220728_21.csv\nSaving file: train_data_20220728_22.csv\nSaving file: train_data_20220728_23.csv\nSaving file: train_data_20220729_00.csv\nSaving file: train_data_20220729_01.csv\nSaving file: train_data_20220729_02.csv\nSaving file: train_data_20220729_03.csv\nSaving file: train_data_20220729_04.csv\nSaving file: train_data_20220729_05.csv\nSaving file: train_data_20220729_06.csv\nSaving file: train_data_20220729_07.csv\nSaving file: train_data_20220729_08.csv\nSaving file: train_data_20220729_09.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220730_00.csv\nSaving file: train_data_20220730_01.csv\nSaving file: train_data_20220730_02.csv\nSaving file: train_data_20220730_03.csv\nSaving file: train_data_20220730_04.csv\nSaving file: train_data_20220730_05.csv\nSaving file: train_data_20220730_06.csv\nSaving file: train_data_20220730_07.csv\nSaving file: train_data_20220730_08.csv\nSaving file: train_data_20220730_09.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220731_00.csv\nSaving file: train_data_20220731_01.csv\nSaving file: train_data_20220731_02.csv\nSaving file: train_data_20220731_03.csv\nSaving file: train_data_20220731_04.csv\nSaving file: train_data_20220731_05.csv\nSaving file: train_data_20220731_06.csv\nSaving file: train_data_20220731_07.csv\nSaving file: train_data_20220731_08.csv\nSaving file: train_data_20220731_09.csv\nSaving file: train_data_20220731_10.csv\nSaving file: train_data_20220731_11.csv\nGetting data for: 20220731\nSaving file: train_data_20220731_12.csv\nSaving file: train_data_20220731_13.csv\nSaving file: train_data_20220731_14.csv\nSaving file: train_data_20220731_15.csv\nSaving file: train_data_20220731_16.csv\nSaving file: train_data_20220731_17.csv\nSaving file: train_data_20220731_18.csv\nSaving file: train_data_20220731_19.csv\nSaving file: train_data_20220731_20.csv\nSaving file: train_data_20220731_21.csv\nSaving file: train_data_20220731_22.csv\nSaving file: train_data_20220731_23.csv\nSaving file: train_data_20220801_00.csv\nSaving file: train_data_20220801_01.csv\nSaving file: train_data_20220801_02.csv\nSaving file: train_data_20220801_03.csv\nSaving file: train_data_20220801_04.csv\nSaving file: train_data_20220801_05.csv\nSaving file: train_data_20220801_06.csv\nSaving file: train_data_20220801_07.csv\nSaving file: train_data_20220801_08.csv\nSaving file: train_data_20220801_09.csv\nSaving file: train_data_20220801_10.csv\nSaving file: train_data_20220801_11.csv\nDone!\n",
  "history_begin_time" : 1660767780910,
  "history_end_time" : 1661385230262,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "nVJW7lPjGw4G",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220801\nSaving file: train_data_20220801_12.csv\nSaving file: train_data_20220801_13.csv\nSaving file: train_data_20220801_14.csv\nSaving file: train_data_20220801_15.csv\nSaving file: train_data_20220801_16.csv\nSaving file: train_data_20220801_17.csv\nSaving file: train_data_20220801_18.csv\nSaving file: train_data_20220801_19.csv\nSaving file: train_data_20220801_20.csv\nSaving file: train_data_20220801_21.csv\nSaving file: train_data_20220801_22.csv\nSaving file: train_data_20220801_23.csv\nSaving file: train_data_20220802_00.csv\nSaving file: train_data_20220802_01.csv\nSaving file: train_data_20220802_02.csv\nSaving file: train_data_20220802_03.csv\nSaving file: train_data_20220802_04.csv\nSaving file: train_data_20220802_05.csv\nSaving file: train_data_20220802_06.csv\nSaving file: train_data_20220802_07.csv\nSaving file: train_data_20220802_08.csv\nSaving file: train_data_20220802_09.csv\nSaving file: train_data_20220802_10.csv\nSaving file: train_data_20220802_11.csv\nGetting data for: 20220802\nSaving file: train_data_20220802_12.csv\nSaving file: train_data_20220802_13.csv\nSaving file: train_data_20220802_14.csv\nSaving file: train_data_20220802_15.csv\nSaving file: train_data_20220802_16.csv\nSaving file: train_data_20220802_17.csv\nSaving file: train_data_20220802_18.csv\nSaving file: train_data_20220802_19.csv\nSaving file: train_data_20220802_20.csv\nSaving file: train_data_20220802_21.csv\nSaving file: train_data_20220802_22.csv\nSaving file: train_data_20220802_23.csv\nSaving file: train_data_20220803_00.csv\nSaving file: train_data_20220803_01.csv\nSaving file: train_data_20220803_02.csv\nSaving file: train_data_20220803_03.csv\nSaving file: train_data_20220803_04.csv\nSaving file: train_data_20220803_05.csv\nSaving file: train_data_20220803_06.csv\nSaving file: train_data_20220803_07.csv\nSaving file: train_data_20220803_08.csv\nSaving file: train_data_20220803_09.csv\nSaving file: train_data_20220803_10.csv\nSaving file: train_data_20220803_11.csv\nDone!\n",
  "history_begin_time" : 1660749060210,
  "history_end_time" : 1660828759400,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "IH2VhObbit9B",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/GRIDCRO2D_'+current_day+'.nc')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nDone!\n",
  "history_begin_time" : 1660681886781,
  "history_end_time" : 1661385229342,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "BbcBPd0NGQ1t",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 5)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_00.csv\nSaving file: train_data_20220704_01.csv\nSaving file: train_data_20220704_02.csv\nSaving file: train_data_20220704_03.csv\nSaving file: train_data_20220704_04.csv\nSaving file: train_data_20220704_05.csv\nSaving file: train_data_20220704_06.csv\nSaving file: train_data_20220704_07.csv\nSaving file: train_data_20220704_08.csv\nSaving file: train_data_20220704_09.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_00.csv\nSaving file: train_data_20220705_01.csv\nSaving file: train_data_20220705_02.csv\nSaving file: train_data_20220705_03.csv\nSaving file: train_data_20220705_04.csv\nSaving file: train_data_20220705_05.csv\nSaving file: train_data_20220705_06.csv\nSaving file: train_data_20220705_07.csv\nSaving file: train_data_20220705_08.csv\nSaving file: train_data_20220705_09.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_00.csv\nSaving file: train_data_20220706_01.csv\nSaving file: train_data_20220706_02.csv\nSaving file: train_data_20220706_03.csv\nSaving file: train_data_20220706_04.csv\nSaving file: train_data_20220706_05.csv\nSaving file: train_data_20220706_06.csv\nSaving file: train_data_20220706_07.csv\nSaving file: train_data_20220706_08.csv\nSaving file: train_data_20220706_09.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nDone!\n",
  "history_begin_time" : 1660677652009,
  "history_end_time" : 1661385228756,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "kjUbDTZnqOzL",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 5)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][k,k]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n#     # NO2\n#     no2=df_cmaq.variables['NO2'][:].values[k,0]\n#     cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n#     # CO\n#     co=df_cmaq.variables['CO'][:].values[k,0]\n#     cmaq_CO=list(np.ravel(co).transpose().round())\n    \n#     # PM25_CO\n#     pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n#     cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n#     # EMIS data\n#     co_emis=df_emis.variables['CO'][:].values[k,0]\n#     CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n#     # MCIP data\n#     # CO variable\n#     prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n#     PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n#     # NO2\n#     pbl=df_mcip.variables['PBL'][:].values[k,0]\n#     PBL=list(np.ravel(pbl).transpose().round())\n    \n#     # TEMP2\n#     temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n#     TEMP2=list(np.ravel(temp2).transpose().round())\n    \n#     # WSPD10\n#     wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n#     WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n#     # WDIR10\n#     wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n#     WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n#     # RGRND\n#     rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n#     RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n#     # CFRAC\n#     cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n#     CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n#     df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n#     df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n#     df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n#     df_hourly['CO(moles/s)'] = CO_emi\n#     df_hourly['PRSFC(Pa)'] = PRSFC\n#     df_hourly['PBL(m)'] = PBL\n#     df_hourly['TEMP2(K)'] = TEMP2\n#     df_hourly['WSPD10(m/s)'] = WSPD10\n#     df_hourly['WDIR10(degree)'] = WDIR10\n#     df_hourly['RGRND(W/m2)'] = RGRND\n#     df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_00.csv\nSaving file: train_data_20220704_01.csv\nSaving file: train_data_20220704_02.csv\nSaving file: train_data_20220704_03.csv\nSaving file: train_data_20220704_04.csv\nSaving file: train_data_20220704_05.csv\nSaving file: train_data_20220704_06.csv\nSaving file: train_data_20220704_07.csv\nSaving file: train_data_20220704_08.csv\nSaving file: train_data_20220704_09.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_00.csv\nSaving file: train_data_20220705_01.csv\nSaving file: train_data_20220705_02.csv\nSaving file: train_data_20220705_03.csv\nSaving file: train_data_20220705_04.csv\nSaving file: train_data_20220705_05.csv\nSaving file: train_data_20220705_06.csv\nSaving file: train_data_20220705_07.csv\nSaving file: train_data_20220705_08.csv\nSaving file: train_data_20220705_09.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_00.csv\nSaving file: train_data_20220706_01.csv\nSaving file: train_data_20220706_02.csv\nSaving file: train_data_20220706_03.csv\nSaving file: train_data_20220706_04.csv\nSaving file: train_data_20220706_05.csv\nSaving file: train_data_20220706_06.csv\nSaving file: train_data_20220706_07.csv\nSaving file: train_data_20220706_08.csv\nSaving file: train_data_20220706_09.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nDone!\n",
  "history_begin_time" : 1660673978268,
  "history_end_time" : 1660677619519,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "lpzeASA2jbaG",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][k,k]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n#     # NO2\n#     no2=df_cmaq.variables['NO2'][:].values[k,0]\n#     cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n#     # CO\n#     co=df_cmaq.variables['CO'][:].values[k,0]\n#     cmaq_CO=list(np.ravel(co).transpose().round())\n    \n#     # PM25_CO\n#     pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n#     cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n#     # EMIS data\n#     co_emis=df_emis.variables['CO'][:].values[k,0]\n#     CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n#     # MCIP data\n#     # CO variable\n#     prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n#     PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n#     # NO2\n#     pbl=df_mcip.variables['PBL'][:].values[k,0]\n#     PBL=list(np.ravel(pbl).transpose().round())\n    \n#     # TEMP2\n#     temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n#     TEMP2=list(np.ravel(temp2).transpose().round())\n    \n#     # WSPD10\n#     wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n#     WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n#     # WDIR10\n#     wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n#     WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n#     # RGRND\n#     rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n#     RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n#     # CFRAC\n#     cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n#     CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n#     df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n#     df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n#     df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n#     df_hourly['CO(moles/s)'] = CO_emi\n#     df_hourly['PRSFC(Pa)'] = PRSFC\n#     df_hourly['PBL(m)'] = PBL\n#     df_hourly['TEMP2(K)'] = TEMP2\n#     df_hourly['WSPD10(m/s)'] = WSPD10\n#     df_hourly['WDIR10(degree)'] = WDIR10\n#     df_hourly['RGRND(W/m2)'] = RGRND\n#     df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_00.csv\nSaving file: train_data_20220704_01.csv\nSaving file: train_data_20220704_02.csv\nSaving file: train_data_20220704_03.csv\nSaving file: train_data_20220704_04.csv\nSaving file: train_data_20220704_05.csv\nSaving file: train_data_20220704_06.csv\nSaving file: train_data_20220704_07.csv\nSaving file: train_data_20220704_08.csv\nSaving file: train_data_20220704_09.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_00.csv\nSaving file: train_data_20220705_01.csv\nSaving file: train_data_20220705_02.csv\nSaving file: train_data_20220705_03.csv\nSaving file: train_data_20220705_04.csv\nSaving file: train_data_20220705_05.csv\nSaving file: train_data_20220705_06.csv\nSaving file: train_data_20220705_07.csv\nSaving file: train_data_20220705_08.csv\nSaving file: train_data_20220705_09.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_00.csv\nSaving file: train_data_20220706_01.csv\nSaving file: train_data_20220706_02.csv\nSaving file: train_data_20220706_03.csv\nSaving file: train_data_20220706_04.csv\nSaving file: train_data_20220706_05.csv\nSaving file: train_data_20220706_06.csv\nSaving file: train_data_20220706_07.csv\nSaving file: train_data_20220706_08.csv\nSaving file: train_data_20220706_09.csv\nSaving file: train_data_20220706_10.csv\n",
  "history_begin_time" : 1660673893577,
  "history_end_time" : 1660674003627,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "Cbwi2fTEzAJC",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220801\nSaving file: train_data_20220801_12.csv\nSaving file: train_data_20220801_13.csv\nSaving file: train_data_20220801_14.csv\nSaving file: train_data_20220801_15.csv\nSaving file: train_data_20220801_16.csv\nSaving file: train_data_20220801_17.csv\nSaving file: train_data_20220801_18.csv\nSaving file: train_data_20220801_19.csv\nSaving file: train_data_20220801_20.csv\nSaving file: train_data_20220801_21.csv\nSaving file: train_data_20220801_22.csv\nSaving file: train_data_20220801_23.csv\nSaving file: train_data_20220802_00.csv\nSaving file: train_data_20220802_01.csv\nSaving file: train_data_20220802_02.csv\nSaving file: train_data_20220802_03.csv\nSaving file: train_data_20220802_04.csv\nSaving file: train_data_20220802_05.csv\nSaving file: train_data_20220802_06.csv\nSaving file: train_data_20220802_07.csv\nSaving file: train_data_20220802_08.csv\nSaving file: train_data_20220802_09.csv\nSaving file: train_data_20220802_10.csv\nSaving file: train_data_20220802_11.csv\nGetting data for: 20220802\nSaving file: train_data_20220802_12.csv\nSaving file: train_data_20220802_13.csv\nSaving file: train_data_20220802_14.csv\nSaving file: train_data_20220802_15.csv\nSaving file: train_data_20220802_16.csv\nSaving file: train_data_20220802_17.csv\nSaving file: train_data_20220802_18.csv\nSaving file: train_data_20220802_19.csv\nSaving file: train_data_20220802_20.csv\nSaving file: train_data_20220802_21.csv\nSaving file: train_data_20220802_22.csv\nSaving file: train_data_20220802_23.csv\nSaving file: train_data_20220803_00.csv\nSaving file: train_data_20220803_01.csv\nSaving file: train_data_20220803_02.csv\nSaving file: train_data_20220803_03.csv\nSaving file: train_data_20220803_04.csv\nSaving file: train_data_20220803_05.csv\nSaving file: train_data_20220803_06.csv\nSaving file: train_data_20220803_07.csv\nSaving file: train_data_20220803_08.csv\nSaving file: train_data_20220803_09.csv\nSaving file: train_data_20220803_10.csv\nSaving file: train_data_20220803_11.csv\nDone!\n",
  "history_begin_time" : 1660522012120,
  "history_end_time" : 1660828758934,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "Euk5DYqU4sl6",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_00.csv\nSaving file: train_data_20220704_01.csv\nSaving file: train_data_20220704_02.csv\nSaving file: train_data_20220704_03.csv\nSaving file: train_data_20220704_04.csv\nSaving file: train_data_20220704_05.csv\nSaving file: train_data_20220704_06.csv\nSaving file: train_data_20220704_07.csv\nSaving file: train_data_20220704_08.csv\nSaving file: train_data_20220704_09.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_00.csv\nSaving file: train_data_20220705_01.csv\nSaving file: train_data_20220705_02.csv\nSaving file: train_data_20220705_03.csv\nSaving file: train_data_20220705_04.csv\nSaving file: train_data_20220705_05.csv\nSaving file: train_data_20220705_06.csv\nSaving file: train_data_20220705_07.csv\nSaving file: train_data_20220705_08.csv\nSaving file: train_data_20220705_09.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_00.csv\nSaving file: train_data_20220706_01.csv\nSaving file: train_data_20220706_02.csv\nSaving file: train_data_20220706_03.csv\nSaving file: train_data_20220706_04.csv\nSaving file: train_data_20220706_05.csv\nSaving file: train_data_20220706_06.csv\nSaving file: train_data_20220706_07.csv\nSaving file: train_data_20220706_08.csv\nSaving file: train_data_20220706_09.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220707_00.csv\nSaving file: train_data_20220707_01.csv\nSaving file: train_data_20220707_02.csv\nSaving file: train_data_20220707_03.csv\nSaving file: train_data_20220707_04.csv\nSaving file: train_data_20220707_05.csv\nSaving file: train_data_20220707_06.csv\nSaving file: train_data_20220707_07.csv\nSaving file: train_data_20220707_08.csv\nSaving file: train_data_20220707_09.csv\nSaving file: train_data_20220707_10.csv\nSaving file: train_data_20220707_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220708_00.csv\nSaving file: train_data_20220708_01.csv\nSaving file: train_data_20220708_02.csv\nSaving file: train_data_20220708_03.csv\nSaving file: train_data_20220708_04.csv\nSaving file: train_data_20220708_05.csv\nSaving file: train_data_20220708_06.csv\nSaving file: train_data_20220708_07.csv\nSaving file: train_data_20220708_08.csv\nSaving file: train_data_20220708_09.csv\nSaving file: train_data_20220708_10.csv\nSaving file: train_data_20220708_11.csv\nGetting data for: 20220708\nSaving file: train_data_20220708_12.csv\nSaving file: train_data_20220708_13.csv\nSaving file: train_data_20220708_14.csv\nSaving file: train_data_20220708_15.csv\nSaving file: train_data_20220708_16.csv\nSaving file: train_data_20220708_17.csv\nSaving file: train_data_20220708_18.csv\nSaving file: train_data_20220708_19.csv\nSaving file: train_data_20220708_20.csv\nSaving file: train_data_20220708_21.csv\nSaving file: train_data_20220708_22.csv\nSaving file: train_data_20220708_23.csv\nSaving file: train_data_20220709_00.csv\nSaving file: train_data_20220709_01.csv\nSaving file: train_data_20220709_02.csv\nSaving file: train_data_20220709_03.csv\nSaving file: train_data_20220709_04.csv\nSaving file: train_data_20220709_05.csv\nSaving file: train_data_20220709_06.csv\nSaving file: train_data_20220709_07.csv\nSaving file: train_data_20220709_08.csv\nSaving file: train_data_20220709_09.csv\nSaving file: train_data_20220709_10.csv\nSaving file: train_data_20220709_11.csv\nGetting data for: 20220709\nSaving file: train_data_20220709_12.csv\nSaving file: train_data_20220709_13.csv\nSaving file: train_data_20220709_14.csv\nSaving file: train_data_20220709_15.csv\nSaving file: train_data_20220709_16.csv\nSaving file: train_data_20220709_17.csv\nSaving file: train_data_20220709_18.csv\nSaving file: train_data_20220709_19.csv\nSaving file: train_data_20220709_20.csv\nSaving file: train_data_20220709_21.csv\nSaving file: train_data_20220709_22.csv\nSaving file: train_data_20220709_23.csv\nSaving file: train_data_20220710_00.csv\nSaving file: train_data_20220710_01.csv\nSaving file: train_data_20220710_02.csv\nSaving file: train_data_20220710_03.csv\nSaving file: train_data_20220710_04.csv\nSaving file: train_data_20220710_05.csv\nSaving file: train_data_20220710_06.csv\nSaving file: train_data_20220710_07.csv\nSaving file: train_data_20220710_08.csv\nSaving file: train_data_20220710_09.csv\nSaving file: train_data_20220710_10.csv\nSaving file: train_data_20220710_11.csv\nGetting data for: 20220710\nSaving file: train_data_20220710_12.csv\nSaving file: train_data_20220710_13.csv\nSaving file: train_data_20220710_14.csv\nSaving file: train_data_20220710_15.csv\nSaving file: train_data_20220710_16.csv\nSaving file: train_data_20220710_17.csv\nSaving file: train_data_20220710_18.csv\nSaving file: train_data_20220710_19.csv\nSaving file: train_data_20220710_20.csv\nSaving file: train_data_20220710_21.csv\nSaving file: train_data_20220710_22.csv\nSaving file: train_data_20220710_23.csv\nSaving file: train_data_20220711_00.csv\nSaving file: train_data_20220711_01.csv\nSaving file: train_data_20220711_02.csv\nSaving file: train_data_20220711_03.csv\nSaving file: train_data_20220711_04.csv\nSaving file: train_data_20220711_05.csv\nSaving file: train_data_20220711_06.csv\nSaving file: train_data_20220711_07.csv\nSaving file: train_data_20220711_08.csv\nSaving file: train_data_20220711_09.csv\nSaving file: train_data_20220711_10.csv\nSaving file: train_data_20220711_11.csv\nGetting data for: 20220711\nSaving file: train_data_20220711_12.csv\nSaving file: train_data_20220711_13.csv\nSaving file: train_data_20220711_14.csv\nSaving file: train_data_20220711_15.csv\nSaving file: train_data_20220711_16.csv\nSaving file: train_data_20220711_17.csv\nSaving file: train_data_20220711_18.csv\nSaving file: train_data_20220711_19.csv\nSaving file: train_data_20220711_20.csv\nSaving file: train_data_20220711_21.csv\nSaving file: train_data_20220711_22.csv\nSaving file: train_data_20220711_23.csv\nSaving file: train_data_20220712_00.csv\nSaving file: train_data_20220712_01.csv\nSaving file: train_data_20220712_02.csv\nSaving file: train_data_20220712_03.csv\nSaving file: train_data_20220712_04.csv\nSaving file: train_data_20220712_05.csv\nSaving file: train_data_20220712_06.csv\nSaving file: train_data_20220712_07.csv\nSaving file: train_data_20220712_08.csv\nSaving file: train_data_20220712_09.csv\nSaving file: train_data_20220712_10.csv\nSaving file: train_data_20220712_11.csv\nGetting data for: 20220712\nSaving file: train_data_20220712_12.csv\nSaving file: train_data_20220712_13.csv\nSaving file: train_data_20220712_14.csv\nSaving file: train_data_20220712_15.csv\nSaving file: train_data_20220712_16.csv\nSaving file: train_data_20220712_17.csv\nSaving file: train_data_20220712_18.csv\nSaving file: train_data_20220712_19.csv\nSaving file: train_data_20220712_20.csv\nSaving file: train_data_20220712_21.csv\nSaving file: train_data_20220712_22.csv\nSaving file: train_data_20220712_23.csv\nSaving file: train_data_20220713_00.csv\nSaving file: train_data_20220713_01.csv\nSaving file: train_data_20220713_02.csv\nSaving file: train_data_20220713_03.csv\nSaving file: train_data_20220713_04.csv\nSaving file: train_data_20220713_05.csv\nSaving file: train_data_20220713_06.csv\nSaving file: train_data_20220713_07.csv\nSaving file: train_data_20220713_08.csv\nSaving file: train_data_20220713_09.csv\nSaving file: train_data_20220713_10.csv\nSaving file: train_data_20220713_11.csv\nGetting data for: 20220713\nSaving file: train_data_20220713_12.csv\nSaving file: train_data_20220713_13.csv\nSaving file: train_data_20220713_14.csv\nSaving file: train_data_20220713_15.csv\nSaving file: train_data_20220713_16.csv\nSaving file: train_data_20220713_17.csv\nSaving file: train_data_20220713_18.csv\nSaving file: train_data_20220713_19.csv\nSaving file: train_data_20220713_20.csv\nSaving file: train_data_20220713_21.csv\nSaving file: train_data_20220713_22.csv\nSaving file: train_data_20220713_23.csv\nSaving file: train_data_20220714_00.csv\nSaving file: train_data_20220714_01.csv\nSaving file: train_data_20220714_02.csv\nSaving file: train_data_20220714_03.csv\nSaving file: train_data_20220714_04.csv\nSaving file: train_data_20220714_05.csv\nSaving file: train_data_20220714_06.csv\nSaving file: train_data_20220714_07.csv\nSaving file: train_data_20220714_08.csv\nSaving file: train_data_20220714_09.csv\nSaving file: train_data_20220714_10.csv\nSaving file: train_data_20220714_11.csv\nGetting data for: 20220714\nSaving file: train_data_20220714_12.csv\nSaving file: train_data_20220714_13.csv\nSaving file: train_data_20220714_14.csv\nSaving file: train_data_20220714_15.csv\nSaving file: train_data_20220714_16.csv\nSaving file: train_data_20220714_17.csv\nSaving file: train_data_20220714_18.csv\nSaving file: train_data_20220714_19.csv\nSaving file: train_data_20220714_20.csv\nSaving file: train_data_20220714_21.csv\nSaving file: train_data_20220714_22.csv\nSaving file: train_data_20220714_23.csv\nSaving file: train_data_20220715_00.csv\nSaving file: train_data_20220715_01.csv\nSaving file: train_data_20220715_02.csv\nSaving file: train_data_20220715_03.csv\nSaving file: train_data_20220715_04.csv\nSaving file: train_data_20220715_05.csv\nSaving file: train_data_20220715_06.csv\nSaving file: train_data_20220715_07.csv\nSaving file: train_data_20220715_08.csv\nSaving file: train_data_20220715_09.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220716_00.csv\nSaving file: train_data_20220716_01.csv\nSaving file: train_data_20220716_02.csv\nSaving file: train_data_20220716_03.csv\nSaving file: train_data_20220716_04.csv\nSaving file: train_data_20220716_05.csv\nSaving file: train_data_20220716_06.csv\nSaving file: train_data_20220716_07.csv\nSaving file: train_data_20220716_08.csv\nSaving file: train_data_20220716_09.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220717_00.csv\nSaving file: train_data_20220717_01.csv\nSaving file: train_data_20220717_02.csv\nSaving file: train_data_20220717_03.csv\nSaving file: train_data_20220717_04.csv\nSaving file: train_data_20220717_05.csv\nSaving file: train_data_20220717_06.csv\nSaving file: train_data_20220717_07.csv\nSaving file: train_data_20220717_08.csv\nSaving file: train_data_20220717_09.csv\nSaving file: train_data_20220717_10.csv\nSaving file: train_data_20220717_11.csv\nGetting data for: 20220717\nSaving file: train_data_20220717_12.csv\nSaving file: train_data_20220717_13.csv\nSaving file: train_data_20220717_14.csv\nSaving file: train_data_20220717_15.csv\nSaving file: train_data_20220717_16.csv\nSaving file: train_data_20220717_17.csv\nSaving file: train_data_20220717_18.csv\nSaving file: train_data_20220717_19.csv\nSaving file: train_data_20220717_20.csv\nSaving file: train_data_20220717_21.csv\nSaving file: train_data_20220717_22.csv\nSaving file: train_data_20220717_23.csv\nSaving file: train_data_20220718_00.csv\nSaving file: train_data_20220718_01.csv\nSaving file: train_data_20220718_02.csv\nSaving file: train_data_20220718_03.csv\nSaving file: train_data_20220718_04.csv\nSaving file: train_data_20220718_05.csv\nSaving file: train_data_20220718_06.csv\nSaving file: train_data_20220718_07.csv\nSaving file: train_data_20220718_08.csv\nSaving file: train_data_20220718_09.csv\nSaving file: train_data_20220718_10.csv\nSaving file: train_data_20220718_11.csv\nGetting data for: 20220718\nSaving file: train_data_20220718_12.csv\nSaving file: train_data_20220718_13.csv\nSaving file: train_data_20220718_14.csv\nSaving file: train_data_20220718_15.csv\nSaving file: train_data_20220718_16.csv\nSaving file: train_data_20220718_17.csv\nSaving file: train_data_20220718_18.csv\nSaving file: train_data_20220718_19.csv\nSaving file: train_data_20220718_20.csv\nSaving file: train_data_20220718_21.csv\nSaving file: train_data_20220718_22.csv\nSaving file: train_data_20220718_23.csv\nSaving file: train_data_20220719_00.csv\nSaving file: train_data_20220719_01.csv\nSaving file: train_data_20220719_02.csv\nSaving file: train_data_20220719_03.csv\nSaving file: train_data_20220719_04.csv\nSaving file: train_data_20220719_05.csv\nSaving file: train_data_20220719_06.csv\nSaving file: train_data_20220719_07.csv\nSaving file: train_data_20220719_08.csv\nSaving file: train_data_20220719_09.csv\nSaving file: train_data_20220719_10.csv\nSaving file: train_data_20220719_11.csv\nGetting data for: 20220719\nSaving file: train_data_20220719_12.csv\nSaving file: train_data_20220719_13.csv\nSaving file: train_data_20220719_14.csv\nSaving file: train_data_20220719_15.csv\nSaving file: train_data_20220719_16.csv\nSaving file: train_data_20220719_17.csv\nSaving file: train_data_20220719_18.csv\nSaving file: train_data_20220719_19.csv\nSaving file: train_data_20220719_20.csv\nSaving file: train_data_20220719_21.csv\nSaving file: train_data_20220719_22.csv\nSaving file: train_data_20220719_23.csv\nSaving file: train_data_20220720_00.csv\nSaving file: train_data_20220720_01.csv\nSaving file: train_data_20220720_02.csv\nSaving file: train_data_20220720_03.csv\nSaving file: train_data_20220720_04.csv\nSaving file: train_data_20220720_05.csv\nSaving file: train_data_20220720_06.csv\nSaving file: train_data_20220720_07.csv\nSaving file: train_data_20220720_08.csv\nSaving file: train_data_20220720_09.csv\nSaving file: train_data_20220720_10.csv\nSaving file: train_data_20220720_11.csv\nGetting data for: 20220720\nSaving file: train_data_20220720_12.csv\nSaving file: train_data_20220720_13.csv\nSaving file: train_data_20220720_14.csv\nSaving file: train_data_20220720_15.csv\nSaving file: train_data_20220720_16.csv\nSaving file: train_data_20220720_17.csv\nSaving file: train_data_20220720_18.csv\nSaving file: train_data_20220720_19.csv\nSaving file: train_data_20220720_20.csv\nSaving file: train_data_20220720_21.csv\nSaving file: train_data_20220720_22.csv\nSaving file: train_data_20220720_23.csv\nSaving file: train_data_20220721_00.csv\nSaving file: train_data_20220721_01.csv\nSaving file: train_data_20220721_02.csv\nSaving file: train_data_20220721_03.csv\nSaving file: train_data_20220721_04.csv\nSaving file: train_data_20220721_05.csv\nSaving file: train_data_20220721_06.csv\nSaving file: train_data_20220721_07.csv\nSaving file: train_data_20220721_08.csv\nSaving file: train_data_20220721_09.csv\nSaving file: train_data_20220721_10.csv\nSaving file: train_data_20220721_11.csv\nGetting data for: 20220721\nSaving file: train_data_20220721_12.csv\nSaving file: train_data_20220721_13.csv\nSaving file: train_data_20220721_14.csv\nSaving file: train_data_20220721_15.csv\nSaving file: train_data_20220721_16.csv\nSaving file: train_data_20220721_17.csv\nSaving file: train_data_20220721_18.csv\nSaving file: train_data_20220721_19.csv\nSaving file: train_data_20220721_20.csv\nSaving file: train_data_20220721_21.csv\nSaving file: train_data_20220721_22.csv\nSaving file: train_data_20220721_23.csv\nSaving file: train_data_20220722_00.csv\nSaving file: train_data_20220722_01.csv\nSaving file: train_data_20220722_02.csv\nSaving file: train_data_20220722_03.csv\nSaving file: train_data_20220722_04.csv\nSaving file: train_data_20220722_05.csv\nSaving file: train_data_20220722_06.csv\nSaving file: train_data_20220722_07.csv\nSaving file: train_data_20220722_08.csv\nSaving file: train_data_20220722_09.csv\nSaving file: train_data_20220722_10.csv\nSaving file: train_data_20220722_11.csv\nGetting data for: 20220722\nSaving file: train_data_20220722_12.csv\nSaving file: train_data_20220722_13.csv\nSaving file: train_data_20220722_14.csv\nSaving file: train_data_20220722_15.csv\nSaving file: train_data_20220722_16.csv\nSaving file: train_data_20220722_17.csv\nSaving file: train_data_20220722_18.csv\nSaving file: train_data_20220722_19.csv\nSaving file: train_data_20220722_20.csv\nSaving file: train_data_20220722_21.csv\nSaving file: train_data_20220722_22.csv\nSaving file: train_data_20220722_23.csv\nSaving file: train_data_20220723_00.csv\nSaving file: train_data_20220723_01.csv\nSaving file: train_data_20220723_02.csv\nSaving file: train_data_20220723_03.csv\nSaving file: train_data_20220723_04.csv\nSaving file: train_data_20220723_05.csv\nSaving file: train_data_20220723_06.csv\nSaving file: train_data_20220723_07.csv\nSaving file: train_data_20220723_08.csv\nSaving file: train_data_20220723_09.csv\nSaving file: train_data_20220723_10.csv\nSaving file: train_data_20220723_11.csv\nGetting data for: 20220723\nSaving file: train_data_20220723_12.csv\nSaving file: train_data_20220723_13.csv\nSaving file: train_data_20220723_14.csv\nSaving file: train_data_20220723_15.csv\nSaving file: train_data_20220723_16.csv\nSaving file: train_data_20220723_17.csv\nSaving file: train_data_20220723_18.csv\nSaving file: train_data_20220723_19.csv\nSaving file: train_data_20220723_20.csv\nSaving file: train_data_20220723_21.csv\nSaving file: train_data_20220723_22.csv\nSaving file: train_data_20220723_23.csv\nSaving file: train_data_20220724_00.csv\nSaving file: train_data_20220724_01.csv\nSaving file: train_data_20220724_02.csv\nSaving file: train_data_20220724_03.csv\nSaving file: train_data_20220724_04.csv\nSaving file: train_data_20220724_05.csv\nSaving file: train_data_20220724_06.csv\nSaving file: train_data_20220724_07.csv\nSaving file: train_data_20220724_08.csv\nSaving file: train_data_20220724_09.csv\nSaving file: train_data_20220724_10.csv\nSaving file: train_data_20220724_11.csv\nGetting data for: 20220724\nSaving file: train_data_20220724_12.csv\nSaving file: train_data_20220724_13.csv\nSaving file: train_data_20220724_14.csv\nSaving file: train_data_20220724_15.csv\nSaving file: train_data_20220724_16.csv\nSaving file: train_data_20220724_17.csv\nSaving file: train_data_20220724_18.csv\nSaving file: train_data_20220724_19.csv\nSaving file: train_data_20220724_20.csv\nSaving file: train_data_20220724_21.csv\nSaving file: train_data_20220724_22.csv\nSaving file: train_data_20220724_23.csv\nSaving file: train_data_20220725_00.csv\nSaving file: train_data_20220725_01.csv\nSaving file: train_data_20220725_02.csv\nSaving file: train_data_20220725_03.csv\nSaving file: train_data_20220725_04.csv\nSaving file: train_data_20220725_05.csv\nSaving file: train_data_20220725_06.csv\nSaving file: train_data_20220725_07.csv\nSaving file: train_data_20220725_08.csv\nSaving file: train_data_20220725_09.csv\nSaving file: train_data_20220725_10.csv\nSaving file: train_data_20220725_11.csv\nGetting data for: 20220725\nSaving file: train_data_20220725_12.csv\nSaving file: train_data_20220725_13.csv\nSaving file: train_data_20220725_14.csv\nSaving file: train_data_20220725_15.csv\nSaving file: train_data_20220725_16.csv\nSaving file: train_data_20220725_17.csv\nSaving file: train_data_20220725_18.csv\nSaving file: train_data_20220725_19.csv\nSaving file: train_data_20220725_20.csv\nSaving file: train_data_20220725_21.csv\nSaving file: train_data_20220725_22.csv\nSaving file: train_data_20220725_23.csv\nSaving file: train_data_20220726_00.csv\nSaving file: train_data_20220726_01.csv\nSaving file: train_data_20220726_02.csv\nSaving file: train_data_20220726_03.csv\nSaving file: train_data_20220726_04.csv\nSaving file: train_data_20220726_05.csv\nSaving file: train_data_20220726_06.csv\nSaving file: train_data_20220726_07.csv\nSaving file: train_data_20220726_08.csv\nSaving file: train_data_20220726_09.csv\nSaving file: train_data_20220726_10.csv\nSaving file: train_data_20220726_11.csv\nGetting data for: 20220726\nSaving file: train_data_20220726_12.csv\nSaving file: train_data_20220726_13.csv\nSaving file: train_data_20220726_14.csv\nSaving file: train_data_20220726_15.csv\nSaving file: train_data_20220726_16.csv\nSaving file: train_data_20220726_17.csv\nSaving file: train_data_20220726_18.csv\nSaving file: train_data_20220726_19.csv\nSaving file: train_data_20220726_20.csv\nSaving file: train_data_20220726_21.csv\nSaving file: train_data_20220726_22.csv\nSaving file: train_data_20220726_23.csv\nSaving file: train_data_20220727_00.csv\nSaving file: train_data_20220727_01.csv\nSaving file: train_data_20220727_02.csv\nSaving file: train_data_20220727_03.csv\nSaving file: train_data_20220727_04.csv\nSaving file: train_data_20220727_05.csv\nSaving file: train_data_20220727_06.csv\nSaving file: train_data_20220727_07.csv\nSaving file: train_data_20220727_08.csv\nSaving file: train_data_20220727_09.csv\nSaving file: train_data_20220727_10.csv\nSaving file: train_data_20220727_11.csv\nGetting data for: 20220727\nSaving file: train_data_20220727_12.csv\nSaving file: train_data_20220727_13.csv\nSaving file: train_data_20220727_14.csv\nSaving file: train_data_20220727_15.csv\nSaving file: train_data_20220727_16.csv\nSaving file: train_data_20220727_17.csv\nSaving file: train_data_20220727_18.csv\nSaving file: train_data_20220727_19.csv\nSaving file: train_data_20220727_20.csv\nSaving file: train_data_20220727_21.csv\nSaving file: train_data_20220727_22.csv\nSaving file: train_data_20220727_23.csv\nSaving file: train_data_20220728_00.csv\nSaving file: train_data_20220728_01.csv\nSaving file: train_data_20220728_02.csv\nSaving file: train_data_20220728_03.csv\nSaving file: train_data_20220728_04.csv\nSaving file: train_data_20220728_05.csv\nSaving file: train_data_20220728_06.csv\nSaving file: train_data_20220728_07.csv\nSaving file: train_data_20220728_08.csv\nSaving file: train_data_20220728_09.csv\nSaving file: train_data_20220728_10.csv\nSaving file: train_data_20220728_11.csv\nGetting data for: 20220728\nSaving file: train_data_20220728_12.csv\nSaving file: train_data_20220728_13.csv\nSaving file: train_data_20220728_14.csv\nSaving file: train_data_20220728_15.csv\nSaving file: train_data_20220728_16.csv\nSaving file: train_data_20220728_17.csv\nSaving file: train_data_20220728_18.csv\nSaving file: train_data_20220728_19.csv\nSaving file: train_data_20220728_20.csv\nSaving file: train_data_20220728_21.csv\nSaving file: train_data_20220728_22.csv\nSaving file: train_data_20220728_23.csv\nSaving file: train_data_20220729_00.csv\nSaving file: train_data_20220729_01.csv\nSaving file: train_data_20220729_02.csv\nSaving file: train_data_20220729_03.csv\nSaving file: train_data_20220729_04.csv\nSaving file: train_data_20220729_05.csv\nSaving file: train_data_20220729_06.csv\nSaving file: train_data_20220729_07.csv\nSaving file: train_data_20220729_08.csv\nSaving file: train_data_20220729_09.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220730_00.csv\nSaving file: train_data_20220730_01.csv\nSaving file: train_data_20220730_02.csv\nSaving file: train_data_20220730_03.csv\nSaving file: train_data_20220730_04.csv\nSaving file: train_data_20220730_05.csv\nSaving file: train_data_20220730_06.csv\nSaving file: train_data_20220730_07.csv\nSaving file: train_data_20220730_08.csv\nSaving file: train_data_20220730_09.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220731_00.csv\nSaving file: train_data_20220731_01.csv\nSaving file: train_data_20220731_02.csv\nSaving file: train_data_20220731_03.csv\nSaving file: train_data_20220731_04.csv\nSaving file: train_data_20220731_05.csv\nSaving file: train_data_20220731_06.csv\nSaving file: train_data_20220731_07.csv\nSaving file: train_data_20220731_08.csv\nSaving file: train_data_20220731_09.csv\nSaving file: train_data_20220731_10.csv\nSaving file: train_data_20220731_11.csv\nGetting data for: 20220731\nSaving file: train_data_20220731_12.csv\nSaving file: train_data_20220731_13.csv\nSaving file: train_data_20220731_14.csv\nSaving file: train_data_20220731_15.csv\nSaving file: train_data_20220731_16.csv\nSaving file: train_data_20220731_17.csv\nSaving file: train_data_20220731_18.csv\nSaving file: train_data_20220731_19.csv\nSaving file: train_data_20220731_20.csv\nSaving file: train_data_20220731_21.csv\nSaving file: train_data_20220731_22.csv\nSaving file: train_data_20220731_23.csv\nSaving file: train_data_20220801_00.csv\nSaving file: train_data_20220801_01.csv\nSaving file: train_data_20220801_02.csv\nSaving file: train_data_20220801_03.csv\nSaving file: train_data_20220801_04.csv\nSaving file: train_data_20220801_05.csv\nSaving file: train_data_20220801_06.csv\nSaving file: train_data_20220801_07.csv\nSaving file: train_data_20220801_08.csv\nSaving file: train_data_20220801_09.csv\nSaving file: train_data_20220801_10.csv\nSaving file: train_data_20220801_11.csv\nDone!\n",
  "history_begin_time" : 1660366450547,
  "history_end_time" : 1660673957775,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "DzGAJgwl3kM0",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nTraceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 124, in <module>\n    df_hourly.to_csv(filename,index=False)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 241, in save\n    with get_handle(\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nPermissionError: [Errno 13] Permission denied: '/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_12.csv'\n",
  "history_begin_time" : 1660366273800,
  "history_end_time" : 1660673957328,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "RoTRxlBbTvtL",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : null,
  "history_begin_time" : 1660366176090,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "BSUOqc27Ik77",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+turn_2_digits(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{turn_2_digits(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{turn_2_digits(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_00.csv\nSaving file: train_data_20220702_01.csv\nSaving file: train_data_20220702_02.csv\nSaving file: train_data_20220702_03.csv\nSaving file: train_data_20220702_04.csv\nSaving file: train_data_20220702_05.csv\nSaving file: train_data_20220702_06.csv\nSaving file: train_data_20220702_07.csv\nSaving file: train_data_20220702_08.csv\nSaving file: train_data_20220702_09.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_00.csv\nSaving file: train_data_20220703_01.csv\nSaving file: train_data_20220703_02.csv\nSaving file: train_data_20220703_03.csv\nSaving file: train_data_20220703_04.csv\nSaving file: train_data_20220703_05.csv\nSaving file: train_data_20220703_06.csv\nSaving file: train_data_20220703_07.csv\nSaving file: train_data_20220703_08.csv\nSaving file: train_data_20220703_09.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nDone!\n",
  "history_begin_time" : 1660310756713,
  "history_end_time" : 1660828758383,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "i76ba4ihb8v",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'{cmaq_folder}/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_0.csv\nSaving file: train_data_20220703_1.csv\nSaving file: train_data_20220703_2.csv\nSaving file: train_data_20220703_3.csv\nSaving file: train_data_20220703_4.csv\nSaving file: train_data_20220703_5.csv\nSaving file: train_data_20220703_6.csv\nSaving file: train_data_20220703_7.csv\nSaving file: train_data_20220703_8.csv\nSaving file: train_data_20220703_9.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220704_0.csv\nSaving file: train_data_20220704_1.csv\nSaving file: train_data_20220704_2.csv\nSaving file: train_data_20220704_3.csv\nSaving file: train_data_20220704_4.csv\nSaving file: train_data_20220704_5.csv\nSaving file: train_data_20220704_6.csv\nSaving file: train_data_20220704_7.csv\nSaving file: train_data_20220704_8.csv\nSaving file: train_data_20220704_9.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220705_0.csv\nSaving file: train_data_20220705_1.csv\nSaving file: train_data_20220705_2.csv\nSaving file: train_data_20220705_3.csv\nSaving file: train_data_20220705_4.csv\nSaving file: train_data_20220705_5.csv\nSaving file: train_data_20220705_6.csv\nSaving file: train_data_20220705_7.csv\nSaving file: train_data_20220705_8.csv\nSaving file: train_data_20220705_9.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220706_0.csv\nSaving file: train_data_20220706_1.csv\nSaving file: train_data_20220706_2.csv\nSaving file: train_data_20220706_3.csv\nSaving file: train_data_20220706_4.csv\nSaving file: train_data_20220706_5.csv\nSaving file: train_data_20220706_6.csv\nSaving file: train_data_20220706_7.csv\nSaving file: train_data_20220706_8.csv\nSaving file: train_data_20220706_9.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220707_0.csv\nSaving file: train_data_20220707_1.csv\nSaving file: train_data_20220707_2.csv\nSaving file: train_data_20220707_3.csv\nSaving file: train_data_20220707_4.csv\nSaving file: train_data_20220707_5.csv\nSaving file: train_data_20220707_6.csv\nSaving file: train_data_20220707_7.csv\nSaving file: train_data_20220707_8.csv\nSaving file: train_data_20220707_9.csv\nSaving file: train_data_20220707_10.csv\nSaving file: train_data_20220707_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220708_0.csv\nSaving file: train_data_20220708_1.csv\nSaving file: train_data_20220708_2.csv\nSaving file: train_data_20220708_3.csv\nSaving file: train_data_20220708_4.csv\nSaving file: train_data_20220708_5.csv\nSaving file: train_data_20220708_6.csv\nSaving file: train_data_20220708_7.csv\nSaving file: train_data_20220708_8.csv\nSaving file: train_data_20220708_9.csv\nSaving file: train_data_20220708_10.csv\nSaving file: train_data_20220708_11.csv\nGetting data for: 20220708\nSaving file: train_data_20220708_12.csv\nSaving file: train_data_20220708_13.csv\nSaving file: train_data_20220708_14.csv\nSaving file: train_data_20220708_15.csv\nSaving file: train_data_20220708_16.csv\nSaving file: train_data_20220708_17.csv\nSaving file: train_data_20220708_18.csv\nSaving file: train_data_20220708_19.csv\nSaving file: train_data_20220708_20.csv\nSaving file: train_data_20220708_21.csv\nSaving file: train_data_20220708_22.csv\nSaving file: train_data_20220708_23.csv\nSaving file: train_data_20220709_0.csv\nSaving file: train_data_20220709_1.csv\nSaving file: train_data_20220709_2.csv\nSaving file: train_data_20220709_3.csv\nSaving file: train_data_20220709_4.csv\nSaving file: train_data_20220709_5.csv\nSaving file: train_data_20220709_6.csv\nSaving file: train_data_20220709_7.csv\nSaving file: train_data_20220709_8.csv\nSaving file: train_data_20220709_9.csv\nSaving file: train_data_20220709_10.csv\nSaving file: train_data_20220709_11.csv\nGetting data for: 20220709\nSaving file: train_data_20220709_12.csv\nSaving file: train_data_20220709_13.csv\nSaving file: train_data_20220709_14.csv\nSaving file: train_data_20220709_15.csv\nSaving file: train_data_20220709_16.csv\nSaving file: train_data_20220709_17.csv\nSaving file: train_data_20220709_18.csv\nSaving file: train_data_20220709_19.csv\nSaving file: train_data_20220709_20.csv\nSaving file: train_data_20220709_21.csv\nSaving file: train_data_20220709_22.csv\nSaving file: train_data_20220709_23.csv\nSaving file: train_data_20220710_0.csv\nSaving file: train_data_20220710_1.csv\nSaving file: train_data_20220710_2.csv\nSaving file: train_data_20220710_3.csv\nSaving file: train_data_20220710_4.csv\nSaving file: train_data_20220710_5.csv\nSaving file: train_data_20220710_6.csv\nSaving file: train_data_20220710_7.csv\nSaving file: train_data_20220710_8.csv\nSaving file: train_data_20220710_9.csv\nSaving file: train_data_20220710_10.csv\nSaving file: train_data_20220710_11.csv\nGetting data for: 20220710\nSaving file: train_data_20220710_12.csv\nSaving file: train_data_20220710_13.csv\nSaving file: train_data_20220710_14.csv\nSaving file: train_data_20220710_15.csv\nSaving file: train_data_20220710_16.csv\nSaving file: train_data_20220710_17.csv\nSaving file: train_data_20220710_18.csv\nSaving file: train_data_20220710_19.csv\nSaving file: train_data_20220710_20.csv\nSaving file: train_data_20220710_21.csv\nSaving file: train_data_20220710_22.csv\nSaving file: train_data_20220710_23.csv\nSaving file: train_data_20220711_0.csv\nSaving file: train_data_20220711_1.csv\nSaving file: train_data_20220711_2.csv\nSaving file: train_data_20220711_3.csv\nSaving file: train_data_20220711_4.csv\nSaving file: train_data_20220711_5.csv\nSaving file: train_data_20220711_6.csv\nSaving file: train_data_20220711_7.csv\nSaving file: train_data_20220711_8.csv\nSaving file: train_data_20220711_9.csv\nSaving file: train_data_20220711_10.csv\nSaving file: train_data_20220711_11.csv\nGetting data for: 20220711\nSaving file: train_data_20220711_12.csv\nSaving file: train_data_20220711_13.csv\nSaving file: train_data_20220711_14.csv\nSaving file: train_data_20220711_15.csv\nSaving file: train_data_20220711_16.csv\nSaving file: train_data_20220711_17.csv\nSaving file: train_data_20220711_18.csv\nSaving file: train_data_20220711_19.csv\nSaving file: train_data_20220711_20.csv\nSaving file: train_data_20220711_21.csv\nSaving file: train_data_20220711_22.csv\nSaving file: train_data_20220711_23.csv\nSaving file: train_data_20220712_0.csv\nSaving file: train_data_20220712_1.csv\nSaving file: train_data_20220712_2.csv\nSaving file: train_data_20220712_3.csv\nSaving file: train_data_20220712_4.csv\nSaving file: train_data_20220712_5.csv\nSaving file: train_data_20220712_6.csv\nSaving file: train_data_20220712_7.csv\nSaving file: train_data_20220712_8.csv\nSaving file: train_data_20220712_9.csv\nSaving file: train_data_20220712_10.csv\nSaving file: train_data_20220712_11.csv\nGetting data for: 20220712\nSaving file: train_data_20220712_12.csv\nSaving file: train_data_20220712_13.csv\nSaving file: train_data_20220712_14.csv\nSaving file: train_data_20220712_15.csv\nSaving file: train_data_20220712_16.csv\nSaving file: train_data_20220712_17.csv\nSaving file: train_data_20220712_18.csv\nSaving file: train_data_20220712_19.csv\nSaving file: train_data_20220712_20.csv\nSaving file: train_data_20220712_21.csv\nSaving file: train_data_20220712_22.csv\nSaving file: train_data_20220712_23.csv\nSaving file: train_data_20220713_0.csv\nSaving file: train_data_20220713_1.csv\nSaving file: train_data_20220713_2.csv\nSaving file: train_data_20220713_3.csv\nSaving file: train_data_20220713_4.csv\nSaving file: train_data_20220713_5.csv\nSaving file: train_data_20220713_6.csv\nSaving file: train_data_20220713_7.csv\nSaving file: train_data_20220713_8.csv\nSaving file: train_data_20220713_9.csv\nSaving file: train_data_20220713_10.csv\nSaving file: train_data_20220713_11.csv\nGetting data for: 20220713\nSaving file: train_data_20220713_12.csv\nSaving file: train_data_20220713_13.csv\nSaving file: train_data_20220713_14.csv\nSaving file: train_data_20220713_15.csv\nSaving file: train_data_20220713_16.csv\nSaving file: train_data_20220713_17.csv\nSaving file: train_data_20220713_18.csv\nSaving file: train_data_20220713_19.csv\nSaving file: train_data_20220713_20.csv\nSaving file: train_data_20220713_21.csv\nSaving file: train_data_20220713_22.csv\nSaving file: train_data_20220713_23.csv\nSaving file: train_data_20220714_0.csv\nSaving file: train_data_20220714_1.csv\nSaving file: train_data_20220714_2.csv\nSaving file: train_data_20220714_3.csv\nSaving file: train_data_20220714_4.csv\nSaving file: train_data_20220714_5.csv\nSaving file: train_data_20220714_6.csv\nSaving file: train_data_20220714_7.csv\nSaving file: train_data_20220714_8.csv\nSaving file: train_data_20220714_9.csv\nSaving file: train_data_20220714_10.csv\nSaving file: train_data_20220714_11.csv\nGetting data for: 20220714\nSaving file: train_data_20220714_12.csv\nSaving file: train_data_20220714_13.csv\nSaving file: train_data_20220714_14.csv\nSaving file: train_data_20220714_15.csv\nSaving file: train_data_20220714_16.csv\nSaving file: train_data_20220714_17.csv\nSaving file: train_data_20220714_18.csv\nSaving file: train_data_20220714_19.csv\nSaving file: train_data_20220714_20.csv\nSaving file: train_data_20220714_21.csv\nSaving file: train_data_20220714_22.csv\nSaving file: train_data_20220714_23.csv\nSaving file: train_data_20220715_0.csv\nSaving file: train_data_20220715_1.csv\nSaving file: train_data_20220715_2.csv\nSaving file: train_data_20220715_3.csv\nSaving file: train_data_20220715_4.csv\nSaving file: train_data_20220715_5.csv\nSaving file: train_data_20220715_6.csv\nSaving file: train_data_20220715_7.csv\nSaving file: train_data_20220715_8.csv\nSaving file: train_data_20220715_9.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220716_0.csv\nSaving file: train_data_20220716_1.csv\nSaving file: train_data_20220716_2.csv\nSaving file: train_data_20220716_3.csv\nSaving file: train_data_20220716_4.csv\nSaving file: train_data_20220716_5.csv\nSaving file: train_data_20220716_6.csv\nSaving file: train_data_20220716_7.csv\nSaving file: train_data_20220716_8.csv\nSaving file: train_data_20220716_9.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220717_0.csv\nSaving file: train_data_20220717_1.csv\nSaving file: train_data_20220717_2.csv\nSaving file: train_data_20220717_3.csv\nSaving file: train_data_20220717_4.csv\nSaving file: train_data_20220717_5.csv\nSaving file: train_data_20220717_6.csv\nSaving file: train_data_20220717_7.csv\nSaving file: train_data_20220717_8.csv\nSaving file: train_data_20220717_9.csv\nSaving file: train_data_20220717_10.csv\nSaving file: train_data_20220717_11.csv\nGetting data for: 20220717\nSaving file: train_data_20220717_12.csv\nSaving file: train_data_20220717_13.csv\nSaving file: train_data_20220717_14.csv\nSaving file: train_data_20220717_15.csv\nSaving file: train_data_20220717_16.csv\nSaving file: train_data_20220717_17.csv\nSaving file: train_data_20220717_18.csv\nSaving file: train_data_20220717_19.csv\nSaving file: train_data_20220717_20.csv\nSaving file: train_data_20220717_21.csv\nSaving file: train_data_20220717_22.csv\nSaving file: train_data_20220717_23.csv\nSaving file: train_data_20220718_0.csv\nSaving file: train_data_20220718_1.csv\nSaving file: train_data_20220718_2.csv\nSaving file: train_data_20220718_3.csv\nSaving file: train_data_20220718_4.csv\nSaving file: train_data_20220718_5.csv\nSaving file: train_data_20220718_6.csv\nSaving file: train_data_20220718_7.csv\nSaving file: train_data_20220718_8.csv\nSaving file: train_data_20220718_9.csv\nSaving file: train_data_20220718_10.csv\nSaving file: train_data_20220718_11.csv\nGetting data for: 20220718\nSaving file: train_data_20220718_12.csv\nSaving file: train_data_20220718_13.csv\nSaving file: train_data_20220718_14.csv\nSaving file: train_data_20220718_15.csv\nSaving file: train_data_20220718_16.csv\nSaving file: train_data_20220718_17.csv\nSaving file: train_data_20220718_18.csv\nSaving file: train_data_20220718_19.csv\nSaving file: train_data_20220718_20.csv\nSaving file: train_data_20220718_21.csv\nSaving file: train_data_20220718_22.csv\nSaving file: train_data_20220718_23.csv\nSaving file: train_data_20220719_0.csv\nSaving file: train_data_20220719_1.csv\nSaving file: train_data_20220719_2.csv\nSaving file: train_data_20220719_3.csv\nSaving file: train_data_20220719_4.csv\nSaving file: train_data_20220719_5.csv\nSaving file: train_data_20220719_6.csv\nSaving file: train_data_20220719_7.csv\nSaving file: train_data_20220719_8.csv\nSaving file: train_data_20220719_9.csv\nSaving file: train_data_20220719_10.csv\nSaving file: train_data_20220719_11.csv\nGetting data for: 20220719\nSaving file: train_data_20220719_12.csv\nSaving file: train_data_20220719_13.csv\nSaving file: train_data_20220719_14.csv\nSaving file: train_data_20220719_15.csv\nSaving file: train_data_20220719_16.csv\nSaving file: train_data_20220719_17.csv\nSaving file: train_data_20220719_18.csv\nSaving file: train_data_20220719_19.csv\nSaving file: train_data_20220719_20.csv\nSaving file: train_data_20220719_21.csv\nSaving file: train_data_20220719_22.csv\nSaving file: train_data_20220719_23.csv\nSaving file: train_data_20220720_0.csv\nSaving file: train_data_20220720_1.csv\nSaving file: train_data_20220720_2.csv\nSaving file: train_data_20220720_3.csv\nSaving file: train_data_20220720_4.csv\nSaving file: train_data_20220720_5.csv\nSaving file: train_data_20220720_6.csv\nSaving file: train_data_20220720_7.csv\nSaving file: train_data_20220720_8.csv\nSaving file: train_data_20220720_9.csv\nSaving file: train_data_20220720_10.csv\nSaving file: train_data_20220720_11.csv\nGetting data for: 20220720\nSaving file: train_data_20220720_12.csv\nSaving file: train_data_20220720_13.csv\nSaving file: train_data_20220720_14.csv\nSaving file: train_data_20220720_15.csv\nSaving file: train_data_20220720_16.csv\nSaving file: train_data_20220720_17.csv\nSaving file: train_data_20220720_18.csv\nSaving file: train_data_20220720_19.csv\nSaving file: train_data_20220720_20.csv\nSaving file: train_data_20220720_21.csv\nSaving file: train_data_20220720_22.csv\nSaving file: train_data_20220720_23.csv\nSaving file: train_data_20220721_0.csv\nSaving file: train_data_20220721_1.csv\nSaving file: train_data_20220721_2.csv\nSaving file: train_data_20220721_3.csv\nSaving file: train_data_20220721_4.csv\nSaving file: train_data_20220721_5.csv\nSaving file: train_data_20220721_6.csv\nSaving file: train_data_20220721_7.csv\nSaving file: train_data_20220721_8.csv\nSaving file: train_data_20220721_9.csv\nSaving file: train_data_20220721_10.csv\nSaving file: train_data_20220721_11.csv\nGetting data for: 20220721\nSaving file: train_data_20220721_12.csv\nSaving file: train_data_20220721_13.csv\nSaving file: train_data_20220721_14.csv\nSaving file: train_data_20220721_15.csv\nSaving file: train_data_20220721_16.csv\nSaving file: train_data_20220721_17.csv\nSaving file: train_data_20220721_18.csv\nSaving file: train_data_20220721_19.csv\nSaving file: train_data_20220721_20.csv\nSaving file: train_data_20220721_21.csv\nSaving file: train_data_20220721_22.csv\nSaving file: train_data_20220721_23.csv\nSaving file: train_data_20220722_0.csv\nSaving file: train_data_20220722_1.csv\nSaving file: train_data_20220722_2.csv\nSaving file: train_data_20220722_3.csv\nSaving file: train_data_20220722_4.csv\nSaving file: train_data_20220722_5.csv\nSaving file: train_data_20220722_6.csv\nSaving file: train_data_20220722_7.csv\nSaving file: train_data_20220722_8.csv\nSaving file: train_data_20220722_9.csv\nSaving file: train_data_20220722_10.csv\nSaving file: train_data_20220722_11.csv\nGetting data for: 20220722\nSaving file: train_data_20220722_12.csv\nSaving file: train_data_20220722_13.csv\nSaving file: train_data_20220722_14.csv\nSaving file: train_data_20220722_15.csv\nSaving file: train_data_20220722_16.csv\nSaving file: train_data_20220722_17.csv\nSaving file: train_data_20220722_18.csv\nSaving file: train_data_20220722_19.csv\nSaving file: train_data_20220722_20.csv\nSaving file: train_data_20220722_21.csv\nSaving file: train_data_20220722_22.csv\nSaving file: train_data_20220722_23.csv\nSaving file: train_data_20220723_0.csv\nSaving file: train_data_20220723_1.csv\nSaving file: train_data_20220723_2.csv\nSaving file: train_data_20220723_3.csv\nSaving file: train_data_20220723_4.csv\nSaving file: train_data_20220723_5.csv\nSaving file: train_data_20220723_6.csv\nSaving file: train_data_20220723_7.csv\nSaving file: train_data_20220723_8.csv\nSaving file: train_data_20220723_9.csv\nSaving file: train_data_20220723_10.csv\nSaving file: train_data_20220723_11.csv\nGetting data for: 20220723\nSaving file: train_data_20220723_12.csv\nSaving file: train_data_20220723_13.csv\nSaving file: train_data_20220723_14.csv\nSaving file: train_data_20220723_15.csv\nSaving file: train_data_20220723_16.csv\nSaving file: train_data_20220723_17.csv\nSaving file: train_data_20220723_18.csv\nSaving file: train_data_20220723_19.csv\nSaving file: train_data_20220723_20.csv\nSaving file: train_data_20220723_21.csv\nSaving file: train_data_20220723_22.csv\nSaving file: train_data_20220723_23.csv\nSaving file: train_data_20220724_0.csv\nSaving file: train_data_20220724_1.csv\nSaving file: train_data_20220724_2.csv\nSaving file: train_data_20220724_3.csv\nSaving file: train_data_20220724_4.csv\nSaving file: train_data_20220724_5.csv\nSaving file: train_data_20220724_6.csv\nSaving file: train_data_20220724_7.csv\nSaving file: train_data_20220724_8.csv\nSaving file: train_data_20220724_9.csv\nSaving file: train_data_20220724_10.csv\nSaving file: train_data_20220724_11.csv\nGetting data for: 20220724\nSaving file: train_data_20220724_12.csv\nSaving file: train_data_20220724_13.csv\nSaving file: train_data_20220724_14.csv\nSaving file: train_data_20220724_15.csv\nSaving file: train_data_20220724_16.csv\nSaving file: train_data_20220724_17.csv\nSaving file: train_data_20220724_18.csv\nSaving file: train_data_20220724_19.csv\nSaving file: train_data_20220724_20.csv\nSaving file: train_data_20220724_21.csv\nSaving file: train_data_20220724_22.csv\nSaving file: train_data_20220724_23.csv\nSaving file: train_data_20220725_0.csv\nSaving file: train_data_20220725_1.csv\nSaving file: train_data_20220725_2.csv\nSaving file: train_data_20220725_3.csv\nSaving file: train_data_20220725_4.csv\nSaving file: train_data_20220725_5.csv\nSaving file: train_data_20220725_6.csv\nSaving file: train_data_20220725_7.csv\nSaving file: train_data_20220725_8.csv\nSaving file: train_data_20220725_9.csv\nSaving file: train_data_20220725_10.csv\nSaving file: train_data_20220725_11.csv\nGetting data for: 20220725\nSaving file: train_data_20220725_12.csv\nSaving file: train_data_20220725_13.csv\nSaving file: train_data_20220725_14.csv\nSaving file: train_data_20220725_15.csv\nSaving file: train_data_20220725_16.csv\nSaving file: train_data_20220725_17.csv\nSaving file: train_data_20220725_18.csv\nSaving file: train_data_20220725_19.csv\nSaving file: train_data_20220725_20.csv\nSaving file: train_data_20220725_21.csv\nSaving file: train_data_20220725_22.csv\nSaving file: train_data_20220725_23.csv\nSaving file: train_data_20220726_0.csv\nSaving file: train_data_20220726_1.csv\nSaving file: train_data_20220726_2.csv\nSaving file: train_data_20220726_3.csv\nSaving file: train_data_20220726_4.csv\nSaving file: train_data_20220726_5.csv\nSaving file: train_data_20220726_6.csv\nSaving file: train_data_20220726_7.csv\nSaving file: train_data_20220726_8.csv\nSaving file: train_data_20220726_9.csv\nSaving file: train_data_20220726_10.csv\nSaving file: train_data_20220726_11.csv\nGetting data for: 20220726\nSaving file: train_data_20220726_12.csv\nSaving file: train_data_20220726_13.csv\nSaving file: train_data_20220726_14.csv\nSaving file: train_data_20220726_15.csv\nSaving file: train_data_20220726_16.csv\nSaving file: train_data_20220726_17.csv\nSaving file: train_data_20220726_18.csv\nSaving file: train_data_20220726_19.csv\nSaving file: train_data_20220726_20.csv\nSaving file: train_data_20220726_21.csv\nSaving file: train_data_20220726_22.csv\nSaving file: train_data_20220726_23.csv\nSaving file: train_data_20220727_0.csv\nSaving file: train_data_20220727_1.csv\nSaving file: train_data_20220727_2.csv\nSaving file: train_data_20220727_3.csv\nSaving file: train_data_20220727_4.csv\nSaving file: train_data_20220727_5.csv\nSaving file: train_data_20220727_6.csv\nSaving file: train_data_20220727_7.csv\nSaving file: train_data_20220727_8.csv\nSaving file: train_data_20220727_9.csv\nSaving file: train_data_20220727_10.csv\nSaving file: train_data_20220727_11.csv\nGetting data for: 20220727\nSaving file: train_data_20220727_12.csv\nSaving file: train_data_20220727_13.csv\nSaving file: train_data_20220727_14.csv\nSaving file: train_data_20220727_15.csv\nSaving file: train_data_20220727_16.csv\nSaving file: train_data_20220727_17.csv\nSaving file: train_data_20220727_18.csv\nSaving file: train_data_20220727_19.csv\nSaving file: train_data_20220727_20.csv\nSaving file: train_data_20220727_21.csv\nSaving file: train_data_20220727_22.csv\nSaving file: train_data_20220727_23.csv\nSaving file: train_data_20220728_0.csv\nSaving file: train_data_20220728_1.csv\nSaving file: train_data_20220728_2.csv\nSaving file: train_data_20220728_3.csv\nSaving file: train_data_20220728_4.csv\nSaving file: train_data_20220728_5.csv\nSaving file: train_data_20220728_6.csv\nSaving file: train_data_20220728_7.csv\nSaving file: train_data_20220728_8.csv\nSaving file: train_data_20220728_9.csv\nSaving file: train_data_20220728_10.csv\nSaving file: train_data_20220728_11.csv\nGetting data for: 20220728\nSaving file: train_data_20220728_12.csv\nSaving file: train_data_20220728_13.csv\nSaving file: train_data_20220728_14.csv\nSaving file: train_data_20220728_15.csv\nSaving file: train_data_20220728_16.csv\nSaving file: train_data_20220728_17.csv\nSaving file: train_data_20220728_18.csv\nSaving file: train_data_20220728_19.csv\nSaving file: train_data_20220728_20.csv\nSaving file: train_data_20220728_21.csv\nSaving file: train_data_20220728_22.csv\nSaving file: train_data_20220728_23.csv\nSaving file: train_data_20220729_0.csv\nSaving file: train_data_20220729_1.csv\nSaving file: train_data_20220729_2.csv\nSaving file: train_data_20220729_3.csv\nSaving file: train_data_20220729_4.csv\nSaving file: train_data_20220729_5.csv\nSaving file: train_data_20220729_6.csv\nSaving file: train_data_20220729_7.csv\nSaving file: train_data_20220729_8.csv\nSaving file: train_data_20220729_9.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220730_0.csv\nSaving file: train_data_20220730_1.csv\nSaving file: train_data_20220730_2.csv\nSaving file: train_data_20220730_3.csv\nSaving file: train_data_20220730_4.csv\nSaving file: train_data_20220730_5.csv\nSaving file: train_data_20220730_6.csv\nSaving file: train_data_20220730_7.csv\nSaving file: train_data_20220730_8.csv\nSaving file: train_data_20220730_9.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220731_0.csv\nSaving file: train_data_20220731_1.csv\nSaving file: train_data_20220731_2.csv\nSaving file: train_data_20220731_3.csv\nSaving file: train_data_20220731_4.csv\nSaving file: train_data_20220731_5.csv\nSaving file: train_data_20220731_6.csv\nSaving file: train_data_20220731_7.csv\nSaving file: train_data_20220731_8.csv\nSaving file: train_data_20220731_9.csv\nSaving file: train_data_20220731_10.csv\nSaving file: train_data_20220731_11.csv\nGetting data for: 20220731\nSaving file: train_data_20220731_12.csv\nSaving file: train_data_20220731_13.csv\nSaving file: train_data_20220731_14.csv\nSaving file: train_data_20220731_15.csv\nSaving file: train_data_20220731_16.csv\nSaving file: train_data_20220731_17.csv\nSaving file: train_data_20220731_18.csv\nSaving file: train_data_20220731_19.csv\nSaving file: train_data_20220731_20.csv\nSaving file: train_data_20220731_21.csv\nSaving file: train_data_20220731_22.csv\nSaving file: train_data_20220731_23.csv\nSaving file: train_data_20220801_0.csv\nSaving file: train_data_20220801_1.csv\nSaving file: train_data_20220801_2.csv\nSaving file: train_data_20220801_3.csv\nSaving file: train_data_20220801_4.csv\nSaving file: train_data_20220801_5.csv\nSaving file: train_data_20220801_6.csv\nSaving file: train_data_20220801_7.csv\nSaving file: train_data_20220801_8.csv\nSaving file: train_data_20220801_9.csv\nSaving file: train_data_20220801_10.csv\nSaving file: train_data_20220801_11.csv\nDone!\n",
  "history_begin_time" : 1660295808101,
  "history_end_time" : 1660301768661,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "9uoh9khkeql",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = f\"{cmaq_folder}/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nTraceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 124, in <module>\n    df_hourly.to_csv(filename,index=False)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 241, in save\n    with get_handle(\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/io/common.py\", line 789, in get_handle\n    handle = open(\nPermissionError: [Errno 13] Permission denied: '/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_12.csv'\n",
  "history_begin_time" : 1660294427183,
  "history_end_time" : 1660294477684,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "aHo7I6gy2uOh",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 10)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n  day = sdate + timedelta(days=i)\n  list_day=day.strftime('%Y%m%d')\n  days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n  print(\"Getting data for: \"+day)\n    \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n  for k in time_step_in_netcdf_list:\n    real_hour_value = real_hour_list[k]\n            \n    df_hourly = pd.DataFrame()\n            \n    # CMAQ data\n            \n    # O3 variable\n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n\n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n    # EMIS data\n                              \n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n    # MCIP data\n            \n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n            \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n            \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n            \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n            \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n\n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n\n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n\n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n            \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n    print('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n    df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220701_0.csv\nSaving file: train_data_20220701_1.csv\nSaving file: train_data_20220701_2.csv\nSaving file: train_data_20220701_3.csv\nSaving file: train_data_20220701_4.csv\nSaving file: train_data_20220701_5.csv\nSaving file: train_data_20220701_6.csv\nSaving file: train_data_20220701_7.csv\nSaving file: train_data_20220701_8.csv\nSaving file: train_data_20220701_9.csv\nSaving file: train_data_20220701_10.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220703_0.csv\nSaving file: train_data_20220703_1.csv\nSaving file: train_data_20220703_2.csv\nSaving file: train_data_20220703_3.csv\nSaving file: train_data_20220703_4.csv\nSaving file: train_data_20220703_5.csv\nSaving file: train_data_20220703_6.csv\nSaving file: train_data_20220703_7.csv\nSaving file: train_data_20220703_8.csv\nSaving file: train_data_20220703_9.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220704_0.csv\nSaving file: train_data_20220704_1.csv\nSaving file: train_data_20220704_2.csv\nSaving file: train_data_20220704_3.csv\nSaving file: train_data_20220704_4.csv\nSaving file: train_data_20220704_5.csv\nSaving file: train_data_20220704_6.csv\nSaving file: train_data_20220704_7.csv\nSaving file: train_data_20220704_8.csv\nSaving file: train_data_20220704_9.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220705_0.csv\nSaving file: train_data_20220705_1.csv\nSaving file: train_data_20220705_2.csv\nSaving file: train_data_20220705_3.csv\nSaving file: train_data_20220705_4.csv\nSaving file: train_data_20220705_5.csv\nSaving file: train_data_20220705_6.csv\nSaving file: train_data_20220705_7.csv\nSaving file: train_data_20220705_8.csv\nSaving file: train_data_20220705_9.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220706_0.csv\nSaving file: train_data_20220706_1.csv\nSaving file: train_data_20220706_2.csv\nSaving file: train_data_20220706_3.csv\nSaving file: train_data_20220706_4.csv\nSaving file: train_data_20220706_5.csv\nSaving file: train_data_20220706_6.csv\nSaving file: train_data_20220706_7.csv\nSaving file: train_data_20220706_8.csv\nSaving file: train_data_20220706_9.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220707_0.csv\n",
  "history_begin_time" : 1660272210923,
  "history_end_time" : 1660274817994,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "6pQCedIe07yc",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\ncreate_and_clean_folder(training_input_folder)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n    print(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220703_0.csv\nSaving file: train_data_20220703_1.csv\nSaving file: train_data_20220703_2.csv\nSaving file: train_data_20220703_3.csv\nSaving file: train_data_20220703_4.csv\nSaving file: train_data_20220703_5.csv\nSaving file: train_data_20220703_6.csv\nSaving file: train_data_20220703_7.csv\nSaving file: train_data_20220703_8.csv\nSaving file: train_data_20220703_9.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nDone!\n",
  "history_begin_time" : 1660271360298,
  "history_end_time" : 1660828757835,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "rgKsgzR85fxS",
  "history_input" : "# get all of the cmaq model output variables\nfrom cmaq_ai_utils import *\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndays = get_days_list(sdate, edate)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n# clean all files inside the folder\nfor f in os.listdir(training_input_folder):\n  os.remove(os.path.join(training_input_folder, f))\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n    print(f'remove old files{filename}')\n    if os.path.exists(filename):\n      os.remove(filename)\n    print(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Traceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 4, in <module>\n    sdate = date(2022, 7, 1)   # start date\nNameError: name 'date' is not defined\n",
  "history_begin_time" : 1660271117472,
  "history_end_time" : 1660271186988,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "6pIR50aiFY0U",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n  day = sdate + timedelta(days=i)\n  list_day=day.strftime('%Y%m%d')\n  days.append(list_day)\n\n# add one more day\none_more_day = sdate + timedelta(days=delta.days + 1)\nlist_day=one_more_day.strftime('%Y%m%d')\ndays.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n\nfor x in range(len(days)-1):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if real_hour_value >= 0 and real_hour_value <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n    print(f'remove old files{filename}')\n    if os.path.exists(filename):\n      os.remove(filename)\n    print(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_12.csv\nSaving file: train_data_20220701_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_13.csv\nSaving file: train_data_20220701_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_14.csv\nSaving file: train_data_20220701_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_15.csv\nSaving file: train_data_20220701_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_16.csv\nSaving file: train_data_20220701_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_17.csv\nSaving file: train_data_20220701_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_18.csv\nSaving file: train_data_20220701_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_19.csv\nSaving file: train_data_20220701_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_20.csv\nSaving file: train_data_20220701_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_21.csv\nSaving file: train_data_20220701_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_22.csv\nSaving file: train_data_20220701_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_23.csv\nSaving file: train_data_20220701_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_0.csv\nSaving file: train_data_20220702_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_1.csv\nSaving file: train_data_20220702_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_2.csv\nSaving file: train_data_20220702_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_3.csv\nSaving file: train_data_20220702_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_4.csv\nSaving file: train_data_20220702_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_5.csv\nSaving file: train_data_20220702_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_6.csv\nSaving file: train_data_20220702_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_7.csv\nSaving file: train_data_20220702_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_8.csv\nSaving file: train_data_20220702_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_9.csv\nSaving file: train_data_20220702_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_10.csv\nSaving file: train_data_20220702_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_11.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220702\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_12.csv\nSaving file: train_data_20220702_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_13.csv\nSaving file: train_data_20220702_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_14.csv\nSaving file: train_data_20220702_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_15.csv\nSaving file: train_data_20220702_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_16.csv\nSaving file: train_data_20220702_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_17.csv\nSaving file: train_data_20220702_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_18.csv\nSaving file: train_data_20220702_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_19.csv\nSaving file: train_data_20220702_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_20.csv\nSaving file: train_data_20220702_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_21.csv\nSaving file: train_data_20220702_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_22.csv\nSaving file: train_data_20220702_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_23.csv\nSaving file: train_data_20220702_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_0.csv\nSaving file: train_data_20220703_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_1.csv\nSaving file: train_data_20220703_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_2.csv\nSaving file: train_data_20220703_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_3.csv\nSaving file: train_data_20220703_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_4.csv\nSaving file: train_data_20220703_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_5.csv\nSaving file: train_data_20220703_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_6.csv\nSaving file: train_data_20220703_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_7.csv\nSaving file: train_data_20220703_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_8.csv\nSaving file: train_data_20220703_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_9.csv\nSaving file: train_data_20220703_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_10.csv\nSaving file: train_data_20220703_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_11.csv\nSaving file: train_data_20220703_11.csv\nDone!\n",
  "history_begin_time" : 1660270529816,
  "history_end_time" : 1660271187572,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "R5fdK2ZGOVkB",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n  day = sdate + timedelta(days=i)\n  list_day=day.strftime('%Y%m%d')\n  days.append(list_day)\n\n# add one more day\none_more_day = sdate + timedelta(days=delta.days + 1)\nlist_day=one_more_day.strftime('%Y%m%d')\ndays.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n\nfor x in range(len(days)):\n  current_day = days[x]\n  next_day = days[x+1]\n  print(\"Getting data for: \"+current_day)\n  \n  # read cmaq results\n  df_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+current_day+\"_extracted.nc\")\n  \n  # read mcip results \n  df_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+current_day+\".nc\")\n  \n  # read emissions results \n  df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+current_day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  \n  for k in time_step_in_netcdf_list:\n    \n    real_hour_value = real_hour_list[k]\n    \n    if k >= 0 and k <=11:\n      day = next_day\n    else:\n      day = current_day\n    \n    df_hourly = pd.DataFrame()\n    \n    # CMAQ data\n    # O3 variable\n    \n    o3=df_cmaq.variables['O3'][:].values[k,0]\n    cmaq_O3=list(np.ravel(o3).transpose().round())  \n    \n    # NO2\n    no2=df_cmaq.variables['NO2'][:].values[k,0]\n    cmaq_NO2=list(np.ravel(no2).transpose().round())\n    \n    # CO\n    co=df_cmaq.variables['CO'][:].values[k,0]\n    cmaq_CO=list(np.ravel(co).transpose().round())\n    \n    # PM25_CO\n    pm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n    cmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n    \n    # EMIS data\n    co_emis=df_emis.variables['CO'][:].values[k,0]\n    CO_emi=list(np.ravel(co_emis).transpose().round())    \n    \n    # MCIP data\n    # CO variable\n    prsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n    PRSFC=list(np.ravel(prsfc).transpose().round())\n    \n    # NO2\n    pbl=df_mcip.variables['PBL'][:].values[k,0]\n    PBL=list(np.ravel(pbl).transpose().round())\n    \n    # TEMP2\n    temp2=df_mcip.variables['TEMP2'][:].values[k,0]\n    TEMP2=list(np.ravel(temp2).transpose().round())\n    \n    # WSPD10\n    wspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n    WSPD10=list(np.ravel(wspd10).transpose().round())\n    \n    # WDIR10\n    wdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n    WDIR10=list(np.ravel(wdir10).transpose().round())\n    \n    # RGRND\n    rgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n    RGRND=list(np.ravel(rgrnd).transpose().round())\n    \n    # CFRAC\n    cfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n    CFRAC=list(np.ravel(cfrac).transpose().round())\n    \n    ## LAT/LON data\n    df_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n    \n    lat = df_coords.variables['LAT'][:].values[0,0]\n    lat_flt=np.ravel(lat)\n    LAT=np.tile(lat_flt,1)\n    \n    lon = df_coords.variables['LON'][:].values[0,0]\n    lon_flt=np.ravel(lon)\n    LON=np.tile(lon_flt,1)\n    \n    df_hourly['Latitude'] = LAT\n    df_hourly['Longitude'] = LON\n    df_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n    df_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n    df_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n    df_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n    df_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n    df_hourly['CO(moles/s)'] = CO_emi\n    df_hourly['PRSFC(Pa)'] = PRSFC\n    df_hourly['PBL(m)'] = PBL\n    df_hourly['TEMP2(K)'] = TEMP2\n    df_hourly['WSPD10(m/s)'] = WSPD10\n    df_hourly['WDIR10(degree)'] = WDIR10\n    df_hourly['RGRND(W/m2)'] = RGRND\n    df_hourly['CFRAC'] = CFRAC\n    df_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n    df_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n    df_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n    \n    filename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n    print(f'remove old files{filename}')\n    if os.path.exists(filename):\n      os.remove(filename)\n    print(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n    df_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_12.csv\nSaving file: train_data_20220702_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_13.csv\nSaving file: train_data_20220702_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_14.csv\nSaving file: train_data_20220702_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_15.csv\nSaving file: train_data_20220702_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_16.csv\nSaving file: train_data_20220702_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_17.csv\nSaving file: train_data_20220702_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_18.csv\nSaving file: train_data_20220702_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_19.csv\nSaving file: train_data_20220702_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_20.csv\nSaving file: train_data_20220702_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_21.csv\nSaving file: train_data_20220702_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_22.csv\nSaving file: train_data_20220702_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_23.csv\nSaving file: train_data_20220702_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_0.csv\nSaving file: train_data_20220701_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_1.csv\nSaving file: train_data_20220701_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_2.csv\nSaving file: train_data_20220701_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_3.csv\nSaving file: train_data_20220701_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_4.csv\nSaving file: train_data_20220701_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_5.csv\nSaving file: train_data_20220701_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_6.csv\nSaving file: train_data_20220701_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_7.csv\nSaving file: train_data_20220701_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_8.csv\nSaving file: train_data_20220701_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_9.csv\nSaving file: train_data_20220701_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_10.csv\nSaving file: train_data_20220701_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_11.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_12.csv\nSaving file: train_data_20220703_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_13.csv\nSaving file: train_data_20220703_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_14.csv\nSaving file: train_data_20220703_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_15.csv\nSaving file: train_data_20220703_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_16.csv\nSaving file: train_data_20220703_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_17.csv\nSaving file: train_data_20220703_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_18.csv\nSaving file: train_data_20220703_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_19.csv\nSaving file: train_data_20220703_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_20.csv\nSaving file: train_data_20220703_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_21.csv\nSaving file: train_data_20220703_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_22.csv\nSaving file: train_data_20220703_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220703_23.csv\nSaving file: train_data_20220703_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_0.csv\nSaving file: train_data_20220702_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_1.csv\nSaving file: train_data_20220702_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_2.csv\nSaving file: train_data_20220702_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_3.csv\nSaving file: train_data_20220702_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_4.csv\nSaving file: train_data_20220702_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_5.csv\nSaving file: train_data_20220702_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_6.csv\nSaving file: train_data_20220702_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_7.csv\nSaving file: train_data_20220702_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_8.csv\nSaving file: train_data_20220702_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_9.csv\nSaving file: train_data_20220702_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_10.csv\nSaving file: train_data_20220702_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_11.csv\nSaving file: train_data_20220702_11.csv\nTraceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 39, in <module>\n    next_day = days[x+1]\nIndexError: list index out of range\n",
  "history_begin_time" : 1660270222678,
  "history_end_time" : 1660271188104,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "lhLhTEJLsF7A",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n        \n\t\tfilename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n\t\tprint(f'remove old files{filename}')\n\t\tif os.path.exists(filename):\n\t\t\tos.remove(filename)\n\t\tprint(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n\t\tdf_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_12.csv\nSaving file: train_data_20220701_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_13.csv\nSaving file: train_data_20220701_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_14.csv\nSaving file: train_data_20220701_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_15.csv\nSaving file: train_data_20220701_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_16.csv\nSaving file: train_data_20220701_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_17.csv\nSaving file: train_data_20220701_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_18.csv\nSaving file: train_data_20220701_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_19.csv\nSaving file: train_data_20220701_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_20.csv\nSaving file: train_data_20220701_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_21.csv\nSaving file: train_data_20220701_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_22.csv\nSaving file: train_data_20220701_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_23.csv\nSaving file: train_data_20220701_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_0.csv\nSaving file: train_data_20220701_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_1.csv\nSaving file: train_data_20220701_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_2.csv\nSaving file: train_data_20220701_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_3.csv\nSaving file: train_data_20220701_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_4.csv\nSaving file: train_data_20220701_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_5.csv\nSaving file: train_data_20220701_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_6.csv\nSaving file: train_data_20220701_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_7.csv\nSaving file: train_data_20220701_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_8.csv\nSaving file: train_data_20220701_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_9.csv\nSaving file: train_data_20220701_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_10.csv\nSaving file: train_data_20220701_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_11.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_12.csv\nSaving file: train_data_20220702_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_13.csv\nSaving file: train_data_20220702_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_14.csv\nSaving file: train_data_20220702_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_15.csv\nSaving file: train_data_20220702_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_16.csv\nSaving file: train_data_20220702_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_17.csv\nSaving file: train_data_20220702_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_18.csv\nSaving file: train_data_20220702_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_19.csv\nSaving file: train_data_20220702_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_20.csv\nSaving file: train_data_20220702_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_21.csv\nSaving file: train_data_20220702_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_22.csv\nSaving file: train_data_20220702_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_23.csv\nSaving file: train_data_20220702_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_0.csv\nSaving file: train_data_20220702_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_1.csv\nSaving file: train_data_20220702_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_2.csv\nSaving file: train_data_20220702_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_3.csv\nSaving file: train_data_20220702_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_4.csv\nSaving file: train_data_20220702_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_5.csv\nSaving file: train_data_20220702_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_6.csv\nSaving file: train_data_20220702_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_7.csv\nSaving file: train_data_20220702_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_8.csv\nSaving file: train_data_20220702_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_9.csv\nSaving file: train_data_20220702_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_10.csv\nSaving file: train_data_20220702_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_11.csv\nSaving file: train_data_20220702_11.csv\nDone!\n",
  "history_begin_time" : 1660268669574,
  "history_end_time" : 1660270355690,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "VpKD9JbOXIMw",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n        \n\t\tfilename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n\t\tprint(f'remove old files{filename}')\n\t\tif os.path.exists(filename):\n\t\t\tos.remove(filename)\n\t\tprint(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n\t\tdf_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_12.csv\nSaving file: train_data_20220701_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_13.csv\nSaving file: train_data_20220701_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_14.csv\nSaving file: train_data_20220701_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_15.csv\nSaving file: train_data_20220701_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_16.csv\nSaving file: train_data_20220701_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_17.csv\nSaving file: train_data_20220701_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_18.csv\nSaving file: train_data_20220701_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_19.csv\nSaving file: train_data_20220701_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_20.csv\nSaving file: train_data_20220701_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_21.csv\nSaving file: train_data_20220701_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_22.csv\nSaving file: train_data_20220701_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_23.csv\nSaving file: train_data_20220701_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_0.csv\nSaving file: train_data_20220701_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_1.csv\nSaving file: train_data_20220701_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_2.csv\nSaving file: train_data_20220701_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_3.csv\nSaving file: train_data_20220701_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_4.csv\nSaving file: train_data_20220701_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_5.csv\nSaving file: train_data_20220701_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_6.csv\nSaving file: train_data_20220701_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_7.csv\nSaving file: train_data_20220701_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_8.csv\nSaving file: train_data_20220701_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_9.csv\nSaving file: train_data_20220701_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_10.csv\nSaving file: train_data_20220701_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_11.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_12.csv\nSaving file: train_data_20220702_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_13.csv\nSaving file: train_data_20220702_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_14.csv\nSaving file: train_data_20220702_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_15.csv\nSaving file: train_data_20220702_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_16.csv\nSaving file: train_data_20220702_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_17.csv\nSaving file: train_data_20220702_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_18.csv\nSaving file: train_data_20220702_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_19.csv\nSaving file: train_data_20220702_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_20.csv\nSaving file: train_data_20220702_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_21.csv\nSaving file: train_data_20220702_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_22.csv\nSaving file: train_data_20220702_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_23.csv\nSaving file: train_data_20220702_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_0.csv\nSaving file: train_data_20220702_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_1.csv\nSaving file: train_data_20220702_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_2.csv\nSaving file: train_data_20220702_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_3.csv\nSaving file: train_data_20220702_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_4.csv\nSaving file: train_data_20220702_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_5.csv\nSaving file: train_data_20220702_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_6.csv\nSaving file: train_data_20220702_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_7.csv\nSaving file: train_data_20220702_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_8.csv\nSaving file: train_data_20220702_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_9.csv\nSaving file: train_data_20220702_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_10.csv\nSaving file: train_data_20220702_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_11.csv\nSaving file: train_data_20220702_11.csv\nDone!\n",
  "history_begin_time" : 1660267661568,
  "history_end_time" : 1660270354644,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "BmNjJUJkrplM",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/zsun/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n        \n\t\tfilename = f'/groups/ESS/zsun/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n\t\tprint(f'remove old files{filename}')\n\t\tprint(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n\t\tdf_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_12.csv\nSaving file: train_data_20220701_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_13.csv\nSaving file: train_data_20220701_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_14.csv\nSaving file: train_data_20220701_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_15.csv\nSaving file: train_data_20220701_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_16.csv\nSaving file: train_data_20220701_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_17.csv\nSaving file: train_data_20220701_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_18.csv\nSaving file: train_data_20220701_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_19.csv\nSaving file: train_data_20220701_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_20.csv\nSaving file: train_data_20220701_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_21.csv\nSaving file: train_data_20220701_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_22.csv\nSaving file: train_data_20220701_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_23.csv\nSaving file: train_data_20220701_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_0.csv\nSaving file: train_data_20220701_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_1.csv\nSaving file: train_data_20220701_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_2.csv\nSaving file: train_data_20220701_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_3.csv\nSaving file: train_data_20220701_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_4.csv\nSaving file: train_data_20220701_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_5.csv\nSaving file: train_data_20220701_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_6.csv\nSaving file: train_data_20220701_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_7.csv\nSaving file: train_data_20220701_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_8.csv\nSaving file: train_data_20220701_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_9.csv\nSaving file: train_data_20220701_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_10.csv\nSaving file: train_data_20220701_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220701_11.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_12.csv\nSaving file: train_data_20220702_12.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_13.csv\nSaving file: train_data_20220702_13.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_14.csv\nSaving file: train_data_20220702_14.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_15.csv\nSaving file: train_data_20220702_15.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_16.csv\nSaving file: train_data_20220702_16.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_17.csv\nSaving file: train_data_20220702_17.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_18.csv\nSaving file: train_data_20220702_18.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_19.csv\nSaving file: train_data_20220702_19.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_20.csv\nSaving file: train_data_20220702_20.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_21.csv\nSaving file: train_data_20220702_21.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_22.csv\nSaving file: train_data_20220702_22.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_23.csv\nSaving file: train_data_20220702_23.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_0.csv\nSaving file: train_data_20220702_0.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_1.csv\nSaving file: train_data_20220702_1.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_2.csv\nSaving file: train_data_20220702_2.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_3.csv\nSaving file: train_data_20220702_3.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_4.csv\nSaving file: train_data_20220702_4.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_5.csv\nSaving file: train_data_20220702_5.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_6.csv\nSaving file: train_data_20220702_6.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_7.csv\nSaving file: train_data_20220702_7.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_8.csv\nSaving file: train_data_20220702_8.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_9.csv\nSaving file: train_data_20220702_9.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_10.csv\nSaving file: train_data_20220702_10.csv\nremove old files/groups/ESS/zsun/cmaq/training_input_hourly/train_data_20220702_11.csv\nSaving file: train_data_20220702_11.csv\nDone!\n",
  "history_begin_time" : 1660267264711,
  "history_end_time" : 1660270354124,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "fBHZIILfxu2k",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\ntraining_input_folder = \"/groups/ESS/aalnaim/cmaq/training_input_hourly/\"\nos.makedirs(training_input_folder, exist_ok=True)\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n        \n        filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n        print(f'remove old files{filename}')\n\t\tprint(f'Saving file: train_data_{day}_{str(real_hour_value)}.csv')\n\t\tdf_hourly.to_csv(filename,index=False)\n\nprint('Done!')",
  "history_output" : "  File \"preparing_cmaq_training_data.py\", line 138\n    filename = f'/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_{day}_{str(real_hour_value)}.csv'\n                                                                                                           ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1660267085568,
  "history_end_time" : 1660270353640,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "a5z9crastvh",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 8, 8)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220701_0.csv\nSaving file: train_data_20220701_1.csv\nSaving file: train_data_20220701_2.csv\nSaving file: train_data_20220701_3.csv\nSaving file: train_data_20220701_4.csv\nSaving file: train_data_20220701_5.csv\nSaving file: train_data_20220701_6.csv\nSaving file: train_data_20220701_7.csv\nSaving file: train_data_20220701_8.csv\nSaving file: train_data_20220701_9.csv\nSaving file: train_data_20220701_10.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220703_0.csv\nSaving file: train_data_20220703_1.csv\nSaving file: train_data_20220703_2.csv\nSaving file: train_data_20220703_3.csv\nSaving file: train_data_20220703_4.csv\nSaving file: train_data_20220703_5.csv\nSaving file: train_data_20220703_6.csv\nSaving file: train_data_20220703_7.csv\nSaving file: train_data_20220703_8.csv\nSaving file: train_data_20220703_9.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220704_0.csv\nSaving file: train_data_20220704_1.csv\nSaving file: train_data_20220704_2.csv\nSaving file: train_data_20220704_3.csv\nSaving file: train_data_20220704_4.csv\nSaving file: train_data_20220704_5.csv\nSaving file: train_data_20220704_6.csv\nSaving file: train_data_20220704_7.csv\nSaving file: train_data_20220704_8.csv\nSaving file: train_data_20220704_9.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220705_0.csv\nSaving file: train_data_20220705_1.csv\nSaving file: train_data_20220705_2.csv\nSaving file: train_data_20220705_3.csv\nSaving file: train_data_20220705_4.csv\nSaving file: train_data_20220705_5.csv\nSaving file: train_data_20220705_6.csv\nSaving file: train_data_20220705_7.csv\nSaving file: train_data_20220705_8.csv\nSaving file: train_data_20220705_9.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220706_0.csv\nSaving file: train_data_20220706_1.csv\nSaving file: train_data_20220706_2.csv\nSaving file: train_data_20220706_3.csv\nSaving file: train_data_20220706_4.csv\nSaving file: train_data_20220706_5.csv\nSaving file: train_data_20220706_6.csv\nSaving file: train_data_20220706_7.csv\nSaving file: train_data_20220706_8.csv\nSaving file: train_data_20220706_9.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220707_0.csv\nSaving file: train_data_20220707_1.csv\nSaving file: train_data_20220707_2.csv\nSaving file: train_data_20220707_3.csv\nSaving file: train_data_20220707_4.csv\nSaving file: train_data_20220707_5.csv\nSaving file: train_data_20220707_6.csv\nSaving file: train_data_20220707_7.csv\nSaving file: train_data_20220707_8.csv\nSaving file: train_data_20220707_9.csv\nSaving file: train_data_20220707_10.csv\nSaving file: train_data_20220707_11.csv\nGetting data for: 20220708\nSaving file: train_data_20220708_12.csv\nSaving file: train_data_20220708_13.csv\nSaving file: train_data_20220708_14.csv\nSaving file: train_data_20220708_15.csv\nSaving file: train_data_20220708_16.csv\nSaving file: train_data_20220708_17.csv\nSaving file: train_data_20220708_18.csv\nSaving file: train_data_20220708_19.csv\nSaving file: train_data_20220708_20.csv\nSaving file: train_data_20220708_21.csv\nSaving file: train_data_20220708_22.csv\nSaving file: train_data_20220708_23.csv\nSaving file: train_data_20220708_0.csv\nSaving file: train_data_20220708_1.csv\nSaving file: train_data_20220708_2.csv\nSaving file: train_data_20220708_3.csv\nSaving file: train_data_20220708_4.csv\nSaving file: train_data_20220708_5.csv\nSaving file: train_data_20220708_6.csv\nSaving file: train_data_20220708_7.csv\nSaving file: train_data_20220708_8.csv\nSaving file: train_data_20220708_9.csv\nSaving file: train_data_20220708_10.csv\nSaving file: train_data_20220708_11.csv\nGetting data for: 20220709\nSaving file: train_data_20220709_12.csv\nSaving file: train_data_20220709_13.csv\nSaving file: train_data_20220709_14.csv\nSaving file: train_data_20220709_15.csv\nSaving file: train_data_20220709_16.csv\nSaving file: train_data_20220709_17.csv\nSaving file: train_data_20220709_18.csv\nSaving file: train_data_20220709_19.csv\nSaving file: train_data_20220709_20.csv\nSaving file: train_data_20220709_21.csv\nSaving file: train_data_20220709_22.csv\nSaving file: train_data_20220709_23.csv\nSaving file: train_data_20220709_0.csv\nSaving file: train_data_20220709_1.csv\nSaving file: train_data_20220709_2.csv\nSaving file: train_data_20220709_3.csv\nSaving file: train_data_20220709_4.csv\nSaving file: train_data_20220709_5.csv\nSaving file: train_data_20220709_6.csv\nSaving file: train_data_20220709_7.csv\nSaving file: train_data_20220709_8.csv\nSaving file: train_data_20220709_9.csv\nSaving file: train_data_20220709_10.csv\nSaving file: train_data_20220709_11.csv\nGetting data for: 20220710\nSaving file: train_data_20220710_12.csv\nSaving file: train_data_20220710_13.csv\nSaving file: train_data_20220710_14.csv\nSaving file: train_data_20220710_15.csv\nSaving file: train_data_20220710_16.csv\nSaving file: train_data_20220710_17.csv\nSaving file: train_data_20220710_18.csv\nSaving file: train_data_20220710_19.csv\nSaving file: train_data_20220710_20.csv\nSaving file: train_data_20220710_21.csv\nSaving file: train_data_20220710_22.csv\nSaving file: train_data_20220710_23.csv\nSaving file: train_data_20220710_0.csv\nSaving file: train_data_20220710_1.csv\nSaving file: train_data_20220710_2.csv\nSaving file: train_data_20220710_3.csv\nSaving file: train_data_20220710_4.csv\nSaving file: train_data_20220710_5.csv\nSaving file: train_data_20220710_6.csv\nSaving file: train_data_20220710_7.csv\nSaving file: train_data_20220710_8.csv\nSaving file: train_data_20220710_9.csv\nSaving file: train_data_20220710_10.csv\nSaving file: train_data_20220710_11.csv\nGetting data for: 20220711\nSaving file: train_data_20220711_12.csv\nSaving file: train_data_20220711_13.csv\nSaving file: train_data_20220711_14.csv\nSaving file: train_data_20220711_15.csv\nSaving file: train_data_20220711_16.csv\nSaving file: train_data_20220711_17.csv\nSaving file: train_data_20220711_18.csv\nSaving file: train_data_20220711_19.csv\nSaving file: train_data_20220711_20.csv\nSaving file: train_data_20220711_21.csv\nSaving file: train_data_20220711_22.csv\nSaving file: train_data_20220711_23.csv\nSaving file: train_data_20220711_0.csv\nSaving file: train_data_20220711_1.csv\nSaving file: train_data_20220711_2.csv\nSaving file: train_data_20220711_3.csv\nSaving file: train_data_20220711_4.csv\nSaving file: train_data_20220711_5.csv\nSaving file: train_data_20220711_6.csv\nSaving file: train_data_20220711_7.csv\nSaving file: train_data_20220711_8.csv\nSaving file: train_data_20220711_9.csv\nSaving file: train_data_20220711_10.csv\nSaving file: train_data_20220711_11.csv\nGetting data for: 20220712\nSaving file: train_data_20220712_12.csv\nSaving file: train_data_20220712_13.csv\nSaving file: train_data_20220712_14.csv\nSaving file: train_data_20220712_15.csv\nSaving file: train_data_20220712_16.csv\nSaving file: train_data_20220712_17.csv\nSaving file: train_data_20220712_18.csv\nSaving file: train_data_20220712_19.csv\nSaving file: train_data_20220712_20.csv\nSaving file: train_data_20220712_21.csv\nSaving file: train_data_20220712_22.csv\nSaving file: train_data_20220712_23.csv\nSaving file: train_data_20220712_0.csv\nSaving file: train_data_20220712_1.csv\nSaving file: train_data_20220712_2.csv\nSaving file: train_data_20220712_3.csv\nSaving file: train_data_20220712_4.csv\nSaving file: train_data_20220712_5.csv\nSaving file: train_data_20220712_6.csv\nSaving file: train_data_20220712_7.csv\nSaving file: train_data_20220712_8.csv\nSaving file: train_data_20220712_9.csv\nSaving file: train_data_20220712_10.csv\nSaving file: train_data_20220712_11.csv\nGetting data for: 20220713\nSaving file: train_data_20220713_12.csv\nSaving file: train_data_20220713_13.csv\nSaving file: train_data_20220713_14.csv\nSaving file: train_data_20220713_15.csv\nSaving file: train_data_20220713_16.csv\nSaving file: train_data_20220713_17.csv\nSaving file: train_data_20220713_18.csv\nSaving file: train_data_20220713_19.csv\nSaving file: train_data_20220713_20.csv\nSaving file: train_data_20220713_21.csv\nSaving file: train_data_20220713_22.csv\nSaving file: train_data_20220713_23.csv\nSaving file: train_data_20220713_0.csv\nSaving file: train_data_20220713_1.csv\nSaving file: train_data_20220713_2.csv\nSaving file: train_data_20220713_3.csv\nSaving file: train_data_20220713_4.csv\nSaving file: train_data_20220713_5.csv\nSaving file: train_data_20220713_6.csv\nSaving file: train_data_20220713_7.csv\nSaving file: train_data_20220713_8.csv\nSaving file: train_data_20220713_9.csv\nSaving file: train_data_20220713_10.csv\nSaving file: train_data_20220713_11.csv\nGetting data for: 20220714\nSaving file: train_data_20220714_12.csv\nSaving file: train_data_20220714_13.csv\nSaving file: train_data_20220714_14.csv\nSaving file: train_data_20220714_15.csv\nSaving file: train_data_20220714_16.csv\nSaving file: train_data_20220714_17.csv\nSaving file: train_data_20220714_18.csv\nSaving file: train_data_20220714_19.csv\nSaving file: train_data_20220714_20.csv\nSaving file: train_data_20220714_21.csv\nSaving file: train_data_20220714_22.csv\nSaving file: train_data_20220714_23.csv\nSaving file: train_data_20220714_0.csv\nSaving file: train_data_20220714_1.csv\nSaving file: train_data_20220714_2.csv\nSaving file: train_data_20220714_3.csv\nSaving file: train_data_20220714_4.csv\nSaving file: train_data_20220714_5.csv\nSaving file: train_data_20220714_6.csv\nSaving file: train_data_20220714_7.csv\nSaving file: train_data_20220714_8.csv\nSaving file: train_data_20220714_9.csv\nSaving file: train_data_20220714_10.csv\nSaving file: train_data_20220714_11.csv\nGetting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220715_0.csv\nSaving file: train_data_20220715_1.csv\nSaving file: train_data_20220715_2.csv\nSaving file: train_data_20220715_3.csv\nSaving file: train_data_20220715_4.csv\nSaving file: train_data_20220715_5.csv\nSaving file: train_data_20220715_6.csv\nSaving file: train_data_20220715_7.csv\nSaving file: train_data_20220715_8.csv\nSaving file: train_data_20220715_9.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220716_0.csv\nSaving file: train_data_20220716_1.csv\nSaving file: train_data_20220716_2.csv\nSaving file: train_data_20220716_3.csv\nSaving file: train_data_20220716_4.csv\nSaving file: train_data_20220716_5.csv\nSaving file: train_data_20220716_6.csv\nSaving file: train_data_20220716_7.csv\nSaving file: train_data_20220716_8.csv\nSaving file: train_data_20220716_9.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nGetting data for: 20220717\nSaving file: train_data_20220717_12.csv\nSaving file: train_data_20220717_13.csv\nSaving file: train_data_20220717_14.csv\nSaving file: train_data_20220717_15.csv\nSaving file: train_data_20220717_16.csv\nSaving file: train_data_20220717_17.csv\nSaving file: train_data_20220717_18.csv\nSaving file: train_data_20220717_19.csv\nSaving file: train_data_20220717_20.csv\nSaving file: train_data_20220717_21.csv\nSaving file: train_data_20220717_22.csv\nSaving file: train_data_20220717_23.csv\nSaving file: train_data_20220717_0.csv\nSaving file: train_data_20220717_1.csv\nSaving file: train_data_20220717_2.csv\nSaving file: train_data_20220717_3.csv\nSaving file: train_data_20220717_4.csv\nSaving file: train_data_20220717_5.csv\nSaving file: train_data_20220717_6.csv\nSaving file: train_data_20220717_7.csv\nSaving file: train_data_20220717_8.csv\nSaving file: train_data_20220717_9.csv\nSaving file: train_data_20220717_10.csv\nSaving file: train_data_20220717_11.csv\nGetting data for: 20220718\nSaving file: train_data_20220718_12.csv\nSaving file: train_data_20220718_13.csv\nSaving file: train_data_20220718_14.csv\nSaving file: train_data_20220718_15.csv\nSaving file: train_data_20220718_16.csv\nSaving file: train_data_20220718_17.csv\nSaving file: train_data_20220718_18.csv\nSaving file: train_data_20220718_19.csv\nSaving file: train_data_20220718_20.csv\nSaving file: train_data_20220718_21.csv\nSaving file: train_data_20220718_22.csv\nSaving file: train_data_20220718_23.csv\nSaving file: train_data_20220718_0.csv\nSaving file: train_data_20220718_1.csv\nSaving file: train_data_20220718_2.csv\nSaving file: train_data_20220718_3.csv\nSaving file: train_data_20220718_4.csv\nSaving file: train_data_20220718_5.csv\nSaving file: train_data_20220718_6.csv\nSaving file: train_data_20220718_7.csv\nSaving file: train_data_20220718_8.csv\nSaving file: train_data_20220718_9.csv\nSaving file: train_data_20220718_10.csv\nSaving file: train_data_20220718_11.csv\nGetting data for: 20220719\nSaving file: train_data_20220719_12.csv\nSaving file: train_data_20220719_13.csv\nSaving file: train_data_20220719_14.csv\nSaving file: train_data_20220719_15.csv\nSaving file: train_data_20220719_16.csv\nSaving file: train_data_20220719_17.csv\nSaving file: train_data_20220719_18.csv\nSaving file: train_data_20220719_19.csv\nSaving file: train_data_20220719_20.csv\nSaving file: train_data_20220719_21.csv\nSaving file: train_data_20220719_22.csv\nSaving file: train_data_20220719_23.csv\nSaving file: train_data_20220719_0.csv\nSaving file: train_data_20220719_1.csv\nSaving file: train_data_20220719_2.csv\nSaving file: train_data_20220719_3.csv\nSaving file: train_data_20220719_4.csv\nSaving file: train_data_20220719_5.csv\nSaving file: train_data_20220719_6.csv\nSaving file: train_data_20220719_7.csv\nSaving file: train_data_20220719_8.csv\nSaving file: train_data_20220719_9.csv\nSaving file: train_data_20220719_10.csv\nSaving file: train_data_20220719_11.csv\nGetting data for: 20220720\nSaving file: train_data_20220720_12.csv\nSaving file: train_data_20220720_13.csv\nSaving file: train_data_20220720_14.csv\nSaving file: train_data_20220720_15.csv\nSaving file: train_data_20220720_16.csv\nSaving file: train_data_20220720_17.csv\nSaving file: train_data_20220720_18.csv\nSaving file: train_data_20220720_19.csv\nSaving file: train_data_20220720_20.csv\nSaving file: train_data_20220720_21.csv\nSaving file: train_data_20220720_22.csv\nSaving file: train_data_20220720_23.csv\nSaving file: train_data_20220720_0.csv\nSaving file: train_data_20220720_1.csv\nSaving file: train_data_20220720_2.csv\nSaving file: train_data_20220720_3.csv\nSaving file: train_data_20220720_4.csv\nSaving file: train_data_20220720_5.csv\nSaving file: train_data_20220720_6.csv\nSaving file: train_data_20220720_7.csv\nSaving file: train_data_20220720_8.csv\nSaving file: train_data_20220720_9.csv\nSaving file: train_data_20220720_10.csv\nSaving file: train_data_20220720_11.csv\nGetting data for: 20220721\nSaving file: train_data_20220721_12.csv\nSaving file: train_data_20220721_13.csv\nSaving file: train_data_20220721_14.csv\nSaving file: train_data_20220721_15.csv\nSaving file: train_data_20220721_16.csv\nSaving file: train_data_20220721_17.csv\nSaving file: train_data_20220721_18.csv\nSaving file: train_data_20220721_19.csv\nSaving file: train_data_20220721_20.csv\nSaving file: train_data_20220721_21.csv\nSaving file: train_data_20220721_22.csv\nSaving file: train_data_20220721_23.csv\nSaving file: train_data_20220721_0.csv\nSaving file: train_data_20220721_1.csv\nSaving file: train_data_20220721_2.csv\nSaving file: train_data_20220721_3.csv\nSaving file: train_data_20220721_4.csv\nSaving file: train_data_20220721_5.csv\nSaving file: train_data_20220721_6.csv\nSaving file: train_data_20220721_7.csv\nSaving file: train_data_20220721_8.csv\nSaving file: train_data_20220721_9.csv\nSaving file: train_data_20220721_10.csv\nSaving file: train_data_20220721_11.csv\nGetting data for: 20220722\nSaving file: train_data_20220722_12.csv\nSaving file: train_data_20220722_13.csv\nSaving file: train_data_20220722_14.csv\nSaving file: train_data_20220722_15.csv\nSaving file: train_data_20220722_16.csv\nSaving file: train_data_20220722_17.csv\nSaving file: train_data_20220722_18.csv\nSaving file: train_data_20220722_19.csv\nSaving file: train_data_20220722_20.csv\nSaving file: train_data_20220722_21.csv\nSaving file: train_data_20220722_22.csv\nSaving file: train_data_20220722_23.csv\nSaving file: train_data_20220722_0.csv\nSaving file: train_data_20220722_1.csv\nSaving file: train_data_20220722_2.csv\nSaving file: train_data_20220722_3.csv\nSaving file: train_data_20220722_4.csv\nSaving file: train_data_20220722_5.csv\nSaving file: train_data_20220722_6.csv\nSaving file: train_data_20220722_7.csv\nSaving file: train_data_20220722_8.csv\nSaving file: train_data_20220722_9.csv\nSaving file: train_data_20220722_10.csv\nSaving file: train_data_20220722_11.csv\nGetting data for: 20220723\nSaving file: train_data_20220723_12.csv\nSaving file: train_data_20220723_13.csv\nSaving file: train_data_20220723_14.csv\nSaving file: train_data_20220723_15.csv\nSaving file: train_data_20220723_16.csv\nSaving file: train_data_20220723_17.csv\nSaving file: train_data_20220723_18.csv\nSaving file: train_data_20220723_19.csv\nSaving file: train_data_20220723_20.csv\nSaving file: train_data_20220723_21.csv\nSaving file: train_data_20220723_22.csv\nSaving file: train_data_20220723_23.csv\nSaving file: train_data_20220723_0.csv\nSaving file: train_data_20220723_1.csv\nSaving file: train_data_20220723_2.csv\nSaving file: train_data_20220723_3.csv\nSaving file: train_data_20220723_4.csv\nSaving file: train_data_20220723_5.csv\nSaving file: train_data_20220723_6.csv\nSaving file: train_data_20220723_7.csv\nSaving file: train_data_20220723_8.csv\nSaving file: train_data_20220723_9.csv\nSaving file: train_data_20220723_10.csv\nSaving file: train_data_20220723_11.csv\nGetting data for: 20220724\nSaving file: train_data_20220724_12.csv\nSaving file: train_data_20220724_13.csv\nSaving file: train_data_20220724_14.csv\nSaving file: train_data_20220724_15.csv\nSaving file: train_data_20220724_16.csv\nSaving file: train_data_20220724_17.csv\nSaving file: train_data_20220724_18.csv\nSaving file: train_data_20220724_19.csv\nSaving file: train_data_20220724_20.csv\nSaving file: train_data_20220724_21.csv\nSaving file: train_data_20220724_22.csv\nSaving file: train_data_20220724_23.csv\nSaving file: train_data_20220724_0.csv\nSaving file: train_data_20220724_1.csv\nSaving file: train_data_20220724_2.csv\nSaving file: train_data_20220724_3.csv\nSaving file: train_data_20220724_4.csv\nSaving file: train_data_20220724_5.csv\nSaving file: train_data_20220724_6.csv\nSaving file: train_data_20220724_7.csv\nSaving file: train_data_20220724_8.csv\nSaving file: train_data_20220724_9.csv\nSaving file: train_data_20220724_10.csv\nSaving file: train_data_20220724_11.csv\nGetting data for: 20220725\nSaving file: train_data_20220725_12.csv\nSaving file: train_data_20220725_13.csv\nSaving file: train_data_20220725_14.csv\nSaving file: train_data_20220725_15.csv\nSaving file: train_data_20220725_16.csv\nSaving file: train_data_20220725_17.csv\nSaving file: train_data_20220725_18.csv\nSaving file: train_data_20220725_19.csv\nSaving file: train_data_20220725_20.csv\nSaving file: train_data_20220725_21.csv\nSaving file: train_data_20220725_22.csv\nSaving file: train_data_20220725_23.csv\nSaving file: train_data_20220725_0.csv\nSaving file: train_data_20220725_1.csv\nSaving file: train_data_20220725_2.csv\nSaving file: train_data_20220725_3.csv\nSaving file: train_data_20220725_4.csv\nSaving file: train_data_20220725_5.csv\nSaving file: train_data_20220725_6.csv\nSaving file: train_data_20220725_7.csv\nSaving file: train_data_20220725_8.csv\nSaving file: train_data_20220725_9.csv\nSaving file: train_data_20220725_10.csv\nSaving file: train_data_20220725_11.csv\nGetting data for: 20220726\nSaving file: train_data_20220726_12.csv\nSaving file: train_data_20220726_13.csv\nSaving file: train_data_20220726_14.csv\nSaving file: train_data_20220726_15.csv\nSaving file: train_data_20220726_16.csv\nSaving file: train_data_20220726_17.csv\nSaving file: train_data_20220726_18.csv\nSaving file: train_data_20220726_19.csv\nSaving file: train_data_20220726_20.csv\nSaving file: train_data_20220726_21.csv\nSaving file: train_data_20220726_22.csv\nSaving file: train_data_20220726_23.csv\nSaving file: train_data_20220726_0.csv\nSaving file: train_data_20220726_1.csv\nSaving file: train_data_20220726_2.csv\nSaving file: train_data_20220726_3.csv\nSaving file: train_data_20220726_4.csv\nSaving file: train_data_20220726_5.csv\nSaving file: train_data_20220726_6.csv\nSaving file: train_data_20220726_7.csv\nSaving file: train_data_20220726_8.csv\nSaving file: train_data_20220726_9.csv\nSaving file: train_data_20220726_10.csv\nSaving file: train_data_20220726_11.csv\nGetting data for: 20220727\nSaving file: train_data_20220727_12.csv\nSaving file: train_data_20220727_13.csv\nSaving file: train_data_20220727_14.csv\nSaving file: train_data_20220727_15.csv\nSaving file: train_data_20220727_16.csv\nSaving file: train_data_20220727_17.csv\nSaving file: train_data_20220727_18.csv\nSaving file: train_data_20220727_19.csv\nSaving file: train_data_20220727_20.csv\nSaving file: train_data_20220727_21.csv\nSaving file: train_data_20220727_22.csv\nSaving file: train_data_20220727_23.csv\nSaving file: train_data_20220727_0.csv\nSaving file: train_data_20220727_1.csv\nSaving file: train_data_20220727_2.csv\nSaving file: train_data_20220727_3.csv\nSaving file: train_data_20220727_4.csv\nSaving file: train_data_20220727_5.csv\nSaving file: train_data_20220727_6.csv\nSaving file: train_data_20220727_7.csv\nSaving file: train_data_20220727_8.csv\nSaving file: train_data_20220727_9.csv\nSaving file: train_data_20220727_10.csv\nSaving file: train_data_20220727_11.csv\nGetting data for: 20220728\nSaving file: train_data_20220728_12.csv\nSaving file: train_data_20220728_13.csv\nSaving file: train_data_20220728_14.csv\nSaving file: train_data_20220728_15.csv\nSaving file: train_data_20220728_16.csv\nSaving file: train_data_20220728_17.csv\nSaving file: train_data_20220728_18.csv\nSaving file: train_data_20220728_19.csv\nSaving file: train_data_20220728_20.csv\nSaving file: train_data_20220728_21.csv\nSaving file: train_data_20220728_22.csv\nSaving file: train_data_20220728_23.csv\nSaving file: train_data_20220728_0.csv\nSaving file: train_data_20220728_1.csv\nSaving file: train_data_20220728_2.csv\nSaving file: train_data_20220728_3.csv\nSaving file: train_data_20220728_4.csv\nSaving file: train_data_20220728_5.csv\nSaving file: train_data_20220728_6.csv\nSaving file: train_data_20220728_7.csv\nSaving file: train_data_20220728_8.csv\nSaving file: train_data_20220728_9.csv\nSaving file: train_data_20220728_10.csv\nSaving file: train_data_20220728_11.csv\nGetting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220729_0.csv\nSaving file: train_data_20220729_1.csv\nSaving file: train_data_20220729_2.csv\nSaving file: train_data_20220729_3.csv\nSaving file: train_data_20220729_4.csv\nSaving file: train_data_20220729_5.csv\nSaving file: train_data_20220729_6.csv\nSaving file: train_data_20220729_7.csv\nSaving file: train_data_20220729_8.csv\nSaving file: train_data_20220729_9.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220730_0.csv\nSaving file: train_data_20220730_1.csv\nSaving file: train_data_20220730_2.csv\nSaving file: train_data_20220730_3.csv\nSaving file: train_data_20220730_4.csv\nSaving file: train_data_20220730_5.csv\nSaving file: train_data_20220730_6.csv\nSaving file: train_data_20220730_7.csv\nSaving file: train_data_20220730_8.csv\nSaving file: train_data_20220730_9.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nGetting data for: 20220731\nSaving file: train_data_20220731_12.csv\nSaving file: train_data_20220731_13.csv\nSaving file: train_data_20220731_14.csv\nSaving file: train_data_20220731_15.csv\nSaving file: train_data_20220731_16.csv\nSaving file: train_data_20220731_17.csv\nSaving file: train_data_20220731_18.csv\nSaving file: train_data_20220731_19.csv\nSaving file: train_data_20220731_20.csv\nSaving file: train_data_20220731_21.csv\nSaving file: train_data_20220731_22.csv\nSaving file: train_data_20220731_23.csv\nSaving file: train_data_20220731_0.csv\nSaving file: train_data_20220731_1.csv\nSaving file: train_data_20220731_2.csv\nSaving file: train_data_20220731_3.csv\nSaving file: train_data_20220731_4.csv\nSaving file: train_data_20220731_5.csv\nSaving file: train_data_20220731_6.csv\nSaving file: train_data_20220731_7.csv\nSaving file: train_data_20220731_8.csv\nSaving file: train_data_20220731_9.csv\nSaving file: train_data_20220731_10.csv\nSaving file: train_data_20220731_11.csv\nGetting data for: 20220801\nSaving file: train_data_20220801_12.csv\nSaving file: train_data_20220801_13.csv\nSaving file: train_data_20220801_14.csv\nSaving file: train_data_20220801_15.csv\nSaving file: train_data_20220801_16.csv\nSaving file: train_data_20220801_17.csv\nSaving file: train_data_20220801_18.csv\nSaving file: train_data_20220801_19.csv\nSaving file: train_data_20220801_20.csv\nSaving file: train_data_20220801_21.csv\nSaving file: train_data_20220801_22.csv\nSaving file: train_data_20220801_23.csv\nSaving file: train_data_20220801_0.csv\nSaving file: train_data_20220801_1.csv\nSaving file: train_data_20220801_2.csv\nSaving file: train_data_20220801_3.csv\nSaving file: train_data_20220801_4.csv\nSaving file: train_data_20220801_5.csv\nSaving file: train_data_20220801_6.csv\nSaving file: train_data_20220801_7.csv\nSaving file: train_data_20220801_8.csv\nSaving file: train_data_20220801_9.csv\nSaving file: train_data_20220801_10.csv\nSaving file: train_data_20220801_11.csv\nGetting data for: 20220802\nSaving file: train_data_20220802_12.csv\nSaving file: train_data_20220802_13.csv\nSaving file: train_data_20220802_14.csv\nSaving file: train_data_20220802_15.csv\nSaving file: train_data_20220802_16.csv\nSaving file: train_data_20220802_17.csv\nSaving file: train_data_20220802_18.csv\nSaving file: train_data_20220802_19.csv\nSaving file: train_data_20220802_20.csv\nSaving file: train_data_20220802_21.csv\nSaving file: train_data_20220802_22.csv\nSaving file: train_data_20220802_23.csv\nSaving file: train_data_20220802_0.csv\nSaving file: train_data_20220802_1.csv\nSaving file: train_data_20220802_2.csv\nSaving file: train_data_20220802_3.csv\nSaving file: train_data_20220802_4.csv\nSaving file: train_data_20220802_5.csv\nSaving file: train_data_20220802_6.csv\nSaving file: train_data_20220802_7.csv\nSaving file: train_data_20220802_8.csv\nSaving file: train_data_20220802_9.csv\nSaving file: train_data_20220802_10.csv\nSaving file: train_data_20220802_11.csv\nGetting data for: 20220803\nSaving file: train_data_20220803_12.csv\nSaving file: train_data_20220803_13.csv\nSaving file: train_data_20220803_14.csv\nSaving file: train_data_20220803_15.csv\nSaving file: train_data_20220803_16.csv\nSaving file: train_data_20220803_17.csv\nSaving file: train_data_20220803_18.csv\nSaving file: train_data_20220803_19.csv\nSaving file: train_data_20220803_20.csv\nSaving file: train_data_20220803_21.csv\nSaving file: train_data_20220803_22.csv\nSaving file: train_data_20220803_23.csv\nSaving file: train_data_20220803_0.csv\nSaving file: train_data_20220803_1.csv\nSaving file: train_data_20220803_2.csv\nSaving file: train_data_20220803_3.csv\nSaving file: train_data_20220803_4.csv\nSaving file: train_data_20220803_5.csv\nSaving file: train_data_20220803_6.csv\nSaving file: train_data_20220803_7.csv\nSaving file: train_data_20220803_8.csv\nSaving file: train_data_20220803_9.csv\nSaving file: train_data_20220803_10.csv\nSaving file: train_data_20220803_11.csv\nGetting data for: 20220804\nSaving file: train_data_20220804_12.csv\nSaving file: train_data_20220804_13.csv\nSaving file: train_data_20220804_14.csv\nSaving file: train_data_20220804_15.csv\nSaving file: train_data_20220804_16.csv\nSaving file: train_data_20220804_17.csv\nSaving file: train_data_20220804_18.csv\nSaving file: train_data_20220804_19.csv\nSaving file: train_data_20220804_20.csv\nSaving file: train_data_20220804_21.csv\nSaving file: train_data_20220804_22.csv\nSaving file: train_data_20220804_23.csv\nSaving file: train_data_20220804_0.csv\nSaving file: train_data_20220804_1.csv\nSaving file: train_data_20220804_2.csv\nSaving file: train_data_20220804_3.csv\nSaving file: train_data_20220804_4.csv\nSaving file: train_data_20220804_5.csv\nSaving file: train_data_20220804_6.csv\nSaving file: train_data_20220804_7.csv\nSaving file: train_data_20220804_8.csv\nSaving file: train_data_20220804_9.csv\nSaving file: train_data_20220804_10.csv\nSaving file: train_data_20220804_11.csv\nGetting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220805_0.csv\nSaving file: train_data_20220805_1.csv\nSaving file: train_data_20220805_2.csv\nSaving file: train_data_20220805_3.csv\nSaving file: train_data_20220805_4.csv\nSaving file: train_data_20220805_5.csv\nSaving file: train_data_20220805_6.csv\nSaving file: train_data_20220805_7.csv\nSaving file: train_data_20220805_8.csv\nSaving file: train_data_20220805_9.csv\nSaving file: train_data_20220805_10.csv\nSaving file: train_data_20220805_11.csv\nGetting data for: 20220806\nSaving file: train_data_20220806_12.csv\nSaving file: train_data_20220806_13.csv\nSaving file: train_data_20220806_14.csv\nSaving file: train_data_20220806_15.csv\nSaving file: train_data_20220806_16.csv\nSaving file: train_data_20220806_17.csv\nSaving file: train_data_20220806_18.csv\nSaving file: train_data_20220806_19.csv\nSaving file: train_data_20220806_20.csv\nSaving file: train_data_20220806_21.csv\nSaving file: train_data_20220806_22.csv\nSaving file: train_data_20220806_23.csv\nSaving file: train_data_20220806_0.csv\nSaving file: train_data_20220806_1.csv\nSaving file: train_data_20220806_2.csv\nSaving file: train_data_20220806_3.csv\nSaving file: train_data_20220806_4.csv\nSaving file: train_data_20220806_5.csv\nSaving file: train_data_20220806_6.csv\nSaving file: train_data_20220806_7.csv\nSaving file: train_data_20220806_8.csv\nSaving file: train_data_20220806_9.csv\nSaving file: train_data_20220806_10.csv\nSaving file: train_data_20220806_11.csv\nGetting data for: 20220807\nSaving file: train_data_20220807_12.csv\nSaving file: train_data_20220807_13.csv\nSaving file: train_data_20220807_14.csv\nSaving file: train_data_20220807_15.csv\nSaving file: train_data_20220807_16.csv\nSaving file: train_data_20220807_17.csv\nSaving file: train_data_20220807_18.csv\nSaving file: train_data_20220807_19.csv\nSaving file: train_data_20220807_20.csv\nSaving file: train_data_20220807_21.csv\nSaving file: train_data_20220807_22.csv\nSaving file: train_data_20220807_23.csv\nSaving file: train_data_20220807_0.csv\nSaving file: train_data_20220807_1.csv\nSaving file: train_data_20220807_2.csv\nSaving file: train_data_20220807_3.csv\nSaving file: train_data_20220807_4.csv\nSaving file: train_data_20220807_5.csv\nSaving file: train_data_20220807_6.csv\nSaving file: train_data_20220807_7.csv\nSaving file: train_data_20220807_8.csv\nSaving file: train_data_20220807_9.csv\nSaving file: train_data_20220807_10.csv\nSaving file: train_data_20220807_11.csv\nGetting data for: 20220808\nSaving file: train_data_20220808_12.csv\nSaving file: train_data_20220808_13.csv\nSaving file: train_data_20220808_14.csv\nSaving file: train_data_20220808_15.csv\nSaving file: train_data_20220808_16.csv\nSaving file: train_data_20220808_17.csv\nSaving file: train_data_20220808_18.csv\nSaving file: train_data_20220808_19.csv\nSaving file: train_data_20220808_20.csv\nSaving file: train_data_20220808_21.csv\nSaving file: train_data_20220808_22.csv\nSaving file: train_data_20220808_23.csv\nSaving file: train_data_20220808_0.csv\nSaving file: train_data_20220808_1.csv\nSaving file: train_data_20220808_2.csv\nSaving file: train_data_20220808_3.csv\nSaving file: train_data_20220808_4.csv\nSaving file: train_data_20220808_5.csv\nSaving file: train_data_20220808_6.csv\nSaving file: train_data_20220808_7.csv\nSaving file: train_data_20220808_8.csv\nSaving file: train_data_20220808_9.csv\nSaving file: train_data_20220808_10.csv\nSaving file: train_data_20220808_11.csv\nDone!\n",
  "history_begin_time" : 1660171021518,
  "history_end_time" : 1660189689417,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "h337uz1dr19",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 6, 1)   # start date\nedate = date(2022, 8, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220601\nTraceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 40, in <module>\n    df_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/xarray/backends/api.py\", line 479, in open_dataset\n    engine = plugins.guess_engine(filename_or_obj)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/xarray/backends/plugins.py\", line 148, in guess_engine\n    raise ValueError(error_msg)\nValueError: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html\n",
  "history_begin_time" : 1660166193079,
  "history_end_time" : 1660166318912,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "j9fobfrxom7",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 8, 1)   # start date\nedate = date(2022, 8, 5)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220801\nSaving file: train_data_20220801_12.csv\nSaving file: train_data_20220801_13.csv\nSaving file: train_data_20220801_14.csv\nSaving file: train_data_20220801_15.csv\nSaving file: train_data_20220801_16.csv\nSaving file: train_data_20220801_17.csv\nSaving file: train_data_20220801_18.csv\nSaving file: train_data_20220801_19.csv\nSaving file: train_data_20220801_20.csv\nSaving file: train_data_20220801_21.csv\nSaving file: train_data_20220801_22.csv\nSaving file: train_data_20220801_23.csv\nSaving file: train_data_20220801_0.csv\nSaving file: train_data_20220801_1.csv\nSaving file: train_data_20220801_2.csv\nSaving file: train_data_20220801_3.csv\nSaving file: train_data_20220801_4.csv\nSaving file: train_data_20220801_5.csv\nSaving file: train_data_20220801_6.csv\nSaving file: train_data_20220801_7.csv\nSaving file: train_data_20220801_8.csv\nSaving file: train_data_20220801_9.csv\nSaving file: train_data_20220801_10.csv\nSaving file: train_data_20220801_11.csv\nGetting data for: 20220802\nSaving file: train_data_20220802_12.csv\nSaving file: train_data_20220802_13.csv\nSaving file: train_data_20220802_14.csv\nSaving file: train_data_20220802_15.csv\nSaving file: train_data_20220802_16.csv\nSaving file: train_data_20220802_17.csv\nSaving file: train_data_20220802_18.csv\nSaving file: train_data_20220802_19.csv\nSaving file: train_data_20220802_20.csv\nSaving file: train_data_20220802_21.csv\nSaving file: train_data_20220802_22.csv\nSaving file: train_data_20220802_23.csv\nSaving file: train_data_20220802_0.csv\nSaving file: train_data_20220802_1.csv\nSaving file: train_data_20220802_2.csv\nSaving file: train_data_20220802_3.csv\nSaving file: train_data_20220802_4.csv\nSaving file: train_data_20220802_5.csv\nSaving file: train_data_20220802_6.csv\nSaving file: train_data_20220802_7.csv\nSaving file: train_data_20220802_8.csv\nSaving file: train_data_20220802_9.csv\nSaving file: train_data_20220802_10.csv\nSaving file: train_data_20220802_11.csv\nGetting data for: 20220803\nSaving file: train_data_20220803_12.csv\nSaving file: train_data_20220803_13.csv\nSaving file: train_data_20220803_14.csv\nSaving file: train_data_20220803_15.csv\nSaving file: train_data_20220803_16.csv\nSaving file: train_data_20220803_17.csv\nSaving file: train_data_20220803_18.csv\nSaving file: train_data_20220803_19.csv\nSaving file: train_data_20220803_20.csv\nSaving file: train_data_20220803_21.csv\nSaving file: train_data_20220803_22.csv\nSaving file: train_data_20220803_23.csv\nSaving file: train_data_20220803_0.csv\nSaving file: train_data_20220803_1.csv\nSaving file: train_data_20220803_2.csv\nSaving file: train_data_20220803_3.csv\nSaving file: train_data_20220803_4.csv\nSaving file: train_data_20220803_5.csv\nSaving file: train_data_20220803_6.csv\nSaving file: train_data_20220803_7.csv\nSaving file: train_data_20220803_8.csv\nSaving file: train_data_20220803_9.csv\nSaving file: train_data_20220803_10.csv\nSaving file: train_data_20220803_11.csv\nGetting data for: 20220804\nSaving file: train_data_20220804_12.csv\nSaving file: train_data_20220804_13.csv\nSaving file: train_data_20220804_14.csv\nSaving file: train_data_20220804_15.csv\nSaving file: train_data_20220804_16.csv\nSaving file: train_data_20220804_17.csv\nSaving file: train_data_20220804_18.csv\nSaving file: train_data_20220804_19.csv\nSaving file: train_data_20220804_20.csv\nSaving file: train_data_20220804_21.csv\nSaving file: train_data_20220804_22.csv\nSaving file: train_data_20220804_23.csv\nSaving file: train_data_20220804_0.csv\nSaving file: train_data_20220804_1.csv\nSaving file: train_data_20220804_2.csv\nSaving file: train_data_20220804_3.csv\nSaving file: train_data_20220804_4.csv\nSaving file: train_data_20220804_5.csv\nSaving file: train_data_20220804_6.csv\nSaving file: train_data_20220804_7.csv\nSaving file: train_data_20220804_8.csv\nSaving file: train_data_20220804_9.csv\nSaving file: train_data_20220804_10.csv\nSaving file: train_data_20220804_11.csv\nGetting data for: 20220805\nSaving file: train_data_20220805_12.csv\nSaving file: train_data_20220805_13.csv\nSaving file: train_data_20220805_14.csv\nSaving file: train_data_20220805_15.csv\nSaving file: train_data_20220805_16.csv\nSaving file: train_data_20220805_17.csv\nSaving file: train_data_20220805_18.csv\nSaving file: train_data_20220805_19.csv\nSaving file: train_data_20220805_20.csv\nSaving file: train_data_20220805_21.csv\nSaving file: train_data_20220805_22.csv\nSaving file: train_data_20220805_23.csv\nSaving file: train_data_20220805_0.csv\nSaving file: train_data_20220805_1.csv\nSaving file: train_data_20220805_2.csv\nSaving file: train_data_20220805_3.csv\nSaving file: train_data_20220805_4.csv\nSaving file: train_data_20220805_5.csv\nSaving file: train_data_20220805_6.csv\nSaving file: train_data_20220805_7.csv\nSaving file: train_data_20220805_8.csv\nSaving file: train_data_20220805_9.csv\nSaving file: train_data_20220805_10.csv\nSaving file: train_data_20220805_11.csv\nDone!\n",
  "history_begin_time" : 1660007420713,
  "history_end_time" : 1660007981886,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "CncSzAW6aPWz",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(real_hour_value)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220701_0.csv\nSaving file: train_data_20220701_1.csv\nSaving file: train_data_20220701_2.csv\nSaving file: train_data_20220701_3.csv\nSaving file: train_data_20220701_4.csv\nSaving file: train_data_20220701_5.csv\nSaving file: train_data_20220701_6.csv\nSaving file: train_data_20220701_7.csv\nSaving file: train_data_20220701_8.csv\nSaving file: train_data_20220701_9.csv\nSaving file: train_data_20220701_10.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nDone!\n",
  "history_begin_time" : 1659740262737,
  "history_end_time" : 1660261044784,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "qBEAsBypRphl",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220701_0.csv\nSaving file: train_data_20220701_1.csv\nSaving file: train_data_20220701_2.csv\nSaving file: train_data_20220701_3.csv\nSaving file: train_data_20220701_4.csv\nSaving file: train_data_20220701_5.csv\nSaving file: train_data_20220701_6.csv\nSaving file: train_data_20220701_7.csv\nSaving file: train_data_20220701_8.csv\nSaving file: train_data_20220701_9.csv\nSaving file: train_data_20220701_10.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nDone!\n",
  "history_begin_time" : 1659739481318,
  "history_end_time" : 1660261045494,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "KrZbeWClc5uX",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n        df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "  File \"preparing_cmaq_training_data.py\", line 137\n    df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n                                                                                                                                 ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1659739463323,
  "history_end_time" : 1660261046036,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "yNFsHDgnMMR3",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n        \tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "  File \"preparing_cmaq_training_data.py\", line 137\n    df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n                                                                                                                                 ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1659739419362,
  "history_end_time" : 1660261046808,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "FwKqrxfmYisj",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n        df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "  File \"preparing_cmaq_training_data.py\", line 137\n    df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n                                                                                                                                 ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1659739410582,
  "history_end_time" : 1660261047287,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "TPxOpEZgrGYE",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n\t\treal_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n        df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "  File \"preparing_cmaq_training_data.py\", line 137\n    df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n                                                                                                                                 ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1659739393171,
  "history_end_time" : 1660261048450,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "qlgzmf4fiO5h",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n        real_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n        df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "  File \"preparing_cmaq_training_data.py\", line 43\n    real_hour_value = real_hour_list[k]\n                                      ^\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1659739357788,
  "history_end_time" : 1660261049023,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "I5L73hKed1wk",
  "history_input" : "# get all of the cmaq model output variables\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 2)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nreal_hour_list = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\ntime_step_in_netcdf_list = range(0,24)\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in time_step_in_netcdf_list:\n        real_hour_value = real_hour_list[k]\n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(real_hour_value)+'.csv')\n        df_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(real_hour_value)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : null,
  "history_begin_time" : 1659739246430,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "tpiopkrraqa",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 1)   # start date\nedate = date(2022, 7, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in t:\n            \n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(k)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(k)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220701\nSaving file: train_data_20220701_12.csv\nSaving file: train_data_20220701_13.csv\nSaving file: train_data_20220701_14.csv\nSaving file: train_data_20220701_15.csv\nSaving file: train_data_20220701_16.csv\nSaving file: train_data_20220701_17.csv\nSaving file: train_data_20220701_18.csv\nSaving file: train_data_20220701_19.csv\nSaving file: train_data_20220701_20.csv\nSaving file: train_data_20220701_21.csv\nSaving file: train_data_20220701_22.csv\nSaving file: train_data_20220701_23.csv\nSaving file: train_data_20220701_0.csv\nSaving file: train_data_20220701_1.csv\nSaving file: train_data_20220701_2.csv\nSaving file: train_data_20220701_3.csv\nSaving file: train_data_20220701_4.csv\nSaving file: train_data_20220701_5.csv\nSaving file: train_data_20220701_6.csv\nSaving file: train_data_20220701_7.csv\nSaving file: train_data_20220701_8.csv\nSaving file: train_data_20220701_9.csv\nSaving file: train_data_20220701_10.csv\nSaving file: train_data_20220701_11.csv\nGetting data for: 20220702\nSaving file: train_data_20220702_12.csv\nSaving file: train_data_20220702_13.csv\nSaving file: train_data_20220702_14.csv\nSaving file: train_data_20220702_15.csv\nSaving file: train_data_20220702_16.csv\nSaving file: train_data_20220702_17.csv\nSaving file: train_data_20220702_18.csv\nSaving file: train_data_20220702_19.csv\nSaving file: train_data_20220702_20.csv\nSaving file: train_data_20220702_21.csv\nSaving file: train_data_20220702_22.csv\nSaving file: train_data_20220702_23.csv\nSaving file: train_data_20220702_0.csv\nSaving file: train_data_20220702_1.csv\nSaving file: train_data_20220702_2.csv\nSaving file: train_data_20220702_3.csv\nSaving file: train_data_20220702_4.csv\nSaving file: train_data_20220702_5.csv\nSaving file: train_data_20220702_6.csv\nSaving file: train_data_20220702_7.csv\nSaving file: train_data_20220702_8.csv\nSaving file: train_data_20220702_9.csv\nSaving file: train_data_20220702_10.csv\nSaving file: train_data_20220702_11.csv\nGetting data for: 20220703\nSaving file: train_data_20220703_12.csv\nSaving file: train_data_20220703_13.csv\nSaving file: train_data_20220703_14.csv\nSaving file: train_data_20220703_15.csv\nSaving file: train_data_20220703_16.csv\nSaving file: train_data_20220703_17.csv\nSaving file: train_data_20220703_18.csv\nSaving file: train_data_20220703_19.csv\nSaving file: train_data_20220703_20.csv\nSaving file: train_data_20220703_21.csv\nSaving file: train_data_20220703_22.csv\nSaving file: train_data_20220703_23.csv\nSaving file: train_data_20220703_0.csv\nSaving file: train_data_20220703_1.csv\nSaving file: train_data_20220703_2.csv\nSaving file: train_data_20220703_3.csv\nSaving file: train_data_20220703_4.csv\nSaving file: train_data_20220703_5.csv\nSaving file: train_data_20220703_6.csv\nSaving file: train_data_20220703_7.csv\nSaving file: train_data_20220703_8.csv\nSaving file: train_data_20220703_9.csv\nSaving file: train_data_20220703_10.csv\nSaving file: train_data_20220703_11.csv\nGetting data for: 20220704\nSaving file: train_data_20220704_12.csv\nSaving file: train_data_20220704_13.csv\nSaving file: train_data_20220704_14.csv\nSaving file: train_data_20220704_15.csv\nSaving file: train_data_20220704_16.csv\nSaving file: train_data_20220704_17.csv\nSaving file: train_data_20220704_18.csv\nSaving file: train_data_20220704_19.csv\nSaving file: train_data_20220704_20.csv\nSaving file: train_data_20220704_21.csv\nSaving file: train_data_20220704_22.csv\nSaving file: train_data_20220704_23.csv\nSaving file: train_data_20220704_0.csv\nSaving file: train_data_20220704_1.csv\nSaving file: train_data_20220704_2.csv\nSaving file: train_data_20220704_3.csv\nSaving file: train_data_20220704_4.csv\nSaving file: train_data_20220704_5.csv\nSaving file: train_data_20220704_6.csv\nSaving file: train_data_20220704_7.csv\nSaving file: train_data_20220704_8.csv\nSaving file: train_data_20220704_9.csv\nSaving file: train_data_20220704_10.csv\nSaving file: train_data_20220704_11.csv\nGetting data for: 20220705\nSaving file: train_data_20220705_12.csv\nSaving file: train_data_20220705_13.csv\nSaving file: train_data_20220705_14.csv\nSaving file: train_data_20220705_15.csv\nSaving file: train_data_20220705_16.csv\nSaving file: train_data_20220705_17.csv\nSaving file: train_data_20220705_18.csv\nSaving file: train_data_20220705_19.csv\nSaving file: train_data_20220705_20.csv\nSaving file: train_data_20220705_21.csv\nSaving file: train_data_20220705_22.csv\nSaving file: train_data_20220705_23.csv\nSaving file: train_data_20220705_0.csv\nSaving file: train_data_20220705_1.csv\nSaving file: train_data_20220705_2.csv\nSaving file: train_data_20220705_3.csv\nSaving file: train_data_20220705_4.csv\nSaving file: train_data_20220705_5.csv\nSaving file: train_data_20220705_6.csv\nSaving file: train_data_20220705_7.csv\nSaving file: train_data_20220705_8.csv\nSaving file: train_data_20220705_9.csv\nSaving file: train_data_20220705_10.csv\nSaving file: train_data_20220705_11.csv\nGetting data for: 20220706\nSaving file: train_data_20220706_12.csv\nSaving file: train_data_20220706_13.csv\nSaving file: train_data_20220706_14.csv\nSaving file: train_data_20220706_15.csv\nSaving file: train_data_20220706_16.csv\nSaving file: train_data_20220706_17.csv\nSaving file: train_data_20220706_18.csv\nSaving file: train_data_20220706_19.csv\nSaving file: train_data_20220706_20.csv\nSaving file: train_data_20220706_21.csv\nSaving file: train_data_20220706_22.csv\nSaving file: train_data_20220706_23.csv\nSaving file: train_data_20220706_0.csv\nSaving file: train_data_20220706_1.csv\nSaving file: train_data_20220706_2.csv\nSaving file: train_data_20220706_3.csv\nSaving file: train_data_20220706_4.csv\nSaving file: train_data_20220706_5.csv\nSaving file: train_data_20220706_6.csv\nSaving file: train_data_20220706_7.csv\nSaving file: train_data_20220706_8.csv\nSaving file: train_data_20220706_9.csv\nSaving file: train_data_20220706_10.csv\nSaving file: train_data_20220706_11.csv\nGetting data for: 20220707\nSaving file: train_data_20220707_12.csv\nSaving file: train_data_20220707_13.csv\nSaving file: train_data_20220707_14.csv\nSaving file: train_data_20220707_15.csv\nSaving file: train_data_20220707_16.csv\nSaving file: train_data_20220707_17.csv\nSaving file: train_data_20220707_18.csv\nSaving file: train_data_20220707_19.csv\nSaving file: train_data_20220707_20.csv\nSaving file: train_data_20220707_21.csv\nSaving file: train_data_20220707_22.csv\nSaving file: train_data_20220707_23.csv\nSaving file: train_data_20220707_0.csv\nSaving file: train_data_20220707_1.csv\nSaving file: train_data_20220707_2.csv\nSaving file: train_data_20220707_3.csv\nSaving file: train_data_20220707_4.csv\nSaving file: train_data_20220707_5.csv\nSaving file: train_data_20220707_6.csv\nSaving file: train_data_20220707_7.csv\nSaving file: train_data_20220707_8.csv\nSaving file: train_data_20220707_9.csv\nSaving file: train_data_20220707_10.csv\nSaving file: train_data_20220707_11.csv\nGetting data for: 20220708\nSaving file: train_data_20220708_12.csv\nSaving file: train_data_20220708_13.csv\nSaving file: train_data_20220708_14.csv\nSaving file: train_data_20220708_15.csv\nSaving file: train_data_20220708_16.csv\nSaving file: train_data_20220708_17.csv\nSaving file: train_data_20220708_18.csv\nSaving file: train_data_20220708_19.csv\nSaving file: train_data_20220708_20.csv\nSaving file: train_data_20220708_21.csv\nSaving file: train_data_20220708_22.csv\nSaving file: train_data_20220708_23.csv\nSaving file: train_data_20220708_0.csv\nSaving file: train_data_20220708_1.csv\nSaving file: train_data_20220708_2.csv\nSaving file: train_data_20220708_3.csv\nSaving file: train_data_20220708_4.csv\nSaving file: train_data_20220708_5.csv\nSaving file: train_data_20220708_6.csv\nSaving file: train_data_20220708_7.csv\nSaving file: train_data_20220708_8.csv\nSaving file: train_data_20220708_9.csv\nSaving file: train_data_20220708_10.csv\nSaving file: train_data_20220708_11.csv\nGetting data for: 20220709\nSaving file: train_data_20220709_12.csv\nSaving file: train_data_20220709_13.csv\nSaving file: train_data_20220709_14.csv\nSaving file: train_data_20220709_15.csv\nSaving file: train_data_20220709_16.csv\nSaving file: train_data_20220709_17.csv\nSaving file: train_data_20220709_18.csv\nSaving file: train_data_20220709_19.csv\nSaving file: train_data_20220709_20.csv\nSaving file: train_data_20220709_21.csv\nSaving file: train_data_20220709_22.csv\nSaving file: train_data_20220709_23.csv\nSaving file: train_data_20220709_0.csv\nSaving file: train_data_20220709_1.csv\nSaving file: train_data_20220709_2.csv\nSaving file: train_data_20220709_3.csv\nSaving file: train_data_20220709_4.csv\nSaving file: train_data_20220709_5.csv\nSaving file: train_data_20220709_6.csv\nSaving file: train_data_20220709_7.csv\nSaving file: train_data_20220709_8.csv\nSaving file: train_data_20220709_9.csv\nSaving file: train_data_20220709_10.csv\nSaving file: train_data_20220709_11.csv\nGetting data for: 20220710\nSaving file: train_data_20220710_12.csv\nSaving file: train_data_20220710_13.csv\nSaving file: train_data_20220710_14.csv\nSaving file: train_data_20220710_15.csv\nSaving file: train_data_20220710_16.csv\nSaving file: train_data_20220710_17.csv\nSaving file: train_data_20220710_18.csv\nSaving file: train_data_20220710_19.csv\nSaving file: train_data_20220710_20.csv\nSaving file: train_data_20220710_21.csv\nSaving file: train_data_20220710_22.csv\nSaving file: train_data_20220710_23.csv\nSaving file: train_data_20220710_0.csv\nSaving file: train_data_20220710_1.csv\nSaving file: train_data_20220710_2.csv\nSaving file: train_data_20220710_3.csv\nSaving file: train_data_20220710_4.csv\nSaving file: train_data_20220710_5.csv\nSaving file: train_data_20220710_6.csv\nSaving file: train_data_20220710_7.csv\nSaving file: train_data_20220710_8.csv\nSaving file: train_data_20220710_9.csv\nSaving file: train_data_20220710_10.csv\nSaving file: train_data_20220710_11.csv\nGetting data for: 20220711\nSaving file: train_data_20220711_12.csv\nSaving file: train_data_20220711_13.csv\nSaving file: train_data_20220711_14.csv\nSaving file: train_data_20220711_15.csv\nSaving file: train_data_20220711_16.csv\nSaving file: train_data_20220711_17.csv\nSaving file: train_data_20220711_18.csv\nSaving file: train_data_20220711_19.csv\nSaving file: train_data_20220711_20.csv\nSaving file: train_data_20220711_21.csv\nSaving file: train_data_20220711_22.csv\nSaving file: train_data_20220711_23.csv\nSaving file: train_data_20220711_0.csv\nSaving file: train_data_20220711_1.csv\nSaving file: train_data_20220711_2.csv\nSaving file: train_data_20220711_3.csv\nSaving file: train_data_20220711_4.csv\nSaving file: train_data_20220711_5.csv\nSaving file: train_data_20220711_6.csv\nSaving file: train_data_20220711_7.csv\nSaving file: train_data_20220711_8.csv\nSaving file: train_data_20220711_9.csv\nSaving file: train_data_20220711_10.csv\nSaving file: train_data_20220711_11.csv\nGetting data for: 20220712\nSaving file: train_data_20220712_12.csv\nSaving file: train_data_20220712_13.csv\nSaving file: train_data_20220712_14.csv\nSaving file: train_data_20220712_15.csv\nSaving file: train_data_20220712_16.csv\nSaving file: train_data_20220712_17.csv\nSaving file: train_data_20220712_18.csv\nSaving file: train_data_20220712_19.csv\nSaving file: train_data_20220712_20.csv\nSaving file: train_data_20220712_21.csv\nSaving file: train_data_20220712_22.csv\nSaving file: train_data_20220712_23.csv\nSaving file: train_data_20220712_0.csv\nSaving file: train_data_20220712_1.csv\nSaving file: train_data_20220712_2.csv\nSaving file: train_data_20220712_3.csv\nSaving file: train_data_20220712_4.csv\nSaving file: train_data_20220712_5.csv\nSaving file: train_data_20220712_6.csv\nSaving file: train_data_20220712_7.csv\nSaving file: train_data_20220712_8.csv\nSaving file: train_data_20220712_9.csv\nSaving file: train_data_20220712_10.csv\nSaving file: train_data_20220712_11.csv\nGetting data for: 20220713\nSaving file: train_data_20220713_12.csv\nSaving file: train_data_20220713_13.csv\nSaving file: train_data_20220713_14.csv\nSaving file: train_data_20220713_15.csv\nSaving file: train_data_20220713_16.csv\nSaving file: train_data_20220713_17.csv\nSaving file: train_data_20220713_18.csv\nSaving file: train_data_20220713_19.csv\nSaving file: train_data_20220713_20.csv\nSaving file: train_data_20220713_21.csv\nSaving file: train_data_20220713_22.csv\nSaving file: train_data_20220713_23.csv\nSaving file: train_data_20220713_0.csv\nSaving file: train_data_20220713_1.csv\nSaving file: train_data_20220713_2.csv\nSaving file: train_data_20220713_3.csv\nSaving file: train_data_20220713_4.csv\nSaving file: train_data_20220713_5.csv\nSaving file: train_data_20220713_6.csv\nSaving file: train_data_20220713_7.csv\nSaving file: train_data_20220713_8.csv\nSaving file: train_data_20220713_9.csv\nSaving file: train_data_20220713_10.csv\nSaving file: train_data_20220713_11.csv\nGetting data for: 20220714\nSaving file: train_data_20220714_12.csv\nSaving file: train_data_20220714_13.csv\nSaving file: train_data_20220714_14.csv\nSaving file: train_data_20220714_15.csv\nSaving file: train_data_20220714_16.csv\nSaving file: train_data_20220714_17.csv\nSaving file: train_data_20220714_18.csv\nSaving file: train_data_20220714_19.csv\nSaving file: train_data_20220714_20.csv\nSaving file: train_data_20220714_21.csv\nSaving file: train_data_20220714_22.csv\nSaving file: train_data_20220714_23.csv\nSaving file: train_data_20220714_0.csv\nSaving file: train_data_20220714_1.csv\nSaving file: train_data_20220714_2.csv\nSaving file: train_data_20220714_3.csv\nSaving file: train_data_20220714_4.csv\nSaving file: train_data_20220714_5.csv\nSaving file: train_data_20220714_6.csv\nSaving file: train_data_20220714_7.csv\nSaving file: train_data_20220714_8.csv\nSaving file: train_data_20220714_9.csv\nSaving file: train_data_20220714_10.csv\nSaving file: train_data_20220714_11.csv\nGetting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220715_0.csv\nSaving file: train_data_20220715_1.csv\nSaving file: train_data_20220715_2.csv\nSaving file: train_data_20220715_3.csv\nSaving file: train_data_20220715_4.csv\nSaving file: train_data_20220715_5.csv\nSaving file: train_data_20220715_6.csv\nSaving file: train_data_20220715_7.csv\nSaving file: train_data_20220715_8.csv\nSaving file: train_data_20220715_9.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220716_0.csv\nSaving file: train_data_20220716_1.csv\nSaving file: train_data_20220716_2.csv\nSaving file: train_data_20220716_3.csv\nSaving file: train_data_20220716_4.csv\nSaving file: train_data_20220716_5.csv\nSaving file: train_data_20220716_6.csv\nSaving file: train_data_20220716_7.csv\nSaving file: train_data_20220716_8.csv\nSaving file: train_data_20220716_9.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nGetting data for: 20220717\nSaving file: train_data_20220717_12.csv\nSaving file: train_data_20220717_13.csv\nSaving file: train_data_20220717_14.csv\nSaving file: train_data_20220717_15.csv\nSaving file: train_data_20220717_16.csv\nSaving file: train_data_20220717_17.csv\nSaving file: train_data_20220717_18.csv\nSaving file: train_data_20220717_19.csv\nSaving file: train_data_20220717_20.csv\nSaving file: train_data_20220717_21.csv\nSaving file: train_data_20220717_22.csv\nSaving file: train_data_20220717_23.csv\nSaving file: train_data_20220717_0.csv\nSaving file: train_data_20220717_1.csv\nSaving file: train_data_20220717_2.csv\nSaving file: train_data_20220717_3.csv\nSaving file: train_data_20220717_4.csv\nSaving file: train_data_20220717_5.csv\nSaving file: train_data_20220717_6.csv\nSaving file: train_data_20220717_7.csv\nSaving file: train_data_20220717_8.csv\nSaving file: train_data_20220717_9.csv\nSaving file: train_data_20220717_10.csv\nSaving file: train_data_20220717_11.csv\nGetting data for: 20220718\nSaving file: train_data_20220718_12.csv\nSaving file: train_data_20220718_13.csv\nSaving file: train_data_20220718_14.csv\nSaving file: train_data_20220718_15.csv\nSaving file: train_data_20220718_16.csv\nSaving file: train_data_20220718_17.csv\nSaving file: train_data_20220718_18.csv\nSaving file: train_data_20220718_19.csv\nSaving file: train_data_20220718_20.csv\nSaving file: train_data_20220718_21.csv\nSaving file: train_data_20220718_22.csv\nSaving file: train_data_20220718_23.csv\nSaving file: train_data_20220718_0.csv\nSaving file: train_data_20220718_1.csv\nSaving file: train_data_20220718_2.csv\nSaving file: train_data_20220718_3.csv\nSaving file: train_data_20220718_4.csv\nSaving file: train_data_20220718_5.csv\nSaving file: train_data_20220718_6.csv\nSaving file: train_data_20220718_7.csv\nSaving file: train_data_20220718_8.csv\nSaving file: train_data_20220718_9.csv\nSaving file: train_data_20220718_10.csv\nSaving file: train_data_20220718_11.csv\nGetting data for: 20220719\nSaving file: train_data_20220719_12.csv\nSaving file: train_data_20220719_13.csv\nSaving file: train_data_20220719_14.csv\nSaving file: train_data_20220719_15.csv\nSaving file: train_data_20220719_16.csv\nSaving file: train_data_20220719_17.csv\nSaving file: train_data_20220719_18.csv\nSaving file: train_data_20220719_19.csv\nSaving file: train_data_20220719_20.csv\nSaving file: train_data_20220719_21.csv\nSaving file: train_data_20220719_22.csv\nSaving file: train_data_20220719_23.csv\nSaving file: train_data_20220719_0.csv\nSaving file: train_data_20220719_1.csv\nSaving file: train_data_20220719_2.csv\nSaving file: train_data_20220719_3.csv\nSaving file: train_data_20220719_4.csv\nSaving file: train_data_20220719_5.csv\nSaving file: train_data_20220719_6.csv\nSaving file: train_data_20220719_7.csv\nSaving file: train_data_20220719_8.csv\nSaving file: train_data_20220719_9.csv\nSaving file: train_data_20220719_10.csv\nSaving file: train_data_20220719_11.csv\nGetting data for: 20220720\nSaving file: train_data_20220720_12.csv\nSaving file: train_data_20220720_13.csv\nSaving file: train_data_20220720_14.csv\nSaving file: train_data_20220720_15.csv\nSaving file: train_data_20220720_16.csv\nSaving file: train_data_20220720_17.csv\nSaving file: train_data_20220720_18.csv\nSaving file: train_data_20220720_19.csv\nSaving file: train_data_20220720_20.csv\nSaving file: train_data_20220720_21.csv\nSaving file: train_data_20220720_22.csv\nSaving file: train_data_20220720_23.csv\nSaving file: train_data_20220720_0.csv\nSaving file: train_data_20220720_1.csv\nSaving file: train_data_20220720_2.csv\nSaving file: train_data_20220720_3.csv\nSaving file: train_data_20220720_4.csv\nSaving file: train_data_20220720_5.csv\nSaving file: train_data_20220720_6.csv\nSaving file: train_data_20220720_7.csv\nSaving file: train_data_20220720_8.csv\nSaving file: train_data_20220720_9.csv\nSaving file: train_data_20220720_10.csv\nSaving file: train_data_20220720_11.csv\nGetting data for: 20220721\nSaving file: train_data_20220721_12.csv\nSaving file: train_data_20220721_13.csv\nSaving file: train_data_20220721_14.csv\nSaving file: train_data_20220721_15.csv\nSaving file: train_data_20220721_16.csv\nSaving file: train_data_20220721_17.csv\nSaving file: train_data_20220721_18.csv\nSaving file: train_data_20220721_19.csv\nSaving file: train_data_20220721_20.csv\nSaving file: train_data_20220721_21.csv\nSaving file: train_data_20220721_22.csv\nSaving file: train_data_20220721_23.csv\nSaving file: train_data_20220721_0.csv\nSaving file: train_data_20220721_1.csv\nSaving file: train_data_20220721_2.csv\nSaving file: train_data_20220721_3.csv\nSaving file: train_data_20220721_4.csv\nSaving file: train_data_20220721_5.csv\nSaving file: train_data_20220721_6.csv\nSaving file: train_data_20220721_7.csv\nSaving file: train_data_20220721_8.csv\nSaving file: train_data_20220721_9.csv\nSaving file: train_data_20220721_10.csv\nSaving file: train_data_20220721_11.csv\nGetting data for: 20220722\nSaving file: train_data_20220722_12.csv\nSaving file: train_data_20220722_13.csv\nSaving file: train_data_20220722_14.csv\nSaving file: train_data_20220722_15.csv\nSaving file: train_data_20220722_16.csv\nSaving file: train_data_20220722_17.csv\nSaving file: train_data_20220722_18.csv\nSaving file: train_data_20220722_19.csv\nSaving file: train_data_20220722_20.csv\nSaving file: train_data_20220722_21.csv\nSaving file: train_data_20220722_22.csv\nSaving file: train_data_20220722_23.csv\nSaving file: train_data_20220722_0.csv\nSaving file: train_data_20220722_1.csv\nSaving file: train_data_20220722_2.csv\nSaving file: train_data_20220722_3.csv\nSaving file: train_data_20220722_4.csv\nSaving file: train_data_20220722_5.csv\nSaving file: train_data_20220722_6.csv\nSaving file: train_data_20220722_7.csv\nSaving file: train_data_20220722_8.csv\nSaving file: train_data_20220722_9.csv\nSaving file: train_data_20220722_10.csv\nSaving file: train_data_20220722_11.csv\nGetting data for: 20220723\nSaving file: train_data_20220723_12.csv\nSaving file: train_data_20220723_13.csv\nSaving file: train_data_20220723_14.csv\nSaving file: train_data_20220723_15.csv\nSaving file: train_data_20220723_16.csv\nSaving file: train_data_20220723_17.csv\nSaving file: train_data_20220723_18.csv\nSaving file: train_data_20220723_19.csv\nSaving file: train_data_20220723_20.csv\nSaving file: train_data_20220723_21.csv\nSaving file: train_data_20220723_22.csv\nSaving file: train_data_20220723_23.csv\nSaving file: train_data_20220723_0.csv\nSaving file: train_data_20220723_1.csv\nSaving file: train_data_20220723_2.csv\nSaving file: train_data_20220723_3.csv\nSaving file: train_data_20220723_4.csv\nSaving file: train_data_20220723_5.csv\nSaving file: train_data_20220723_6.csv\nSaving file: train_data_20220723_7.csv\nSaving file: train_data_20220723_8.csv\nSaving file: train_data_20220723_9.csv\nSaving file: train_data_20220723_10.csv\nSaving file: train_data_20220723_11.csv\nGetting data for: 20220724\nSaving file: train_data_20220724_12.csv\nSaving file: train_data_20220724_13.csv\nSaving file: train_data_20220724_14.csv\nSaving file: train_data_20220724_15.csv\nSaving file: train_data_20220724_16.csv\nSaving file: train_data_20220724_17.csv\nSaving file: train_data_20220724_18.csv\nSaving file: train_data_20220724_19.csv\nSaving file: train_data_20220724_20.csv\nSaving file: train_data_20220724_21.csv\nSaving file: train_data_20220724_22.csv\nSaving file: train_data_20220724_23.csv\nSaving file: train_data_20220724_0.csv\nSaving file: train_data_20220724_1.csv\nSaving file: train_data_20220724_2.csv\nSaving file: train_data_20220724_3.csv\nSaving file: train_data_20220724_4.csv\nSaving file: train_data_20220724_5.csv\nSaving file: train_data_20220724_6.csv\nSaving file: train_data_20220724_7.csv\nSaving file: train_data_20220724_8.csv\nSaving file: train_data_20220724_9.csv\nSaving file: train_data_20220724_10.csv\nSaving file: train_data_20220724_11.csv\nGetting data for: 20220725\nSaving file: train_data_20220725_12.csv\nSaving file: train_data_20220725_13.csv\nSaving file: train_data_20220725_14.csv\nSaving file: train_data_20220725_15.csv\nSaving file: train_data_20220725_16.csv\nSaving file: train_data_20220725_17.csv\nSaving file: train_data_20220725_18.csv\nSaving file: train_data_20220725_19.csv\nSaving file: train_data_20220725_20.csv\nSaving file: train_data_20220725_21.csv\nSaving file: train_data_20220725_22.csv\nSaving file: train_data_20220725_23.csv\nSaving file: train_data_20220725_0.csv\nSaving file: train_data_20220725_1.csv\nSaving file: train_data_20220725_2.csv\nSaving file: train_data_20220725_3.csv\nSaving file: train_data_20220725_4.csv\nSaving file: train_data_20220725_5.csv\nSaving file: train_data_20220725_6.csv\nSaving file: train_data_20220725_7.csv\nSaving file: train_data_20220725_8.csv\nSaving file: train_data_20220725_9.csv\nSaving file: train_data_20220725_10.csv\nSaving file: train_data_20220725_11.csv\nGetting data for: 20220726\nSaving file: train_data_20220726_12.csv\nSaving file: train_data_20220726_13.csv\nSaving file: train_data_20220726_14.csv\nSaving file: train_data_20220726_15.csv\nSaving file: train_data_20220726_16.csv\nSaving file: train_data_20220726_17.csv\nSaving file: train_data_20220726_18.csv\nSaving file: train_data_20220726_19.csv\nSaving file: train_data_20220726_20.csv\nSaving file: train_data_20220726_21.csv\nSaving file: train_data_20220726_22.csv\nSaving file: train_data_20220726_23.csv\nSaving file: train_data_20220726_0.csv\nSaving file: train_data_20220726_1.csv\nSaving file: train_data_20220726_2.csv\nSaving file: train_data_20220726_3.csv\nSaving file: train_data_20220726_4.csv\nSaving file: train_data_20220726_5.csv\nSaving file: train_data_20220726_6.csv\nSaving file: train_data_20220726_7.csv\nSaving file: train_data_20220726_8.csv\nSaving file: train_data_20220726_9.csv\nSaving file: train_data_20220726_10.csv\nSaving file: train_data_20220726_11.csv\nGetting data for: 20220727\nSaving file: train_data_20220727_12.csv\nSaving file: train_data_20220727_13.csv\nSaving file: train_data_20220727_14.csv\nSaving file: train_data_20220727_15.csv\nSaving file: train_data_20220727_16.csv\nSaving file: train_data_20220727_17.csv\nSaving file: train_data_20220727_18.csv\nSaving file: train_data_20220727_19.csv\nSaving file: train_data_20220727_20.csv\nSaving file: train_data_20220727_21.csv\nSaving file: train_data_20220727_22.csv\nSaving file: train_data_20220727_23.csv\nSaving file: train_data_20220727_0.csv\nSaving file: train_data_20220727_1.csv\nSaving file: train_data_20220727_2.csv\nSaving file: train_data_20220727_3.csv\nSaving file: train_data_20220727_4.csv\nSaving file: train_data_20220727_5.csv\nSaving file: train_data_20220727_6.csv\nSaving file: train_data_20220727_7.csv\nSaving file: train_data_20220727_8.csv\nSaving file: train_data_20220727_9.csv\nSaving file: train_data_20220727_10.csv\nSaving file: train_data_20220727_11.csv\nGetting data for: 20220728\nSaving file: train_data_20220728_12.csv\nSaving file: train_data_20220728_13.csv\nSaving file: train_data_20220728_14.csv\nSaving file: train_data_20220728_15.csv\nSaving file: train_data_20220728_16.csv\nSaving file: train_data_20220728_17.csv\nSaving file: train_data_20220728_18.csv\nSaving file: train_data_20220728_19.csv\nSaving file: train_data_20220728_20.csv\nSaving file: train_data_20220728_21.csv\nSaving file: train_data_20220728_22.csv\nSaving file: train_data_20220728_23.csv\nSaving file: train_data_20220728_0.csv\nSaving file: train_data_20220728_1.csv\nSaving file: train_data_20220728_2.csv\nSaving file: train_data_20220728_3.csv\nSaving file: train_data_20220728_4.csv\nSaving file: train_data_20220728_5.csv\nSaving file: train_data_20220728_6.csv\nSaving file: train_data_20220728_7.csv\nSaving file: train_data_20220728_8.csv\nSaving file: train_data_20220728_9.csv\nSaving file: train_data_20220728_10.csv\nSaving file: train_data_20220728_11.csv\nGetting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220729_0.csv\nSaving file: train_data_20220729_1.csv\nSaving file: train_data_20220729_2.csv\nSaving file: train_data_20220729_3.csv\nSaving file: train_data_20220729_4.csv\nSaving file: train_data_20220729_5.csv\nSaving file: train_data_20220729_6.csv\nSaving file: train_data_20220729_7.csv\nSaving file: train_data_20220729_8.csv\nSaving file: train_data_20220729_9.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220730_0.csv\nSaving file: train_data_20220730_1.csv\nSaving file: train_data_20220730_2.csv\nSaving file: train_data_20220730_3.csv\nSaving file: train_data_20220730_4.csv\nSaving file: train_data_20220730_5.csv\nSaving file: train_data_20220730_6.csv\nSaving file: train_data_20220730_7.csv\nSaving file: train_data_20220730_8.csv\nSaving file: train_data_20220730_9.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nGetting data for: 20220731\nSaving file: train_data_20220731_12.csv\nSaving file: train_data_20220731_13.csv\nSaving file: train_data_20220731_14.csv\nSaving file: train_data_20220731_15.csv\nSaving file: train_data_20220731_16.csv\nSaving file: train_data_20220731_17.csv\nSaving file: train_data_20220731_18.csv\nSaving file: train_data_20220731_19.csv\nSaving file: train_data_20220731_20.csv\nSaving file: train_data_20220731_21.csv\nSaving file: train_data_20220731_22.csv\nSaving file: train_data_20220731_23.csv\nSaving file: train_data_20220731_0.csv\nSaving file: train_data_20220731_1.csv\nSaving file: train_data_20220731_2.csv\nSaving file: train_data_20220731_3.csv\nSaving file: train_data_20220731_4.csv\nSaving file: train_data_20220731_5.csv\nSaving file: train_data_20220731_6.csv\nSaving file: train_data_20220731_7.csv\nSaving file: train_data_20220731_8.csv\nSaving file: train_data_20220731_9.csv\nSaving file: train_data_20220731_10.csv\nSaving file: train_data_20220731_11.csv\nDone!\n",
  "history_begin_time" : 1659574424386,
  "history_end_time" : 1659578345905,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "JfefIeHToxfQ",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 29)   # start date\nedate = date(2022, 7, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in t:\n            \n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(k)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(k)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220729\nSaving file: train_data_20220729_12.csv\nSaving file: train_data_20220729_13.csv\nSaving file: train_data_20220729_14.csv\nSaving file: train_data_20220729_15.csv\nSaving file: train_data_20220729_16.csv\nSaving file: train_data_20220729_17.csv\nSaving file: train_data_20220729_18.csv\nSaving file: train_data_20220729_19.csv\nSaving file: train_data_20220729_20.csv\nSaving file: train_data_20220729_21.csv\nSaving file: train_data_20220729_22.csv\nSaving file: train_data_20220729_23.csv\nSaving file: train_data_20220729_0.csv\nSaving file: train_data_20220729_1.csv\nSaving file: train_data_20220729_2.csv\nSaving file: train_data_20220729_3.csv\nSaving file: train_data_20220729_4.csv\nSaving file: train_data_20220729_5.csv\nSaving file: train_data_20220729_6.csv\nSaving file: train_data_20220729_7.csv\nSaving file: train_data_20220729_8.csv\nSaving file: train_data_20220729_9.csv\nSaving file: train_data_20220729_10.csv\nSaving file: train_data_20220729_11.csv\nGetting data for: 20220730\nSaving file: train_data_20220730_12.csv\nSaving file: train_data_20220730_13.csv\nSaving file: train_data_20220730_14.csv\nSaving file: train_data_20220730_15.csv\nSaving file: train_data_20220730_16.csv\nSaving file: train_data_20220730_17.csv\nSaving file: train_data_20220730_18.csv\nSaving file: train_data_20220730_19.csv\nSaving file: train_data_20220730_20.csv\nSaving file: train_data_20220730_21.csv\nSaving file: train_data_20220730_22.csv\nSaving file: train_data_20220730_23.csv\nSaving file: train_data_20220730_0.csv\nSaving file: train_data_20220730_1.csv\nSaving file: train_data_20220730_2.csv\nSaving file: train_data_20220730_3.csv\nSaving file: train_data_20220730_4.csv\nSaving file: train_data_20220730_5.csv\nSaving file: train_data_20220730_6.csv\nSaving file: train_data_20220730_7.csv\nSaving file: train_data_20220730_8.csv\nSaving file: train_data_20220730_9.csv\nSaving file: train_data_20220730_10.csv\nSaving file: train_data_20220730_11.csv\nDone!\n",
  "history_begin_time" : 1659411499292,
  "history_end_time" : 1660261050311,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "yXxM1zezPa4b",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 7, 15)   # start date\nedate = date(2022, 7, 16)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\n\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\n\n\nfor day in days:\n\tprint(\"Getting data for: \"+day)\n    \n\t# read cmaq results\n\tdf_cmaq = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+day+\"_extracted.nc\")\n    \n\t# read mcip results \n\tdf_mcip = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/METCRO2D_\"+day+\".nc\")\n        \n\t# read emissions results \n\tdf_emis = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/emis_mole_all_\"+day+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n        \n\tfor k in t:\n            \n            \n\t\tdf_hourly = pd.DataFrame()\n            \n\t\t# CMAQ data\n            \n\t\t# O3 variable\n\t\to3=df_cmaq.variables['O3'][:].values[k,0]\n\t\tcmaq_O3=list(np.ravel(o3).transpose().round())  \n            \n\t\t# NO2\n\t\tno2=df_cmaq.variables['NO2'][:].values[k,0]\n\t\tcmaq_NO2=list(np.ravel(no2).transpose().round())\n      \n\t\t# CO\n\t\tco=df_cmaq.variables['CO'][:].values[k,0]\n\t\tcmaq_CO=list(np.ravel(co).transpose().round())\n\n\t\t# PM25_CO\n\t\tpm25=df_cmaq.variables['PM25_OC'][:].values[k,0]\n\t\tcmaq_PM25_CO=list(np.ravel(pm25).transpose().round())\n            \n                              \n                              \n\t\t# EMIS data\n                              \n\t\tco_emis=df_emis.variables['CO'][:].values[k,0]\n\t\tCO_emi=list(np.ravel(co_emis).transpose().round())    \n                \n                              \n                              \n\t\t# MCIP data\n            \n\t\t# CO variable\n\t\tprsfc=df_mcip.variables['PRSFC'][:].values[k,0]\n\t\tPRSFC=list(np.ravel(prsfc).transpose().round())\n            \n\t\t# NO2\n\t\tpbl=df_mcip.variables['PBL'][:].values[k,0]\n\t\tPBL=list(np.ravel(pbl).transpose().round())\n            \n\t\t# TEMP2\n\t\ttemp2=df_mcip.variables['TEMP2'][:].values[k,0]\n\t\tTEMP2=list(np.ravel(temp2).transpose().round())\n            \n\t\t# WSPD10\n\t\twspd10=df_mcip.variables['WSPD10'][:].values[k,0]\n\t\tWSPD10=list(np.ravel(wspd10).transpose().round())\n            \n\t\t# WDIR10\n\t\twdir10=df_mcip.variables['WDIR10'][:].values[k,0]\n\t\tWDIR10=list(np.ravel(wdir10).transpose().round())\n\n\t\t# RGRND\n\t\trgrnd=df_mcip.variables['RGRND'][:].values[k,0]\n\t\tRGRND=list(np.ravel(rgrnd).transpose().round())\n\n\t\t# CFRAC\n\t\tcfrac=df_mcip.variables['CFRAC'][:].values[k,0]\n\t\tCFRAC=list(np.ravel(cfrac).transpose().round())\n\n            \n\t\t## LAT/LON data\n\t\tdf_coords = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\n            \n\t\tlat = df_coords.variables['LAT'][:].values[0,0]\n\t\tlat_flt=np.ravel(lat)\n\t\tLAT=np.tile(lat_flt,1)\n\n\t\tlon = df_coords.variables['LON'][:].values[0,0]\n\t\tlon_flt=np.ravel(lon)\n\t\tLON=np.tile(lon_flt,1)\n            \n\t\tdf_hourly['Latitude'] = LAT\n\t\tdf_hourly['Longitude'] = LON\n\t\tdf_hourly['YYYYMMDDHH'] = day+str(k)\n\t\tdf_hourly['CMAQ12KM_O3(ppb)'] = cmaq_O3\n\t\tdf_hourly['CMAQ12KM_NO2(ppb)'] = cmaq_NO2\n\t\tdf_hourly['CMAQ12KM_CO(ppm)'] = cmaq_CO\n\t\tdf_hourly['CMAQ_OC(ug/m3)'] = cmaq_PM25_CO\n\t\tdf_hourly['CO(moles/s)'] = CO_emi\n\t\tdf_hourly['PRSFC(Pa)'] = PRSFC\n\t\tdf_hourly['PBL(m)'] = PBL\n\t\tdf_hourly['TEMP2(K)'] = TEMP2\n\t\tdf_hourly['WSPD10(m/s)'] = WSPD10\n\t\tdf_hourly['WDIR10(degree)'] = WDIR10\n\t\tdf_hourly['RGRND(W/m2)'] = RGRND\n\t\tdf_hourly['CFRAC'] = CFRAC\n\t\tdf_hourly['month'] = df_hourly['YYYYMMDDHH'].str[4:6]\n\t\tdf_hourly['day'] = df_hourly['YYYYMMDDHH'].str[6:8]\n\t\tdf_hourly['hours'] = df_hourly['YYYYMMDDHH'].str[8:10]\n            \n            \n\t\tprint('Saving file: train_data_'+day+'_'+str(k)+'.csv')\n\t\tdf_hourly.to_csv('/groups/ESS/aalnaim/cmaq/training_input_hourly/train_data_'+day+'_'+str(k)+'.csv',index=False)\n\nprint('Done!')",
  "history_output" : "Getting data for: 20220715\nSaving file: train_data_20220715_12.csv\nSaving file: train_data_20220715_13.csv\nSaving file: train_data_20220715_14.csv\nSaving file: train_data_20220715_15.csv\nSaving file: train_data_20220715_16.csv\nSaving file: train_data_20220715_17.csv\nSaving file: train_data_20220715_18.csv\nSaving file: train_data_20220715_19.csv\nSaving file: train_data_20220715_20.csv\nSaving file: train_data_20220715_21.csv\nSaving file: train_data_20220715_22.csv\nSaving file: train_data_20220715_23.csv\nSaving file: train_data_20220715_0.csv\nSaving file: train_data_20220715_1.csv\nSaving file: train_data_20220715_2.csv\nSaving file: train_data_20220715_3.csv\nSaving file: train_data_20220715_4.csv\nSaving file: train_data_20220715_5.csv\nSaving file: train_data_20220715_6.csv\nSaving file: train_data_20220715_7.csv\nSaving file: train_data_20220715_8.csv\nSaving file: train_data_20220715_9.csv\nSaving file: train_data_20220715_10.csv\nSaving file: train_data_20220715_11.csv\nGetting data for: 20220716\nSaving file: train_data_20220716_12.csv\nSaving file: train_data_20220716_13.csv\nSaving file: train_data_20220716_14.csv\nSaving file: train_data_20220716_15.csv\nSaving file: train_data_20220716_16.csv\nSaving file: train_data_20220716_17.csv\nSaving file: train_data_20220716_18.csv\nSaving file: train_data_20220716_19.csv\nSaving file: train_data_20220716_20.csv\nSaving file: train_data_20220716_21.csv\nSaving file: train_data_20220716_22.csv\nSaving file: train_data_20220716_23.csv\nSaving file: train_data_20220716_0.csv\nSaving file: train_data_20220716_1.csv\nSaving file: train_data_20220716_2.csv\nSaving file: train_data_20220716_3.csv\nSaving file: train_data_20220716_4.csv\nSaving file: train_data_20220716_5.csv\nSaving file: train_data_20220716_6.csv\nSaving file: train_data_20220716_7.csv\nSaving file: train_data_20220716_8.csv\nSaving file: train_data_20220716_9.csv\nSaving file: train_data_20220716_10.csv\nSaving file: train_data_20220716_11.csv\nDone!\n",
  "history_begin_time" : 1658237027488,
  "history_end_time" : 1658939156188,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "l0u8vjxqrxj",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1655072488829,
  "history_end_time" : 1655072804257,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "c23l8kg7y5w",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/c23l8kg7y5w/preparing_cmaq_training_data.py\", line 149, in <module>\n    cmaq_O3=list(np.concatenate(aa).flat) \n  File \"<__array_function__ internals>\", line 5, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1654726148660,
  "history_end_time" : 1654726151123,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "b7pvjzarx0i",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654618099679,
  "history_end_time" : 1654618414533,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "6c2uzn3sqsi",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654616426011,
  "history_end_time" : 1654616599075,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "wtykulvuvt1",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654477003563,
  "history_end_time" : 1654477292680,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "roeaa3",
  "indicator" : "Done"
},{
  "history_id" : "gb9ng7buc0e",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\nTraceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 149, in <module>\n    cmaq_O3=list(np.concatenate(aa).flat) \n  File \"<__array_function__ internals>\", line 6, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1654465993733,
  "history_end_time" : 1654465994802,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "13fdf45bteh",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : 1654465719244,
  "history_end_time" : 1657806879199,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "roeaa3",
  "indicator" : "Stopped"
},{
  "history_id" : "q8vhh6o8akv",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 31)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654455589889,
  "history_end_time" : 1654455933594,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "roeaa3",
  "indicator" : "Failed"
},{
  "history_id" : "qyzk8o1p2fn",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654319452339,
  "history_end_time" : 1654319625187,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "mio4k3c2oqo",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654317575735,
  "history_end_time" : 1654317761223,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "roeaa3",
  "indicator" : "Done"
},{
  "history_id" : "n0znrv9klf8",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : 1654316204187,
  "history_end_time" : 1657806899996,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "76ck9196x08",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1654314407093,
  "history_end_time" : 1654314557067,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "roeaa3",
  "indicator" : "Done"
},{
  "history_id" : "p2wirg795b9",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1653698009492,
  "history_end_time" : 1653698137454,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "lzfzpq71nqc",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1653697901101,
  "history_end_time" : 1653698043928,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "1cqnff2q20h",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\nTraceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 149, in <module>\n    cmaq_O3=list(np.concatenate(aa).flat) \n  File \"<__array_function__ internals>\", line 6, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1652934709501,
  "history_end_time" : 1652934710765,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jCQJLD4C5DVb",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 1, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1652897726174,
  "history_end_time" : 1652897735592,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "MXquK67K1ELa",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"preparing_cmaq_training_data.py\", line 1, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1652897598059,
  "history_end_time" : 1652897607253,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cOfNVhsGtWE8",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/cOfNVhsGtWE8/preparing_cmaq_training_data.py\", line 149, in <module>\n    cmaq_O3=list(np.concatenate(aa).flat) \n  File \"<__array_function__ internals>\", line 5, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1652897564173,
  "history_end_time" : 1652897566349,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "jpe50t7cdvw",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/jpe50t7cdvw/preparing_cmaq_training_data.py\", line 149, in <module>\n    cmaq_O3=list(np.concatenate(aa).flat) \n  File \"<__array_function__ internals>\", line 5, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1652897329275,
  "history_end_time" : 1652897332789,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sw6k8lmj53u",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1652831769607,
  "history_end_time" : 1652831897871,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "nzeqf6dvz0u",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1652830882087,
  "history_end_time" : 1652831027749,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "yrxyehbcoah",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n2811120\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1652054791839,
  "history_end_time" : 1652054919641,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "8ueh935m5yn",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 29)   # start date\nedate = date(2021, 10, 30)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211029\n20211030\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n5622240\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021102912  ...             2.0        317.0    0.0\n1  21.855751 -120.512497  2021102912  ...             2.0        315.0    0.0\n2  21.882309 -120.404144  2021102912  ...             2.0        313.0    0.0\n3  21.908745 -120.295715  2021102912  ...             3.0        311.0    0.0\n4  21.935051 -120.187225  2021102912  ...             5.0        309.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1652047444593,
  "history_end_time" : 1652047689912,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "nn0sld690mh",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\n20211101\n20211102\n20211103\n20211104\n20211105\n20211106\n20211107\n20211108\n20211109\n20211110\n20211111\n20211112\n20211113\n20211114\n20211115\n20211116\n20211117\n20211118\n20211119\n20211120\n20211121\n20211122\n20211123\n20211124\n20211125\n20211126\n20211127\n20211128\n20211129\n20211130\n20211201\n20211202\n20211203\n20211204\n20211205\n20211206\n20211207\n20211208\n20211209\n20211210\n20211211\n20211212\n20211213\n20211214\n20211215\n20211216\n20211217\n20211218\n20211219\n20211220\n20211221\n20211222\n20211223\n20211224\n20211225\n20211226\n20211227\n20211228\n20211229\n20211230\n20211231\n20220101\n179911680\n179911680\n179911680\n179911680\n179911680\n179911680\n179911680\n179911680\n",
  "history_begin_time" : 1652045859633,
  "history_end_time" : 1652786130075,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Failed"
},{
  "history_id" : "acnz50jgs2g",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 12, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n       # PM25_EC\n      oo=df.variables['PM25_EC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      dd.append(o3tp)\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      gg.append(o3tp)\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n            # NO\n      oo=df.variables['WSTAR'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      nn.append(o3tp)\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n            # NO\n      oo=df.variables['RN'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      pp.append(o3tp)\n        \t# NO2\n      oo=df.variables['RC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      qq.append(o3tp)\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\ncmaq_PM25_EC=list(np.concatenate(dd).flat) \nprint(len(cmaq_PM25_EC))\ndel dd\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\nNO2_emi=list(np.concatenate(gg).flat) \nprint(len(NO2_emi))\ndel gg\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\nWSTAR=list(np.concatenate(nn).flat) \ndel nn\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\nRN=list(np.concatenate(pp).flat)\ndel pp\nRC=list(np.concatenate(qq).flat)\ndel qq\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_EC(ug/m3)':cmaq_PM25_EC,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'NO2(moles/s)':NO2_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'WSTAR(m/s)':WSTAR,'RGRND(W/m2)':RGRND,'RN(cm)':RN,'RC(cm)':RC,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211230\n20211231\n20220101\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/acnz50jgs2g/preparing_cmaq_training_data.py\", line 174, in <module>\n    cmaq_O3=list(np.concatenate(aa).flat) \n  File \"<__array_function__ internals>\", line 5, in concatenate\nValueError: need at least one array to concatenate\n",
  "history_begin_time" : 1651361403617,
  "history_end_time" : 1651361405806,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mkomopy5htx",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 10, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211030\n20211031\n20211101\n20211102\n20211103\n20211104\n20211105\n20211106\n20211107\n20211108\n20211109\n20211110\n20211111\n20211112\n20211113\n20211114\n20211115\n20211116\n20211117\n20211118\n20211119\n20211120\n20211121\n20211122\n20211123\n20211124\n20211125\n20211126\n20211127\n20211128\n20211129\n20211130\n20211201\n20211202\n20211203\n20211204\n20211205\n20211206\n20211207\n20211208\n20211209\n20211210\n20211211\n20211212\n20211213\n20211214\n20211215\n20211216\n20211217\n20211218\n20211219\n20211220\n20211221\n20211222\n20211223\n20211224\n20211225\n20211226\n20211227\n20211228\n20211229\n20211230\n20211231\n20220101\n179911680\n179911680\n179911680\n179911680\n179911680\n179911680\n179911680\n179911680\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021103012  ...           348.0        312.0    0.0\n1  21.855751 -120.512497  2021103012  ...           346.0        310.0    0.0\n2  21.882309 -120.404144  2021103012  ...           345.0        308.0    0.0\n3  21.908745 -120.295715  2021103012  ...           344.0        306.0    0.0\n4  21.935051 -120.187225  2021103012  ...           344.0        304.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1650471586390,
  "history_end_time" : 1650479843075,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "mmwwhemloao",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 9, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20210930\n20211001\n20211002\n20211003\n20211004\n20211005\n20211006\n20211007\n20211008\n20211009\n20211010\n20211011\n20211012\n20211013\n20211014\n20211015\n20211016\n20211017\n20211018\n20211019\n20211020\n20211021\n20211022\n20211023\n20211024\n20211025\n20211026\n20211027\n20211028\n20211029\n20211030\n20211031\n20211101\n20211102\n20211103\n20211104\n20211105\n20211106\n20211107\n20211108\n20211109\n20211110\n20211111\n20211112\n20211113\n20211114\n20211115\n20211116\n20211117\n20211118\n20211119\n20211120\n20211121\n20211122\n20211123\n20211124\n20211125\n20211126\n20211127\n20211128\n20211129\n20211130\n20211201\n20211202\n20211203\n20211204\n20211205\n20211206\n20211207\n20211208\n20211209\n20211210\n20211211\n20211212\n20211213\n20211214\n20211215\n20211216\n20211217\n20211218\n20211219\n20211220\n20211221\n20211222\n20211223\n20211224\n20211225\n20211226\n20211227\n20211228\n20211229\n20211230\n20211231\n20220101\n264245280\n264245280\n264245280\n264245280\n264245280\n264245280\n264245280\n264245280\n    Latitude   Longitude  YYYYMMDDHH  ...  WDIR10(degree)  RGRND(W/m2)  CFRAC\n0  21.829086 -120.620789  2021093012  ...            11.0        222.0    0.0\n1  21.855751 -120.512497  2021093012  ...            10.0        198.0    0.0\n2  21.882309 -120.404144  2021093012  ...            10.0        179.0    0.0\n3  21.908745 -120.295715  2021093012  ...            10.0        165.0    0.0\n4  21.935051 -120.187225  2021093012  ...             9.0        158.0    0.0\n\n[5 rows x 15 columns]\n",
  "history_begin_time" : 1650460208496,
  "history_end_time" : 1650472621354,
  "history_notes" : "2021, 9, 30 three months",
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "l7wrcq1tyyd",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 9, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1650388987586,
  "history_end_time" : 1654318084127,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Stopped"
},{
  "history_id" : "7vinhdqu4kn",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : 1650388692856,
  "history_end_time" : 1654318084737,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Stopped"
},{
  "history_id" : "k6wt3hlvdhb",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 9, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1650388332855,
  "history_end_time" : 1654318085485,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Stopped"
},{
  "history_id" : "xud3ppmrj23",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 12, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n       # PM25_EC\n      oo=df.variables['PM25_EC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      dd.append(o3tp)\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      gg.append(o3tp)\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n            # NO\n      oo=df.variables['WSTAR'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      nn.append(o3tp)\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n            # NO\n      oo=df.variables['RN'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      pp.append(o3tp)\n        \t# NO2\n      oo=df.variables['RC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      qq.append(o3tp)\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\ncmaq_PM25_EC=list(np.concatenate(dd).flat) \nprint(len(cmaq_PM25_EC))\ndel dd\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\nNO2_emi=list(np.concatenate(gg).flat) \nprint(len(NO2_emi))\ndel gg\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\nWSTAR=list(np.concatenate(nn).flat) \ndel nn\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\nRN=list(np.concatenate(pp).flat)\ndel pp\nRC=list(np.concatenate(qq).flat)\ndel qq\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_EC(ug/m3)':cmaq_PM25_EC,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'NO2(moles/s)':NO2_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'WSTAR(m/s)':WSTAR,'RGRND(W/m2)':RGRND,'RN(cm)':RN,'RC(cm)':RC,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211230\n20211231\n20220101\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n    Latitude   Longitude  YYYYMMDDHH  ...  RN(cm)  RC(cm)  CFRAC\n0  21.829086 -120.620789  2021123012  ...     0.0     0.0    1.0\n1  21.855751 -120.512497  2021123012  ...     0.0     0.0    1.0\n2  21.882309 -120.404144  2021123012  ...     0.0     0.0    1.0\n3  21.908745 -120.295715  2021123012  ...     0.0     0.0    1.0\n4  21.935051 -120.187225  2021123012  ...     0.0     0.0    1.0\n\n[5 rows x 20 columns]\n",
  "history_begin_time" : 1650251409537,
  "history_end_time" : 1650251961555,
  "history_notes" : "2021, 12, 30 one day",
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "4gazrzxgvsd",
  "history_input" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2021, 12, 30)   # start date\nedate = date(2022, 1, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n       # PM25_EC\n      oo=df.variables['PM25_EC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      dd.append(o3tp)\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      gg.append(o3tp)\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n            # NO\n      oo=df.variables['WSTAR'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      nn.append(o3tp)\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n            # NO\n      oo=df.variables['RN'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      pp.append(o3tp)\n        \t# NO2\n      oo=df.variables['RC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      qq.append(o3tp)\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\ncmaq_PM25_EC=list(np.concatenate(dd).flat) \nprint(len(cmaq_PM25_EC))\ndel dd\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\nNO2_emi=list(np.concatenate(gg).flat) \nprint(len(NO2_emi))\ndel gg\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\nWSTAR=list(np.concatenate(nn).flat) \ndel nn\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\nRN=list(np.concatenate(pp).flat)\ndel pp\nRC=list(np.concatenate(qq).flat)\ndel qq\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_EC(ug/m3)':cmaq_PM25_EC,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'NO2(moles/s)':NO2_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'WSTAR(m/s)':WSTAR,'RGRND(W/m2)':RGRND,'RN(cm)':RN,'RC(cm)':RC,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv(home+'/cmaq/training_data.csv',index=False)\n\n",
  "history_output" : "20211230\n20211231\n20220101\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n8433360\n    Latitude   Longitude  YYYYMMDDHH  ...  RN(cm)  RC(cm)  CFRAC\n0  21.829086 -120.620789  2021123012  ...     0.0     0.0    1.0\n1  21.855751 -120.512497  2021123012  ...     0.0     0.0    1.0\n2  21.882309 -120.404144  2021123012  ...     0.0     0.0    1.0\n3  21.908745 -120.295715  2021123012  ...     0.0     0.0    1.0\n4  21.935051 -120.187225  2021123012  ...     0.0     0.0    1.0\n\n[5 rows x 20 columns]\n",
  "history_begin_time" : 1650213979291,
  "history_end_time" : 1650214557201,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "ptcfwwrq82v",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660295756046,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "tdwh1m6xpwh",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660777306997,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "wyxgac3ynzm",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664422603319,
  "history_notes" : null,
  "history_process" : "6up921",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},]
