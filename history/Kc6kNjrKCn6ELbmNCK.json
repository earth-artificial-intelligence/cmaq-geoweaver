[{
  "history_id" : "u7mhhrxc57d",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/text_to_csv_2021.py",
  "history_output" : "python: can't open file '/home/mislam25/cmaq/text_to_csv_2020s.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1645731069501,
  "history_end_time" : 1645731079363,
  "history_notes" : null,
  "history_process" : "ol8aa4",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "s1ihw35jxzn",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/text_to_csv_2020s.py",
  "history_output" : "python: can't open file '/home/mislam25/cmaq/text_to_csv_2020s.py': [Errno 2] No such file or directory\nrm: cannot remove './geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh': No such file or directory\n",
  "history_begin_time" : 1645731069032,
  "history_end_time" : 1645731079368,
  "history_notes" : null,
  "history_process" : "r41da2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "ob1x9pr5hbl",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/pre_processing.py",
  "history_output" : "running_preprocess\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/pre_processing.py\", line 63, in <module>\n    df1 = pd.read_csv('/home/mislam25/cmaq/2020.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/2020.csv'\n",
  "history_begin_time" : 1645731079513,
  "history_end_time" : 1645731098852,
  "history_notes" : null,
  "history_process" : "ftn2kp",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "ehe60lasp7u",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/exploratory_data_analysis.py",
  "history_output" : "running_preprocess\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/exploratory_data_analysis.py\", line 34, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1645731099454,
  "history_end_time" : 1645731144163,
  "history_notes" : null,
  "history_process" : "wfd3c5",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "n21vz5ewffk",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_xgboost.py",
  "history_output" : "chmod: changing permissions of 'geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh': No such file or directory\nbash: line 18: ./geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh: No such file or directory\nrm: cannot remove './geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh': No such file or directory\n",
  "history_begin_time" : 1645731144743,
  "history_end_time" : 1645731154255,
  "history_notes" : null,
  "history_process" : "j7uo3v",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "mq6u4wykoy6",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_xgboost.py",
  "history_output" : "bash: ./geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh: /bin/bash: bad interpreter: Text file busy\n",
  "history_begin_time" : 1645731155252,
  "history_end_time" : 1645731164280,
  "history_notes" : null,
  "history_process" : "zt10an",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "3qnf73thfb7",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_random_forest.py",
  "history_output" : "bash: ./geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh: /bin/bash: bad interpreter: Text file busy\n",
  "history_begin_time" : 1645731145115,
  "history_end_time" : 1645731154221,
  "history_notes" : null,
  "history_process" : "48iyth",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "jh5g6zccq1z",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_random_forest.py",
  "history_output" : "running prediciton rf\nTraceback (most recent call last):\n  File \"/home/mislam25/cmaq/prediction_random_forest.py\", line 8, in <module>\n    final=pd.read_csv('/home/mislam25/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\nrm: cannot remove './geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh': No such file or directory\n",
  "history_begin_time" : 1645731154235,
  "history_end_time" : 1645731172282,
  "history_notes" : null,
  "history_process" : "bembwt",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "w4bpuwwzfcx",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_autokeras.py",
  "history_output" : "bash: ./geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh: /bin/bash: bad interpreter: Text file busy\nrm: cannot remove './geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh': No such file or directory\n",
  "history_begin_time" : 1645731144569,
  "history_end_time" : 1645731154225,
  "history_notes" : null,
  "history_process" : "l0t844",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "3shns86oryy",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_autokeras.py",
  "history_output" : "/bin/bash: ./geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh: No such file or directory\nrm: cannot remove './geoweaver-VW1J59g80RDCTLpGmXcnP4gqRQ.sh': No such file or directory\n",
  "history_begin_time" : 1645731155235,
  "history_end_time" : 1645731164311,
  "history_notes" : null,
  "history_process" : "zmy3vb",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "a1lir7yus6v",
  "history_input" : "#!/bin/bash\n#write your bash script\nsalloc -p normal  -n 1  --cpus-per-task=12 --mem=15GB -t 0-00:05:00 python cmaq/model_comparison.py",
  "history_output" : "salloc: Pending job allocation 45944\nsalloc: job 45944 queued and waiting for resources\nsalloc: job 45944 has been allocated resources\nsalloc: Granted job allocation 45944\nsalloc: Waiting for resource configuration\nsalloc: Nodes hop046 are ready for job\n[]\nsalloc: Relinquishing job allocation 45944\nsalloc: Job allocation 45944 has been revoked.\n",
  "history_begin_time" : 1645731172400,
  "history_end_time" : 1645731222564,
  "history_notes" : null,
  "history_process" : "z1t6b2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
}]
