[{
  "history_id" : "5b7g2oorv67",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717529408659,
  "history_end_time" : 1717529408659,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tl1hvbef8a3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717486209738,
  "history_end_time" : 1717486209738,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fn8msyqj4f9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717443008546,
  "history_end_time" : 1717443008546,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "svzlqj68uhq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717399806051,
  "history_end_time" : 1717399806051,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ixufxtqdko0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717356608670,
  "history_end_time" : 1717356608670,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vbm922ji481",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717313408064,
  "history_end_time" : 1717313408064,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dz0n1z7yed9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717270208331,
  "history_end_time" : 1717270208331,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1nr6nrf9i8y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1717183808593,
  "history_end_time" : 1717183808593,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d2i9tm65c8a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716622207979,
  "history_end_time" : 1716622207979,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v1yon5fo4kd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716579009793,
  "history_end_time" : 1716579009793,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7qbxllncfkx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716535806796,
  "history_end_time" : 1716535806796,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sdp1cah0ymt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716492607563,
  "history_end_time" : 1716492607563,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eql1zdw69td",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716449407422,
  "history_end_time" : 1716449407422,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a0g1e8xwjud",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716406207385,
  "history_end_time" : 1716406207385,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jsgrrtbibsx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716363008062,
  "history_end_time" : 1716363008062,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i9bhje1fgai",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716319808282,
  "history_end_time" : 1716319808282,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2i3ytb5kk90",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1716276606861,
  "history_end_time" : 1716276606861,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ff5lzstsvb9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715974207910,
  "history_end_time" : 1715974207910,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n6xtnndquah",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715542211537,
  "history_end_time" : 1715542211537,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uy2s6nnztll",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715499007198,
  "history_end_time" : 1715499007198,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sxhu8wwvbf2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715455808476,
  "history_end_time" : 1715455808476,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xjrd6v0il3i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715412607682,
  "history_end_time" : 1715412607682,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lbm6jr29gd1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715369408555,
  "history_end_time" : 1715369408555,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tb926j7326a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715326206306,
  "history_end_time" : 1715326206306,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "feva9p70d1q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715283010463,
  "history_end_time" : 1715283010463,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4b89sk06r39",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715239811069,
  "history_end_time" : 1715239811069,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3c2gp2s1p9a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715196613685,
  "history_end_time" : 1715196613685,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "67k1drst18c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1715023809464,
  "history_end_time" : 1715023809464,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d1j7qircvx3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714980608262,
  "history_end_time" : 1714980608262,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vd8kclv2cje",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714937407878,
  "history_end_time" : 1714937407878,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7px1hc1w0lm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714894206765,
  "history_end_time" : 1714894206765,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4kmhxf4ip8g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714851009462,
  "history_end_time" : 1714851009462,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c1ao9f4zqn4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714807807043,
  "history_end_time" : 1714807807043,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fsgnde2zd16",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714764609046,
  "history_end_time" : 1714764609046,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q4v8btk69i5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714721408370,
  "history_end_time" : 1714721408370,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kdodbamahui",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714678208844,
  "history_end_time" : 1714678208844,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "h4r278dz5ut",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714635008126,
  "history_end_time" : 1714635008126,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u8sskqsp4xg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714591808339,
  "history_end_time" : 1714591808339,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uyv20dh7m3l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714548608976,
  "history_end_time" : 1714548608976,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j4mexcy9075",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714505407698,
  "history_end_time" : 1714505407698,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i7wfd15o50a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714462207473,
  "history_end_time" : 1714462207473,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0fghg1qmlow",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714419007965,
  "history_end_time" : 1714419007965,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pshftvh8yt5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714375805674,
  "history_end_time" : 1714375805674,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pj8cddc61rj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714332608189,
  "history_end_time" : 1714332608189,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "470hjlmjr01",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714289407075,
  "history_end_time" : 1714289407075,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j9zteyp315p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714246207214,
  "history_end_time" : 1714246207214,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "39d3bt97cy3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714203007007,
  "history_end_time" : 1714203007007,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ygv02zrsmdf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714159808154,
  "history_end_time" : 1714159808154,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0xiir293tfo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714116606452,
  "history_end_time" : 1714116606452,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3ew9hms2jn3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714073407221,
  "history_end_time" : 1714073407221,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k98yz7ew4ww",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714030206574,
  "history_end_time" : 1714030206574,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fwg7ym2h5ps",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714028455299,
  "history_end_time" : 1714028455299,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2xwavmq14pv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714022735362,
  "history_end_time" : 1714022735362,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tamv2lpzopf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1714022600815,
  "history_end_time" : 1714022600815,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6lu7gcgkomh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713987010032,
  "history_end_time" : 1713987010032,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "472g02rlwff",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713943807443,
  "history_end_time" : 1713943807443,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jzvw7j7li3o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713936140850,
  "history_end_time" : 1713936140850,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wro5tc0zde7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713935991005,
  "history_end_time" : 1713936031887,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xophn4p0pxq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713931874302,
  "history_end_time" : 1713931874302,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q0ut2hngr6s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713900608236,
  "history_end_time" : 1713900608236,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y0mo2la0rq8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713857406227,
  "history_end_time" : 1713857406227,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "txya2hiavki",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713814207536,
  "history_end_time" : 1713814207536,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cqgeoe9z6s4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713771006357,
  "history_end_time" : 1713771006357,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1n7sxluzq59",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713727807341,
  "history_end_time" : 1713727807341,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yv2hlv6770q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713684607331,
  "history_end_time" : 1713684607331,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rp61h3bxrqn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713641429394,
  "history_end_time" : 1713641429394,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8058iggaeze",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713598206735,
  "history_end_time" : 1713598206735,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zc4z290x8qx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713555010896,
  "history_end_time" : 1713555010896,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g2l0vqbgwq4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713511807484,
  "history_end_time" : 1713511807484,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3i8orh4smjg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713468608270,
  "history_end_time" : 1713468608270,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3unvg6ape80",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713425407655,
  "history_end_time" : 1713425407655,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rp91xk7pur5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713382207851,
  "history_end_time" : 1713382207851,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qn2xq6jfkpq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713339006431,
  "history_end_time" : 1713339006431,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dkmut44fbxj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713295809097,
  "history_end_time" : 1713295809097,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "du9lijnke3d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713252610297,
  "history_end_time" : 1713252610297,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e59ipa72of2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713209408431,
  "history_end_time" : 1713209408431,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aapwxuqvc9r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713166206452,
  "history_end_time" : 1713166206452,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ch9doemczyy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713123007551,
  "history_end_time" : 1713123007551,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qly2riolpud",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713079806601,
  "history_end_time" : 1713079806601,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j3scr17ibx4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1713036607688,
  "history_end_time" : 1713036607688,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aa3p6i3rdqr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712993405664,
  "history_end_time" : 1712993405664,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v9t489vok34",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712950207691,
  "history_end_time" : 1712950207691,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xlajmzig3le",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712907009883,
  "history_end_time" : 1712907009883,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j4cs79ycbjn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712863810119,
  "history_end_time" : 1712863810119,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1kz95ql8ae8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712820608972,
  "history_end_time" : 1712820608972,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qcl9ppkio4x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712777409183,
  "history_end_time" : 1712777409183,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3o98aaajuk2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712734207694,
  "history_end_time" : 1712734207694,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p3hthod9qtj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712691008513,
  "history_end_time" : 1712691008513,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t4qu0z0gjc2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712647806914,
  "history_end_time" : 1712647806914,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ck3qykogvdw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712604608486,
  "history_end_time" : 1712604608486,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r32ssqikc5v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712561408370,
  "history_end_time" : 1712561408370,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jjcrc6f6mrh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712518207798,
  "history_end_time" : 1712518207798,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dp249js62ug",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712475007956,
  "history_end_time" : 1712475007956,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i9qbqvapicq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712431807694,
  "history_end_time" : 1712431807694,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k4t9jsi9768",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712388606396,
  "history_end_time" : 1712388606396,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3k2kokb66gp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712345407391,
  "history_end_time" : 1712345407391,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j7cg6kqpof7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712302209219,
  "history_end_time" : 1712302209219,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4vjnbg1j7o3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712259007333,
  "history_end_time" : 1712259007333,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a3qg4f2p8ww",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712215806401,
  "history_end_time" : 1712215806401,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "audhyjh69f3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712172607313,
  "history_end_time" : 1712172607313,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jgaewgt7r0c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712129406892,
  "history_end_time" : 1712129406892,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uw03oy5fktr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712086208918,
  "history_end_time" : 1712086208918,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r9p38r130j0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1712043006972,
  "history_end_time" : 1712043006972,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nrng9weue5k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711999808377,
  "history_end_time" : 1711999808377,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8663l0mxatw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711956606885,
  "history_end_time" : 1711956606885,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6n3avv92opc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711913410600,
  "history_end_time" : 1711913410600,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "opb9z2083ox",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711870206649,
  "history_end_time" : 1711870206649,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0h2f8q3ip7k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711827009329,
  "history_end_time" : 1711827009329,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zuihivcpctp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711783806871,
  "history_end_time" : 1711783806871,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yhkn1fx7pff",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711740608618,
  "history_end_time" : 1711740608618,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gfq9xhuqi44",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711697407124,
  "history_end_time" : 1711697407124,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t97mi5r16i1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711654207591,
  "history_end_time" : 1711654207591,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tiygo0p31o0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711611008919,
  "history_end_time" : 1711611008919,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vf41gt4y7lp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711567808905,
  "history_end_time" : 1711567808905,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lcfqy8s9mw8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711524609406,
  "history_end_time" : 1711524609406,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jph13ej5w2q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711481408359,
  "history_end_time" : 1711481408359,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hbkgze1avat",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711438207582,
  "history_end_time" : 1711438207582,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sxspx9ojsl3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711395008361,
  "history_end_time" : 1711395008361,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v2x0hd0q0n7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711351806621,
  "history_end_time" : 1711351806621,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6wtzs570vmq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711308608320,
  "history_end_time" : 1711308608320,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jzhveghk0qs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711265407048,
  "history_end_time" : 1711265407048,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ds1dadodezb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711222207856,
  "history_end_time" : 1711222207856,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q433iu1pg0j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711179008159,
  "history_end_time" : 1711179008159,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5xndk4y27jr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711135808237,
  "history_end_time" : 1711135808237,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cn4zjdyidu0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710444608113,
  "history_end_time" : 1710444608113,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z2r20oxko6e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710401409689,
  "history_end_time" : 1710401409689,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dur2kehkhm6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710358210123,
  "history_end_time" : 1710358210123,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4w0x3kt743c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710315007082,
  "history_end_time" : 1710315007082,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zkg67ob9kb8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710271807331,
  "history_end_time" : 1710271807331,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "51uu56qy71w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710228607332,
  "history_end_time" : 1710228607332,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fogjmujvace",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710185407637,
  "history_end_time" : 1710185407637,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l243qfqh45x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710142206624,
  "history_end_time" : 1710142206624,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kbidiefodan",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710099008024,
  "history_end_time" : 1710099008024,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ournizi7r6w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710055809480,
  "history_end_time" : 1710055809480,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lj2wbydf22z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710016207742,
  "history_end_time" : 1710016207742,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wk7sfgkvtf7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709929808622,
  "history_end_time" : 1709929808622,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "h6mpnhsy0eq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709757009352,
  "history_end_time" : 1709757009352,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0wz020rgdid",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709713807919,
  "history_end_time" : 1709713807919,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zgpejbja6da",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709670609418,
  "history_end_time" : 1709670609418,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6kys7llsrfy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709627406867,
  "history_end_time" : 1709627406867,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "upuun1oewvk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709584208331,
  "history_end_time" : 1709584208331,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5ykrocelwa4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709541006563,
  "history_end_time" : 1709541006563,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l1s5kz2syip",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709497808339,
  "history_end_time" : 1709497808339,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wkppz85zvz4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709454606037,
  "history_end_time" : 1709454606037,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "f3sfnphy8l8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709411409050,
  "history_end_time" : 1709411409050,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zwj3jmjoaob",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709325007691,
  "history_end_time" : 1709325007691,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "40s1kqa97eb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709281806766,
  "history_end_time" : 1709281806766,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "f65s08nd2w1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709238608121,
  "history_end_time" : 1709238608121,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "abblxssye9d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709195407498,
  "history_end_time" : 1709195407498,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ypp14h4nlgv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709152208483,
  "history_end_time" : 1709152208483,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "h679x9lfs9e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709109007644,
  "history_end_time" : 1709109007644,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bjs5c25yong",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709065809691,
  "history_end_time" : 1709065809691,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2kpj4tjetnp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709022607813,
  "history_end_time" : 1709022607813,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n81obqyofxl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708979408427,
  "history_end_time" : 1708979408427,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x8kytuz7fhl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708936208981,
  "history_end_time" : 1708936208981,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "b57t7yxqh4n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708893008479,
  "history_end_time" : 1708893008479,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0m47riw2gfs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708849806368,
  "history_end_time" : 1708849806368,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xj6gchvee8h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708806610266,
  "history_end_time" : 1708806610266,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4m0ess0o5lc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708763406653,
  "history_end_time" : 1708763406653,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dh38r2fjvtv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708547410332,
  "history_end_time" : 1708547410332,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qcy63rb6sgu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708504206934,
  "history_end_time" : 1708504206934,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sav00bkedag",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708461009391,
  "history_end_time" : 1708461009391,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vohkdsi8179",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708417807973,
  "history_end_time" : 1708417807973,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xx15pewetnm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708374608917,
  "history_end_time" : 1708374608917,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iptlg2439n0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708331406447,
  "history_end_time" : 1708331406447,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "20iht3whonq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708288208184,
  "history_end_time" : 1708288208184,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "81okl5h7n41",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708245006381,
  "history_end_time" : 1708245006381,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hhm8js3zywg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708201808551,
  "history_end_time" : 1708201808551,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cyp2u939t46",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708158607324,
  "history_end_time" : 1708158607324,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "30o0v5iiiyp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707942608255,
  "history_end_time" : 1707942608255,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l885sjrtomw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707899407027,
  "history_end_time" : 1707899407027,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k6utcnrqaas",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707856208211,
  "history_end_time" : 1707856208211,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wrxpnfwqnzs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707813006278,
  "history_end_time" : 1707813006278,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mhkumyw5ihh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707769807828,
  "history_end_time" : 1707769807828,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "84rx07zyil6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707726605968,
  "history_end_time" : 1707726605968,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ds6dpql1b26",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707683408400,
  "history_end_time" : 1707683408400,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0r4thsid7at",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707640205971,
  "history_end_time" : 1707640205971,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wf1pb02iuo3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707597007790,
  "history_end_time" : 1707597007790,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "angii1ez75y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707553807242,
  "history_end_time" : 1707553807242,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "or1pob1skpz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707510608466,
  "history_end_time" : 1707510608466,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l37xocstek2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707467409801,
  "history_end_time" : 1707467409801,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "icm3q2pavtq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707424207991,
  "history_end_time" : 1707424207991,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rv0qsu8vtfl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707381006706,
  "history_end_time" : 1707381006706,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dwwzgc7tuad",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707337808241,
  "history_end_time" : 1707337808241,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1imzddotx9j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707294606168,
  "history_end_time" : 1707294606168,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nylpv9s9xwk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707251410945,
  "history_end_time" : 1707251410945,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eyz003lrsxl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707208206124,
  "history_end_time" : 1707208206124,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gitos69l6ag",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707165008108,
  "history_end_time" : 1707165008108,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8l088x0fnu6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707121806261,
  "history_end_time" : 1707121806261,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iwbgr3qryuh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707078609256,
  "history_end_time" : 1707078609256,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "izbz4oh1bjo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707035406881,
  "history_end_time" : 1707035406881,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hsvcdu4fuza",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706992207988,
  "history_end_time" : 1706992207988,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r805ro5m337",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706949005661,
  "history_end_time" : 1706949005661,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "26ggu4w70pj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706905812415,
  "history_end_time" : 1706905812415,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qjci581517m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706862609614,
  "history_end_time" : 1706862609614,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kwpjkojw0l5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706819411167,
  "history_end_time" : 1706819411167,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "27aieue6k90",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706776208160,
  "history_end_time" : 1706776208160,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bydyatrr3b6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706733009993,
  "history_end_time" : 1706733009993,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gyfu11p24zz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706689806312,
  "history_end_time" : 1706689806312,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1bv5fgvzyg3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706646607601,
  "history_end_time" : 1706646607601,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6di84h9cusk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706603406501,
  "history_end_time" : 1706603406501,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m1wr7p8utuc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706560210763,
  "history_end_time" : 1706560210763,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vcvq33uxs6x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706517005425,
  "history_end_time" : 1706517005425,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lppqnjdv1va",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706473807679,
  "history_end_time" : 1706473807679,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "16b6hf8gokf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706430606381,
  "history_end_time" : 1706430606381,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oa8fyane24u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706387407985,
  "history_end_time" : 1706387407985,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dtds5r3wt5w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706344206455,
  "history_end_time" : 1706344206455,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7y7easw3rea",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706301007163,
  "history_end_time" : 1706301007163,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7wxes59xeyz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706257809070,
  "history_end_time" : 1706257809070,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1hmamriekdf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706214609444,
  "history_end_time" : 1706214609444,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hxiha2ncjw2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706128210710,
  "history_end_time" : 1706128210710,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ffvwbabpq3p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706085006110,
  "history_end_time" : 1706085006110,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "acvq1zjwgkp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706041809885,
  "history_end_time" : 1706041809885,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pkzd0m5m83j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705998606290,
  "history_end_time" : 1705998606290,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1eyvsrv25jy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705955410925,
  "history_end_time" : 1705955410925,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jjk8abarueo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705912206021,
  "history_end_time" : 1705912206021,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "coid0fxwwdx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705869008384,
  "history_end_time" : 1705869008384,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wjie3huj0ul",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705825806336,
  "history_end_time" : 1705825806336,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ejb1o14nw4n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705782608427,
  "history_end_time" : 1705782608427,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sb2mo868o6l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705696210020,
  "history_end_time" : 1705696210020,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "o1pyprn7qtc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705609807308,
  "history_end_time" : 1705609807308,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dhl4r75dskt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705523407215,
  "history_end_time" : 1705523407215,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pl11ssyhbdx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705437007753,
  "history_end_time" : 1705437007753,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bb2johu50bw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705350607345,
  "history_end_time" : 1705350607345,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dogrj3wgw7r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705264207587,
  "history_end_time" : 1705264207587,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ghudxsu4b3u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705177807167,
  "history_end_time" : 1705177807167,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oom8opo06be",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705091408103,
  "history_end_time" : 1705091408103,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3pobdgog2qd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705005019186,
  "history_end_time" : 1705005019186,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ys82x4iq6is",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704918607506,
  "history_end_time" : 1704918607506,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nhofjlbtas6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704832207048,
  "history_end_time" : 1704832207048,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "abx7oyc7hxq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704789008101,
  "history_end_time" : 1704789008101,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wqy33iqbwft",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704745807613,
  "history_end_time" : 1704745807613,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wcpusutepm8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704702607500,
  "history_end_time" : 1704702607500,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bhhrhjfj3jp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704659407782,
  "history_end_time" : 1704659407782,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bluzefk3o8k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704616210550,
  "history_end_time" : 1704616210550,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ovzrwrbfhug",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704573009484,
  "history_end_time" : 1704573009484,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6vbns84n7gf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704529810744,
  "history_end_time" : 1704529810744,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pse2pn6dsl8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704486609244,
  "history_end_time" : 1704486609244,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jad80x32ng5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704443409878,
  "history_end_time" : 1704443409878,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jvnn91uqaqr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704400209970,
  "history_end_time" : 1704400209970,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tbs9t8lawmj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704357009232,
  "history_end_time" : 1704357009232,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dg2ycdkylmb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704313809188,
  "history_end_time" : 1704313809188,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ygodigs6gok",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704270607910,
  "history_end_time" : 1704270607910,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ltbw7i3bcf8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704227409913,
  "history_end_time" : 1704227409913,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vgeo4rvcr66",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704184207753,
  "history_end_time" : 1704184207753,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "txv5ecbgf7b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704141008618,
  "history_end_time" : 1704141008618,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kl7wisga4sw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704097808374,
  "history_end_time" : 1704097808374,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uueucgqr4eh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704054608309,
  "history_end_time" : 1704054608309,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "s6vvpe9xkvv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704011407992,
  "history_end_time" : 1704011407992,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jp3tou51iij",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703968208369,
  "history_end_time" : 1703968208369,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "owkfaij106p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703925007561,
  "history_end_time" : 1703925007561,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qon5fxth2px",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703881808123,
  "history_end_time" : 1703881808123,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qer73y7s1hx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703838608025,
  "history_end_time" : 1703838608025,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6msuyxwqyx6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703795409108,
  "history_end_time" : 1703795409108,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9v3q4k3shma",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703752210373,
  "history_end_time" : 1703752210373,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zjderkdszrh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703709006987,
  "history_end_time" : 1703709006987,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cs6sq26grze",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703665811059,
  "history_end_time" : 1703665811059,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ptejma7ivu2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703622607178,
  "history_end_time" : 1703622607178,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n5h12e99hyz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703579408153,
  "history_end_time" : 1703579408153,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cpl7lk2ll0e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703536207398,
  "history_end_time" : 1703536207398,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1rzhjn7jahf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703493007016,
  "history_end_time" : 1703493007016,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "98oelvqt3qj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703449807607,
  "history_end_time" : 1703449807607,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bc9daqaeg1i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703406608486,
  "history_end_time" : 1703406608486,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "muy97a63359",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703363407143,
  "history_end_time" : 1703363407143,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bi3g1pylrkb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703320207577,
  "history_end_time" : 1703320207577,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6kll4myqijv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703277009902,
  "history_end_time" : 1703277009902,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ve4jjb72qlo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703233809148,
  "history_end_time" : 1703233809148,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3r6r54fzzk7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703190609034,
  "history_end_time" : 1703190609034,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qwawhjrrbr1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703147408252,
  "history_end_time" : 1703147408252,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "auyv9j5zcwg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703104209694,
  "history_end_time" : 1703104209694,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "h9vnufivmat",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703061008526,
  "history_end_time" : 1703061008526,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e65zo85j52y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703017807140,
  "history_end_time" : 1703017807140,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zrqfkt5esin",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702979081183,
  "history_end_time" : 1702979081183,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "syav55fjxtj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702931407106,
  "history_end_time" : 1702931407106,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6ymxaqgxuzv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702888209119,
  "history_end_time" : 1702888209119,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fslyjn032oo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702845007119,
  "history_end_time" : 1702845007119,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bg8ts7ycgrg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702801808760,
  "history_end_time" : 1702801808760,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t8sm43upsj3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702758607185,
  "history_end_time" : 1702758607185,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0110zscx3k6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702715409391,
  "history_end_time" : 1702715409391,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "27toxi85duz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702672207464,
  "history_end_time" : 1702672207464,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "79fbpw5019g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702629009443,
  "history_end_time" : 1702629009443,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9haq4xuvz4i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702585807525,
  "history_end_time" : 1702585807525,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bns2g1459up",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702542608379,
  "history_end_time" : 1702542608379,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5wtn64edzpo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702499407638,
  "history_end_time" : 1702499407638,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9ha5na92qyc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702456207423,
  "history_end_time" : 1702456207423,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yhj48bedrwy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702413007635,
  "history_end_time" : 1702413007635,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4vwd6lkaxyg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702369807695,
  "history_end_time" : 1702369807695,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pmuj3bvd3q8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702326607591,
  "history_end_time" : 1702326607591,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "roeh25w7bi7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702283406767,
  "history_end_time" : 1702283406767,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ptnyb7na3yk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702240207794,
  "history_end_time" : 1702240207794,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nj0xom73xdw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702197007003,
  "history_end_time" : 1702197007003,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3fjf7faycih",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702153808115,
  "history_end_time" : 1702153808115,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7hcgqwcvvsy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702110607781,
  "history_end_time" : 1702110607781,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3bhf2mioakw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702067407736,
  "history_end_time" : 1702067407736,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wq2lhiy34kd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702024210550,
  "history_end_time" : 1702024210550,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fotnqs0oh0j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701981007274,
  "history_end_time" : 1701981007274,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uihv7my3y47",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701937807861,
  "history_end_time" : 1701937807861,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "upajuqn2caq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701894607517,
  "history_end_time" : 1701894607517,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y5m9lve3bnz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701851407922,
  "history_end_time" : 1701851407922,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vwj5ink90sw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701808207548,
  "history_end_time" : 1701808207548,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sohj84zvkbq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701765009224,
  "history_end_time" : 1701765009224,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u7a3g124pm2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701721807394,
  "history_end_time" : 1701721807394,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r8v3mx7c23z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701678608748,
  "history_end_time" : 1701678608748,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4uepf0wmnul",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701635407842,
  "history_end_time" : 1701635407842,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iiaq0gg6d8i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701592207834,
  "history_end_time" : 1701592207834,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wlqhefnp8ph",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701549007259,
  "history_end_time" : 1701549007259,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vp6la96hpsv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701505808098,
  "history_end_time" : 1701505808098,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0fy1t8lf0xp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701462607363,
  "history_end_time" : 1701462607363,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zj2tffvkpza",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701419408836,
  "history_end_time" : 1701419408836,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aohznnan5oj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701376207484,
  "history_end_time" : 1701376207484,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8ji1j6fpg8k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701333008692,
  "history_end_time" : 1701333008692,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2dlwvpyce59",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701289811477,
  "history_end_time" : 1701289811477,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lf5ygi9asrb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701246609430,
  "history_end_time" : 1701246609430,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2klgqwqsmnw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701203409442,
  "history_end_time" : 1701203409442,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tb03gacf1id",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701160206769,
  "history_end_time" : 1701160206769,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x9t09ksvfty",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701117008346,
  "history_end_time" : 1701117008346,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5v9inzuehjk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701073806785,
  "history_end_time" : 1701073806785,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gwq8hdhxdzh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701030608254,
  "history_end_time" : 1701030608254,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8q5cubq4tyd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700987406984,
  "history_end_time" : 1700987406984,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1sdvxo7ed8d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700944207441,
  "history_end_time" : 1700944207441,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7efp682k72o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700901008275,
  "history_end_time" : 1700901008275,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yl7j203ui6u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700857807655,
  "history_end_time" : 1700857807655,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r9nsimdmh47",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700814606665,
  "history_end_time" : 1700814606665,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "93rl3hipclw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700771407469,
  "history_end_time" : 1700771407469,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "psq5mylgx4b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700728206644,
  "history_end_time" : 1700728206644,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xv5hfwqv2sv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700685008378,
  "history_end_time" : 1700685008378,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ikyv7phkv6j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700641808316,
  "history_end_time" : 1700641808316,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9oap1a86mnn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700598608191,
  "history_end_time" : 1700598608191,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8nqg9h86x0x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700555406991,
  "history_end_time" : 1700555406991,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lo3ck7v6dv6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700512208056,
  "history_end_time" : 1700512208056,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zlyzmv28amb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700469009623,
  "history_end_time" : 1700469009623,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wdvhf0gre5q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700425808053,
  "history_end_time" : 1700425808053,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6mykcxbso8a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700382608805,
  "history_end_time" : 1700382608805,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bprga5fkkzx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700339407344,
  "history_end_time" : 1700339407344,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c2ig3oos1cf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700296207992,
  "history_end_time" : 1700296207992,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "39t5cwhx7xv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700253007571,
  "history_end_time" : 1700253007571,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fe26fcsbvz0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700209808994,
  "history_end_time" : 1700209808994,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8zvuth0zzca",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700166608819,
  "history_end_time" : 1700166608819,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w2emwo9ghg5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700123408403,
  "history_end_time" : 1700123408403,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uty7yftnqrf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700080209769,
  "history_end_time" : 1700080209769,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fvrpzb7hg04",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700037009116,
  "history_end_time" : 1700037009116,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9vlr22v64ti",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699993810614,
  "history_end_time" : 1699993810614,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w856by6096u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699950608023,
  "history_end_time" : 1699950608023,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3s93hazk2a4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699907408871,
  "history_end_time" : 1699907408871,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zf0sgem4loz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699864209283,
  "history_end_time" : 1699864209283,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "huimngud9tk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699821008022,
  "history_end_time" : 1699821008022,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ugwpvah6km6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699777807322,
  "history_end_time" : 1699777807322,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "et5nkhls027",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699734607630,
  "history_end_time" : 1699734607630,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "paqabpw6vm3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699691409264,
  "history_end_time" : 1699691409264,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fwqympd76ke",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699648207565,
  "history_end_time" : 1699648207565,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ybnxab4925g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699605009356,
  "history_end_time" : 1699605009356,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1x1ps5hppus",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699561808868,
  "history_end_time" : 1699561808868,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5rha3gnxqni",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699518609237,
  "history_end_time" : 1699518609237,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "52ysh7a60bb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699475408427,
  "history_end_time" : 1699475408427,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4nzdsm0df52",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699432210802,
  "history_end_time" : 1699432210802,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0j7j4wfta1w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699389007524,
  "history_end_time" : 1699389007524,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r554ujyz2bh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699345811005,
  "history_end_time" : 1699345811005,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1zim15rb4z3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699302609226,
  "history_end_time" : 1699302609226,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mn313h61s60",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699259411763,
  "history_end_time" : 1699259411763,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xof31p272y2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699216207796,
  "history_end_time" : 1699216207796,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bpfverflxq7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699173009609,
  "history_end_time" : 1699173009609,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kozgbplrmd7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699126208448,
  "history_end_time" : 1699126208448,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r80ssgj142s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699083013869,
  "history_end_time" : 1699083013869,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7y11n8cc1cx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699039819093,
  "history_end_time" : 1699039819093,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4z71syi9dd1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698996610824,
  "history_end_time" : 1698996610824,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5unt22k3t3a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698953411339,
  "history_end_time" : 1698953411339,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rwf4mipnhqb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698910210280,
  "history_end_time" : 1698910210280,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9rao81gejrq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698867008169,
  "history_end_time" : 1698867008169,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "laolgpli7wh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698823810596,
  "history_end_time" : 1698823810596,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ctvilc9fq6d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698780610203,
  "history_end_time" : 1698780610203,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gg8uk26rpf5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698737409601,
  "history_end_time" : 1698737409601,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xiairalybeg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698694208236,
  "history_end_time" : 1698694208236,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wheb3ub2i2a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698651011539,
  "history_end_time" : 1698651011539,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v04gl09ydun",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698607808291,
  "history_end_time" : 1698607808291,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kjqka974ekr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698564609899,
  "history_end_time" : 1698564609899,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jftdxxzoq0z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698521407849,
  "history_end_time" : 1698521407849,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "o0r0hk2hacj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698478210368,
  "history_end_time" : 1698478210368,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hivraicjtcv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698435009290,
  "history_end_time" : 1698435009290,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a9g6ttzg9wp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698391810063,
  "history_end_time" : 1698391810063,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2hbd148v0qi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698348609299,
  "history_end_time" : 1698348609299,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2zhzuxzzb0d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698305409302,
  "history_end_time" : 1698305409302,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vaqnlrpcmge",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698262207648,
  "history_end_time" : 1698262207648,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rsva7g0uckc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698219009893,
  "history_end_time" : 1698219009893,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6a9g2uvjamp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698175807238,
  "history_end_time" : 1698175807238,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bepm7sxbd49",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698132608536,
  "history_end_time" : 1698132608536,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "czws0gq5c1i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698089408025,
  "history_end_time" : 1698089408025,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "szd9zqvwywq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698046209076,
  "history_end_time" : 1698046209076,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l5e1ixa3ol9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698003007014,
  "history_end_time" : 1698003007014,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "38y9ymg986r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697959807865,
  "history_end_time" : 1697959807865,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dfslvubkayz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697916609499,
  "history_end_time" : 1697916609499,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qitm51ao96f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697873409310,
  "history_end_time" : 1697873409310,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g0ix2c7qdjx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697830209080,
  "history_end_time" : 1697830209080,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jx14hanut8e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697787009216,
  "history_end_time" : 1697787009216,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0272n6zxm1l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697743809186,
  "history_end_time" : 1697743809186,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j5yq6g0jgji",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697700609062,
  "history_end_time" : 1697700609062,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dlfltka80og",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697657408350,
  "history_end_time" : 1697657408350,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eu4h7w3bq9d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697614208093,
  "history_end_time" : 1697614208093,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tfim6qhr8jo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697571009169,
  "history_end_time" : 1697571009169,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rh5vbhj8bx3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697527808175,
  "history_end_time" : 1697527808175,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4kxgloy5udr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697484609478,
  "history_end_time" : 1697484609478,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cy70x8r3qxd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697441408120,
  "history_end_time" : 1697441408120,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xg4y9oma670",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697398207304,
  "history_end_time" : 1697398207304,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3x6id68dh22",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697355008589,
  "history_end_time" : 1697355008589,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2lv7fpvjp3o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697311808557,
  "history_end_time" : 1697311808557,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r12huixacr7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697268609139,
  "history_end_time" : 1697268609139,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gim95g4n69k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697225409304,
  "history_end_time" : 1697225409304,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "afpb9y2y4f2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697182211122,
  "history_end_time" : 1697182211122,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gbainijdokp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697139010094,
  "history_end_time" : 1697139010094,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1ml6x6e42bx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697095812329,
  "history_end_time" : 1697095812329,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3rl1yjqq7ns",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697052607520,
  "history_end_time" : 1697052607520,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wfw9pkdkezk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697009411596,
  "history_end_time" : 1697009411596,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2qnvw1qbwun",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696966210493,
  "history_end_time" : 1696966210493,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iwt5niyui9u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696923007928,
  "history_end_time" : 1696923007928,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nojky7w7sze",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696879807983,
  "history_end_time" : 1696879807983,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bs0uwngmtiz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696836608328,
  "history_end_time" : 1696836608328,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wl9cuphwy9l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696793406857,
  "history_end_time" : 1696793406857,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ggn7xjolkbz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696750208938,
  "history_end_time" : 1696750208938,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gxrnwtvcjb1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696707007694,
  "history_end_time" : 1696707007694,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xinphzh8xeu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696663808989,
  "history_end_time" : 1696663808989,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z7mmgqd3yag",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696620607970,
  "history_end_time" : 1696620607970,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4uj5o1n4sif",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696577414502,
  "history_end_time" : 1696577414502,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z4d39novin3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696534208069,
  "history_end_time" : 1696534208069,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a5fx1xns0i1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696491011222,
  "history_end_time" : 1696491011222,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "snux0sosf3l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696447809738,
  "history_end_time" : 1696447809738,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zg2afz60i2a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696404610324,
  "history_end_time" : 1696404610324,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "95oq9umms0s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696361411424,
  "history_end_time" : 1696361411424,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6pcq41v41yy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696318210450,
  "history_end_time" : 1696318210450,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ene47s866yj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696275008000,
  "history_end_time" : 1696275008000,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3c5kixu29ef",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696231809249,
  "history_end_time" : 1696231809249,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kjiyb0li2ub",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696188606945,
  "history_end_time" : 1696188606945,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sbauf6ckk5l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696145409977,
  "history_end_time" : 1696145409977,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qvsm8k0o5or",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696102210101,
  "history_end_time" : 1696102210101,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tq1lobrc7es",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696059009924,
  "history_end_time" : 1696059009924,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "59k2ndelo1l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696015809576,
  "history_end_time" : 1696015809576,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ngjvgir1m8r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695972608031,
  "history_end_time" : 1695972608031,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5oyeo8n6gk9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695929409617,
  "history_end_time" : 1695929409617,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xqzwumb3dpu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695886209829,
  "history_end_time" : 1695886209829,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4uyn711d8yg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695843007030,
  "history_end_time" : 1695843007030,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vwvozc2buk9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695799808320,
  "history_end_time" : 1695799808320,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "la0fmsyjwpw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695756608195,
  "history_end_time" : 1695756608195,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6ox4oeudpnr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695713409359,
  "history_end_time" : 1695713409359,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "01qzyelp0ke",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695670210617,
  "history_end_time" : 1695670210617,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "89egbh08arw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695627011085,
  "history_end_time" : 1695627011085,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x95acvg7g29",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695583808242,
  "history_end_time" : 1695583808242,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t0g4skmhoch",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695540607973,
  "history_end_time" : 1695540607973,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "11p093gya0p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695497410233,
  "history_end_time" : 1695497410233,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0g9edd5rhy8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695454207205,
  "history_end_time" : 1695454207205,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cd5fk9uvck7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695411011144,
  "history_end_time" : 1695411011144,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ndx027pyfl7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695367807717,
  "history_end_time" : 1695367807717,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "te0sq9wtds0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695324608491,
  "history_end_time" : 1695324608491,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "b24xland8vo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695281407544,
  "history_end_time" : 1695281407544,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "h5vlxsdnyir",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695238210304,
  "history_end_time" : 1695238210304,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gjvnoa5kwsj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695195007114,
  "history_end_time" : 1695195007114,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i7ccd1imthn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695151809949,
  "history_end_time" : 1695151809949,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9miwm3in4sq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695108606571,
  "history_end_time" : 1695108606571,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p8e1utxdwfi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695065408241,
  "history_end_time" : 1695065408241,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g68ozl39x17",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695022205971,
  "history_end_time" : 1695022205971,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q44ojdi3692",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694979012226,
  "history_end_time" : 1694979012226,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fyz6egh69gp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694935806562,
  "history_end_time" : 1694935806562,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "acjdw9c3vmf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694892610117,
  "history_end_time" : 1694892610117,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ts8ktbfuwtq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694849411520,
  "history_end_time" : 1694849411520,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wk3aj4c834p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694806210099,
  "history_end_time" : 1694806210099,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ff641tq2mar",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694763012545,
  "history_end_time" : 1694763012545,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rrr202vm7c4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694719811530,
  "history_end_time" : 1694719811530,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2kngxq8thif",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694676612978,
  "history_end_time" : 1694676612978,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9pa4zamwgwv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694633414022,
  "history_end_time" : 1694633414022,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "43x0csbcm14",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694590211245,
  "history_end_time" : 1694590211245,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "edxgar0pye3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694547015204,
  "history_end_time" : 1694547015204,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kt4svjcrza4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694503812610,
  "history_end_time" : 1694503812610,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p2v7p1fnm2m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694460611855,
  "history_end_time" : 1694460611855,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mfw47r9mhst",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694417412877,
  "history_end_time" : 1694417412877,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0tknhmgkd5b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694374210755,
  "history_end_time" : 1694374210755,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xeeixhkenvb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694331014795,
  "history_end_time" : 1694331014795,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iyyhvy2ij5o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694287810922,
  "history_end_time" : 1694287810922,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "amh5fsk5un2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694244611873,
  "history_end_time" : 1694244611873,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3khjyyf6fnd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694201411728,
  "history_end_time" : 1694201411728,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p6wna86774r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694158210634,
  "history_end_time" : 1694158210634,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "42m21hmt2um",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694115013658,
  "history_end_time" : 1694115013658,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x9pb8ptuiso",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694071808824,
  "history_end_time" : 1694071808824,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ckigkk8ulnc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694028612118,
  "history_end_time" : 1694028612118,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j2cxch13942",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693985409219,
  "history_end_time" : 1693985409219,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w7prq0lkyak",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693942213177,
  "history_end_time" : 1693942213177,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lpko1hzi1hh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693899009074,
  "history_end_time" : 1693899009074,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x1f5wnmsymp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693855810201,
  "history_end_time" : 1693855810201,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5bwqt95xbc6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693812610524,
  "history_end_time" : 1693812610524,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0ew7q0s7qan",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693769410972,
  "history_end_time" : 1693769410972,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tyass0h9x9o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693726211110,
  "history_end_time" : 1693726211110,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a0sfj4j5sx2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693683010549,
  "history_end_time" : 1693683010549,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r2jpikmc48d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693639809230,
  "history_end_time" : 1693639809230,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v53uo2k3nab",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693596612067,
  "history_end_time" : 1693596612067,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v9jz9f0v3t8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693553408480,
  "history_end_time" : 1693553408480,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fsk559fytml",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693510209258,
  "history_end_time" : 1693510209258,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z8ewm51tbdw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693467008239,
  "history_end_time" : 1693467008239,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vm82rb9962a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693423809033,
  "history_end_time" : 1693423809033,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "98gokodzmcw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693380607928,
  "history_end_time" : 1693380607928,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5uo0l3t6kvh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693337410057,
  "history_end_time" : 1693337410057,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vvv7rs3btc6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693294207470,
  "history_end_time" : 1693294207470,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "218mahn2qao",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693251008561,
  "history_end_time" : 1693251008561,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "28v8wma2lnj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1693207807334,
  "history_end_time" : 1693207807334,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ZElFAl32wqki",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nprint(f\"testing_path: {testing_path}\")\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\nprint(f\"removed all file {testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "",
  "history_begin_time" : 1693201171015,
  "history_end_time" : 1693201249248,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "J8twZ57GTTh6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "",
  "history_begin_time" : 1693200273222,
  "history_end_time" : 1693200434134,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "go7z21ivgsz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "",
  "history_begin_time" : 1693166189760,
  "history_end_time" : 1693166284304,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0qj38jkzsus",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "",
  "history_begin_time" : 1693122760573,
  "history_end_time" : 1693122850735,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9o01akyud3v",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "",
  "history_begin_time" : 1693079828311,
  "history_end_time" : 1693079912419,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4xzku3vlakk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "",
  "history_begin_time" : 1693036464634,
  "history_end_time" : 1693036561954,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ist71jybfv7",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692819007513,
  "history_end_time" : 1692819007572,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xavh62detvp",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692775810039,
  "history_end_time" : 1692775810112,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "py1x9f52uts",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692732608766,
  "history_end_time" : 1692732608832,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "aq80t45cx0i",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692689409720,
  "history_end_time" : 1692689409787,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3yjuy2jab7i",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692646209058,
  "history_end_time" : 1692646209125,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8x4uscfa7ju",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692603010813,
  "history_end_time" : 1692603010880,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9ca8t0rpe4d",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692559808641,
  "history_end_time" : 1692559808707,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8w6mi6colry",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692516608710,
  "history_end_time" : 1692516608796,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "muj4d9q91xf",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692473410474,
  "history_end_time" : 1692473410528,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "i6lmbm1jv2z",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692430210162,
  "history_end_time" : 1692430210245,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "yfpabw0oh7a",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1692387969548,
  "history_end_time" : 1692387969612,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "tld8hapnwtl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Running",
  "history_begin_time" : 1692344719648,
  "history_end_time" : 1692344719520,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Running"
},{
  "history_id" : "ooin3h8uxco",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692301530935,
  "history_end_time" : 1692301901904,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r1qyt40xx71",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692258047891,
  "history_end_time" : 1692258295797,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nmivoocqtrv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692214916167,
  "history_end_time" : 1692215188408,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u5p4x2vxtg7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692171557059,
  "history_end_time" : 1692171767811,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dkyl5slbcvc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692128400528,
  "history_end_time" : 1692128631858,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "17rwfh721pk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692085044889,
  "history_end_time" : 1692085198429,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "o3i9aek79vc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1692041755643,
  "history_end_time" : 1692041875619,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0x5cqlitb5e",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691998412189,
  "history_end_time" : 1691998481369,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5jj1sg5hzhh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691955239437,
  "history_end_time" : 1691955318311,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fpt1b5w17jq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691912021352,
  "history_end_time" : 1691912090699,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lvcj5vugc67",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691868850436,
  "history_end_time" : 1691868930736,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uzutaq34c5e",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691825616112,
  "history_end_time" : 1691825683558,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2aemvy52qag",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691782359909,
  "history_end_time" : 1691782404032,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bn8vs3xislv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691739219137,
  "history_end_time" : 1691739288782,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "van93cw0ss6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691695820125,
  "history_end_time" : 1691695821962,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "69kd4hrt8ai",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691652735197,
  "history_end_time" : 1691652773227,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7cvoksrxyov",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691609418633,
  "history_end_time" : 1691609420584,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kffusqh9mt2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691566325184,
  "history_end_time" : 1691566359883,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qxxp7imfqzf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691523270140,
  "history_end_time" : 1691523327640,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8zp1f951q6j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691479812348,
  "history_end_time" : 1691479813959,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1hggpd9iuyb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691436618108,
  "history_end_time" : 1691436619604,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "84lcajal2bj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691393514560,
  "history_end_time" : 1691393548883,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1r0u37iqy89",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691350216174,
  "history_end_time" : 1691350218124,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "x1scufjimjf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691307014644,
  "history_end_time" : 1691307016100,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ql50p8yr322",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691263818740,
  "history_end_time" : 1691263820207,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "55gyi6v5tsk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691220712847,
  "history_end_time" : 1691220746646,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q78i9oaah4c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691177416397,
  "history_end_time" : 1691177417849,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pp4x9egiuyu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1691134213709,
  "history_end_time" : 1691134215099,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "apt5amynwk0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691091288674,
  "history_end_time" : 1691091370637,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kb7yscdkuf2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691047962159,
  "history_end_time" : 1691048010137,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0v51sljl0r2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1691004905991,
  "history_end_time" : 1691005008503,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "p8olmotz65b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690961721517,
  "history_end_time" : 1690961824794,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rrhix81pnrh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690918732552,
  "history_end_time" : 1690918880425,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7gvzb70siym",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690875420026,
  "history_end_time" : 1690875550934,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vq4k8y9pdad",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690832057710,
  "history_end_time" : 1690832144982,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t44l6o35xgo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690788816504,
  "history_end_time" : 1690788882921,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cij0n5tuewd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690745657044,
  "history_end_time" : 1690745755022,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yjtrsfozwen",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690702404697,
  "history_end_time" : 1690702471287,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "42mbxdcopei",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690659298203,
  "history_end_time" : 1690659380296,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gpy11o2u1jf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690616137970,
  "history_end_time" : 1690616241183,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yd840411509",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690572875318,
  "history_end_time" : 1690572958446,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ufcuvt941sd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690529710744,
  "history_end_time" : 1690529814052,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "67dcab0fux1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690486461133,
  "history_end_time" : 1690486539869,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sufjutjw3ho",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690443317481,
  "history_end_time" : 1690443421738,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yj74d7ixqd3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690400182282,
  "history_end_time" : 1690400275523,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dsjmse33q13",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690356931638,
  "history_end_time" : 1690357037013,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "v49c7zjh1ku",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690313712801,
  "history_end_time" : 1690313797480,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "w7e61tfpqp9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690270535925,
  "history_end_time" : 1690270639885,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "82z4lbi7rpj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690227264885,
  "history_end_time" : 1690227343525,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xisto2s4ap1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690184122715,
  "history_end_time" : 1690184221505,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "majn4toxdqo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690140855261,
  "history_end_time" : 1690140935240,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tfblfkx9rnd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690097711987,
  "history_end_time" : 1690097815880,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nyqsk80laty",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690054490089,
  "history_end_time" : 1690054571003,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "itxguntn31s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1690011309746,
  "history_end_time" : 1690011406354,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ybtzilppi96",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689968091797,
  "history_end_time" : 1689968172202,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3w5xj9yakmb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689924916826,
  "history_end_time" : 1689925019380,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kss54e4r31e",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689881664166,
  "history_end_time" : 1689881755989,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5i936xbiksv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689838524198,
  "history_end_time" : 1689838627241,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vl7u1xnuken",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689795249389,
  "history_end_time" : 1689795328989,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tuozis9xbhx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689752116742,
  "history_end_time" : 1689752221262,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rse4wvt6tge",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689708894897,
  "history_end_time" : 1689708976925,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0a0hlrius38",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689665815495,
  "history_end_time" : 1689665947153,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d65y2jfs2ct",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689622592728,
  "history_end_time" : 1689622715109,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "27sznx2aphl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689579212036,
  "history_end_time" : 1689579276079,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "10mdalfx6c9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689536099301,
  "history_end_time" : 1689536181049,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ckhj1j3dpn9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689492804351,
  "history_end_time" : 1689492873481,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vatzy8oa2li",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689449763472,
  "history_end_time" : 1689449847394,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5znzmorjlm0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689406525066,
  "history_end_time" : 1689406626764,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5piftc0qa17",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689363404090,
  "history_end_time" : 1689363523953,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fh4ty348jzq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689320227952,
  "history_end_time" : 1689320364975,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9t5h59dvpew",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689277202720,
  "history_end_time" : 1689277367160,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4o3vwunvcvi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689233820863,
  "history_end_time" : 1689233949011,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mhhn9gk86e6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689190637473,
  "history_end_time" : 1689190761368,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g8rgjj5plac",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689147314237,
  "history_end_time" : 1689147410093,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fhyxke1ex69",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1689103946361,
  "history_end_time" : 1689103989996,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z7f7dow3t5z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1689060616977,
  "history_end_time" : 1689060618486,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "eep8g14ro5e",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1689017414531,
  "history_end_time" : 1689017415935,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "g940276639g",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688974216024,
  "history_end_time" : 1688974217534,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k45zqf6lm9a",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688931011617,
  "history_end_time" : 1688931012930,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4dtwoesglse",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688887811127,
  "history_end_time" : 1688887812464,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sulggzf8zra",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688844612075,
  "history_end_time" : 1688844613498,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ocjosodzskq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688801412496,
  "history_end_time" : 1688801413852,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "f0e5loqw5rh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688758215083,
  "history_end_time" : 1688758216414,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3mkuyzqdoxp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688715017663,
  "history_end_time" : 1688715019181,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uvzk8u6zi0v",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688671816456,
  "history_end_time" : 1688671817859,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "94n93kbkj1u",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688628612023,
  "history_end_time" : 1688628613329,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xzmgvavw0yi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688585414726,
  "history_end_time" : 1688585416069,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ya5mff4e0x7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688542216831,
  "history_end_time" : 1688542218283,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ukwtn5w70dc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688499014657,
  "history_end_time" : 1688499016408,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vxucf6ie5lv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688455817490,
  "history_end_time" : 1688455819060,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ur5g3q18dsl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688412611897,
  "history_end_time" : 1688412613263,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uw37s85qdz9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688369512851,
  "history_end_time" : 1688369546369,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jwbgfws8tnz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688326371718,
  "history_end_time" : 1688326412669,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5dxq419bvdi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688283128999,
  "history_end_time" : 1688283166553,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2veo8q5myvp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688239828219,
  "history_end_time" : 1688239837863,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0s7dsba3tih",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1688196617821,
  "history_end_time" : 1688196620865,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0t7rvk8pfi3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688153568261,
  "history_end_time" : 1688153609474,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "77e12yq4r0y",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688110429495,
  "history_end_time" : 1688110496228,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8ntepckfp67",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688067318358,
  "history_end_time" : 1688067397101,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nbpckmwr6n6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1688024110987,
  "history_end_time" : 1688024212755,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f0pnijwoiyz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687981173333,
  "history_end_time" : 1687981323422,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nkv4ncbeblx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687937822032,
  "history_end_time" : 1687937954851,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3h7kcps438p",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687894845812,
  "history_end_time" : 1687895007239,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ftum191wpf3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687851538970,
  "history_end_time" : 1687851708083,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fy8rim9vsfn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687808776181,
  "history_end_time" : 1687808990631,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "h5lomvff3ym",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687765210403,
  "history_end_time" : 1687765406067,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4jk9sohzqrd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687722103752,
  "history_end_time" : 1687722366271,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xqo93b83i4u",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687678901804,
  "history_end_time" : 1687679130691,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z3gdkrmk0z3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687635903330,
  "history_end_time" : 1687636177471,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "07e7c1nag5m",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687592615083,
  "history_end_time" : 1687592887710,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8cdcoavza70",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687549507024,
  "history_end_time" : 1687549785769,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fqdymzkvl55",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687506205088,
  "history_end_time" : 1687506462178,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4ievnu02a14",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687464576406,
  "history_end_time" : 1687465011768,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wfufz1jep8j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687419763044,
  "history_end_time" : 1687420024583,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "holgd99ozyt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687376760201,
  "history_end_time" : 1687377050725,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wmm69zck4uo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687333405745,
  "history_end_time" : 1687333666998,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lsggevdrt1w",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687290748585,
  "history_end_time" : 1687291088757,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "48sjetipzqq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687247000741,
  "history_end_time" : 1687247260907,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5dykdwf6giz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687204113504,
  "history_end_time" : 1687204424229,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "17u8odohpb7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687160596677,
  "history_end_time" : 1687160872360,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9poo9iakngj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687117578775,
  "history_end_time" : 1687117852955,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bil0twxsiat",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687074130374,
  "history_end_time" : 1687074374028,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l42019fv9u8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1687031054435,
  "history_end_time" : 1687031334355,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "a5m4p9kz0xr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686987812492,
  "history_end_time" : 1686988100821,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "posc0quoicu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686944607489,
  "history_end_time" : 1686944879198,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xv706s0ixge",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686901378050,
  "history_end_time" : 1686901645196,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8tjndbdq9gn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686858366486,
  "history_end_time" : 1686858678024,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3jf6winymig",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686814881233,
  "history_end_time" : 1686815111947,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7ux16b915pp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686772006051,
  "history_end_time" : 1686772324585,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lv9lxte2okn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686728622224,
  "history_end_time" : 1686728887807,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3dzxkxasdma",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686685664279,
  "history_end_time" : 1686685996055,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pu1ae4jvysi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686642333950,
  "history_end_time" : 1686642624899,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kv5wezmjlev",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686599119911,
  "history_end_time" : 1686599407696,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u938aiyc573",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686555665532,
  "history_end_time" : 1686555897975,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6o1oh67e66i",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686512640840,
  "history_end_time" : 1686512936770,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b8ekju99ih6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686469320799,
  "history_end_time" : 1686469543526,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hj2epez7eba",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686426210013,
  "history_end_time" : 1686426490058,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "31fu4e72mt6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686382983051,
  "history_end_time" : 1686383246882,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "swjegbsp6nr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686339852385,
  "history_end_time" : 1686340122501,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6d7zdkx3087",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686296646991,
  "history_end_time" : 1686296928148,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "spgh84b2tij",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1686252613926,
  "history_end_time" : 1686252615362,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uk9v2sg9lda",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1686234284908,
  "history_end_time" : 1686234858787,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "3hs12ss2ia2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1686209414970,
  "history_end_time" : 1686209416215,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3yilkq0sh9b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1686166216448,
  "history_end_time" : 1686166217900,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cng7kzw4oer",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1686123019624,
  "history_end_time" : 1686123021401,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "on16slk93a8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1686079815464,
  "history_end_time" : 1686079816858,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k9771vnyfu0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1686036616516,
  "history_end_time" : 1686036617960,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "d0rqm099s81",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685993416901,
  "history_end_time" : 1685993418971,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nwvxq6cbt09",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685950209890,
  "history_end_time" : 1685950211123,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8j7koa2w1pe",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685907015930,
  "history_end_time" : 1685907017284,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sgwwhov9iil",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685863813629,
  "history_end_time" : 1685863814875,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jp20jo89dhf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685820615866,
  "history_end_time" : 1685820617209,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "78t3atjj0ft",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685777415619,
  "history_end_time" : 1685777416953,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "x2jf02q507x",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685734215906,
  "history_end_time" : 1685734217323,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "t0ove5lnfll",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685691012911,
  "history_end_time" : 1685691014281,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "v87z7z961ns",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685647817413,
  "history_end_time" : 1685647819618,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "v1bqr8zp0th",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685604617132,
  "history_end_time" : 1685604618399,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dheghoillrt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685561444266,
  "history_end_time" : 1685561446563,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kycsshsr8bb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685518214482,
  "history_end_time" : 1685518215730,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "avxvc5v3mgh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685475014120,
  "history_end_time" : 1685475015437,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fk9jylsi1xo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685431813074,
  "history_end_time" : 1685431814537,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "66fnlfoucj5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685388618989,
  "history_end_time" : 1685388621982,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "62i4q7b3een",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685345412466,
  "history_end_time" : 1685345413804,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k1zsaqauvwi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685302212377,
  "history_end_time" : 1685302213759,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "w7g5pbmzxsf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685259012003,
  "history_end_time" : 1685259013346,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vcg6mtzdgw5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685215816654,
  "history_end_time" : 1685215818075,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "x5ts70p40uo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685172614770,
  "history_end_time" : 1685172616395,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "i3at60lgzo3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685129418505,
  "history_end_time" : 1685129420329,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "crnjdvs96f5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685086215785,
  "history_end_time" : 1685086217264,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3nrbne0vhdr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1685043016284,
  "history_end_time" : 1685043017756,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "f6xkm6go0by",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684999950223,
  "history_end_time" : 1684999984540,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4ihu0qkgx2z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684956618513,
  "history_end_time" : 1684956619954,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gyuv6yyi1hz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684913546395,
  "history_end_time" : 1684913581264,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "65efnlvyht4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684870219439,
  "history_end_time" : 1684870221650,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "x01gcdxrzu3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684827146622,
  "history_end_time" : 1684827180273,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "h9fnivc2vrs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684783987024,
  "history_end_time" : 1684784031384,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0athgh6izwl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684740613341,
  "history_end_time" : 1684740614664,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vdzfwjyer4p",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684697580651,
  "history_end_time" : 1684697620627,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nb4ckjc3b9l",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684654356219,
  "history_end_time" : 1684654391779,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r8sn4yxvuvr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684611015737,
  "history_end_time" : 1684611017134,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3u30lcz1je3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684568094672,
  "history_end_time" : 1684568160917,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f2tqw8jgzp2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684524809543,
  "history_end_time" : 1684524852812,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "403yibqry3x",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684481690492,
  "history_end_time" : 1684481759824,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "omgit53mnp5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1684438384534,
  "history_end_time" : 1684438426957,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j4uycdr1pqo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684395017919,
  "history_end_time" : 1684395019461,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4qbdfggldwa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684351817319,
  "history_end_time" : 1684351818811,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "leplaniuwtm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684308615783,
  "history_end_time" : 1684308617196,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pty5em5rsou",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684265417560,
  "history_end_time" : 1684265419707,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "amwi52epqqb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684222218630,
  "history_end_time" : 1684222220379,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8hihmingu7d",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684179017673,
  "history_end_time" : 1684179019144,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "v9lstn7k9ro",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684135810619,
  "history_end_time" : 1684135812012,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "203oakv1xtx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684092616740,
  "history_end_time" : 1684092618517,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1t4uapkb3z6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684049414078,
  "history_end_time" : 1684049415410,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1loytcs6get",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1684006216016,
  "history_end_time" : 1684006218095,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6aaywy83x1b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683963157694,
  "history_end_time" : 1683963193263,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8dxyums656q",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683919821148,
  "history_end_time" : 1683919824465,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "iusrak1ak67",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683876755959,
  "history_end_time" : 1683876791010,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t8tlmqa5a5b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683833417008,
  "history_end_time" : 1683833418544,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o1y8xc2sjih",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683790367432,
  "history_end_time" : 1683790402388,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "adogmyz9n2q",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683747018848,
  "history_end_time" : 1683747020360,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pcmtt9ohf4x",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683703983491,
  "history_end_time" : 1683704025690,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7axja8924du",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683660616494,
  "history_end_time" : 1683660618282,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "yxd22jqooxp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683617553561,
  "history_end_time" : 1683617589083,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0odfc60ck11",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683574442213,
  "history_end_time" : 1683574484681,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lcvighpvvfd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683531010596,
  "history_end_time" : 1683531011945,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1tlxshutxrd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683488071447,
  "history_end_time" : 1683488113256,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lz7l85mb2op",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683444751370,
  "history_end_time" : 1683444786630,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2inp7m3k3x2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683401415263,
  "history_end_time" : 1683401416762,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "av2o2degjeq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683358346661,
  "history_end_time" : 1683358381334,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ecg6rkfzgku",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683315186792,
  "history_end_time" : 1683315228733,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g9smpe5fbp3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683271951414,
  "history_end_time" : 1683271985660,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pm4fbjj1s4h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683228616584,
  "history_end_time" : 1683228618010,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "e09emc7z23c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683185417736,
  "history_end_time" : 1683185419308,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3stmuyuwrx4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683142215826,
  "history_end_time" : 1683142217226,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "e94o0rolcer",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683099012876,
  "history_end_time" : 1683099014322,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k6dwdx84ifq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1683055819114,
  "history_end_time" : 1683055820628,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lpm5ld4hup0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1683012752890,
  "history_end_time" : 1683012787126,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "54jjaamyref",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682969416442,
  "history_end_time" : 1682969417891,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "r6ubznts392",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682926356595,
  "history_end_time" : 1682926389853,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yi0tldzanzd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682883015807,
  "history_end_time" : 1682883017223,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "azpufvqa00p",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682839945630,
  "history_end_time" : 1682839980859,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1dvo81qqs1b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682796616386,
  "history_end_time" : 1682796617933,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ijtsrkvjfej",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682753556158,
  "history_end_time" : 1682753592111,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "aa77etjfz99",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682710215772,
  "history_end_time" : 1682710217249,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "owoobbx69rb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682667166086,
  "history_end_time" : 1682667200549,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "w07xvle51d5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682623819953,
  "history_end_time" : 1682623822450,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4bo376lwxpk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682580766349,
  "history_end_time" : 1682580801496,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "k2u5idadkx6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682537417510,
  "history_end_time" : 1682537419038,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "g03zgb0isb8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682494367524,
  "history_end_time" : 1682494403976,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fxke4ct0hoe",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682451019881,
  "history_end_time" : 1682451021809,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "edq1l5u0rfk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682407962962,
  "history_end_time" : 1682408000117,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r5np4yc1cg7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682364621354,
  "history_end_time" : 1682364625123,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "v9oiqvkzqf1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682321557670,
  "history_end_time" : 1682321592328,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gyc7alkv011",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682278215762,
  "history_end_time" : 1682278217312,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nv78v79hy4z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682235160599,
  "history_end_time" : 1682235194964,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "as7bag8jcb8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682191816821,
  "history_end_time" : 1682191818301,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "s0svvp9q3sm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682148758071,
  "history_end_time" : 1682148794679,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7kugqf7pmyo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682105412332,
  "history_end_time" : 1682105413835,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vpnl9ki9ceo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1682062352778,
  "history_end_time" : 1682062386986,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ab63v55ia1b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1682019017070,
  "history_end_time" : 1682019018750,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jea7qmo2lr9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681975963343,
  "history_end_time" : 1681975997493,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ujmf39l6w2b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681932616720,
  "history_end_time" : 1681932618510,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "oc6xto6trgl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681889576885,
  "history_end_time" : 1681889610266,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j6kd2026sca",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681846216625,
  "history_end_time" : 1681846218430,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "b9f28g2lt5q",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681803149631,
  "history_end_time" : 1681803184446,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g0trykurmzd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681759815876,
  "history_end_time" : 1681759817389,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gf4cyqskvpk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681716740518,
  "history_end_time" : 1681716775723,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4dfvw4adz36",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681673413608,
  "history_end_time" : 1681673415112,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "euva9iccbr9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681630344962,
  "history_end_time" : 1681630379607,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xlhoygbns7g",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681587016149,
  "history_end_time" : 1681587017583,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ea4wbztscor",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681543946952,
  "history_end_time" : 1681543981932,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u5r1hscbj6o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681500617040,
  "history_end_time" : 1681500618508,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sdtfxjh4qtn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681457548514,
  "history_end_time" : 1681457583430,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "v8tecadk0cp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681414217305,
  "history_end_time" : 1681414218838,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "c73lf1wi1xt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681371151265,
  "history_end_time" : 1681371186061,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jem3nkd4ay2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681327817061,
  "history_end_time" : 1681327818615,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "r356tjvcp56",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681284747082,
  "history_end_time" : 1681284782446,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rjvozb1iibu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681241422582,
  "history_end_time" : 1681241426039,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pdgta8urnur",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681198352802,
  "history_end_time" : 1681198387162,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lcamipkxsea",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681155015625,
  "history_end_time" : 1681155017333,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ipqrrvzmjpl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681111919079,
  "history_end_time" : 1681111953471,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7g9kpnwvvdy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1681068614729,
  "history_end_time" : 1681068616175,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "brfs66bpfnf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1681025558402,
  "history_end_time" : 1681025593653,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "enx4acn7m7c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680982216983,
  "history_end_time" : 1680982218736,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sppoi8oj9sw",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680939156223,
  "history_end_time" : 1680939191041,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zvpeexmcqcd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680895821009,
  "history_end_time" : 1680895822781,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xyrsx57lrpj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680852755654,
  "history_end_time" : 1680852790293,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g81bu7a8pbk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680809414668,
  "history_end_time" : 1680809416051,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dzxg222fcn5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680766350082,
  "history_end_time" : 1680766383922,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6rckzc86rnw",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680723200899,
  "history_end_time" : 1680723245199,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qib8pkyymg8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680679948341,
  "history_end_time" : 1680679982970,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7xxhdfa9s3i",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680636783167,
  "history_end_time" : 1680636829843,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x5yqfobnqp1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680593412342,
  "history_end_time" : 1680593413651,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lla9rjaw5us",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680550449395,
  "history_end_time" : 1680550492042,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "exhwfnpa8zx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680507275399,
  "history_end_time" : 1680507278182,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vxfsxm3h70a",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680463815491,
  "history_end_time" : 1680463816879,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rik6zzzolq0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680420617389,
  "history_end_time" : 1680420618936,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dn3cau6lup2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680377418239,
  "history_end_time" : 1680377420061,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "tgsdl96mfie",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680334355711,
  "history_end_time" : 1680334389192,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z8jvyz118m5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680291015836,
  "history_end_time" : 1680291017250,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "oeuuw0112od",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680247950307,
  "history_end_time" : 1680247984979,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "38quuopk4rl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680204619415,
  "history_end_time" : 1680204623283,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dpufyq5pvt9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680161547976,
  "history_end_time" : 1680161581112,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0yprgky20vt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680118222547,
  "history_end_time" : 1680118224447,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hjxif32ibct",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1680075151158,
  "history_end_time" : 1680075184830,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3itcbrp3a16",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1680031821320,
  "history_end_time" : 1680031823938,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o9qjy0h658f",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679988750710,
  "history_end_time" : 1679988785774,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ec6m7zqebav",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679945418307,
  "history_end_time" : 1679945421123,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "16f9a91eeib",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679902359295,
  "history_end_time" : 1679902394548,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9coun485ona",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679859016427,
  "history_end_time" : 1679859018754,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nq87na9nyp8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679815946571,
  "history_end_time" : 1679815979861,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4hq3thhvrnk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679772621708,
  "history_end_time" : 1679772625506,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bwnjsmujjrp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679729550724,
  "history_end_time" : 1679729583252,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vpaddnrcpx6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679686220773,
  "history_end_time" : 1679686224882,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "q66k4pho06n",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679643147546,
  "history_end_time" : 1679643180874,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t1bpkbgohdg",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679599816108,
  "history_end_time" : 1679599817614,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "m72c48j2mkq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679556752644,
  "history_end_time" : 1679556786548,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sa54f0hmovs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679513416826,
  "history_end_time" : 1679513418889,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k6agt3lcinh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679470371930,
  "history_end_time" : 1679470412589,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d0ngjsexkur",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679427015956,
  "history_end_time" : 1679427017504,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "wwn23lg6c8i",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679383971882,
  "history_end_time" : 1679384012718,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8gws2z3ff8j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679340617128,
  "history_end_time" : 1679340618754,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8dyuebkwooz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679297573765,
  "history_end_time" : 1679297614796,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dhenqha3awy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679254215830,
  "history_end_time" : 1679254217383,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jem63jlcf0r",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679211174499,
  "history_end_time" : 1679211216492,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "i8594gs4zvi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679167816670,
  "history_end_time" : 1679167818262,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "f2pltmm9wjd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679124774266,
  "history_end_time" : 1679124815928,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "is0frhdrdrn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1679081418250,
  "history_end_time" : 1679081419903,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bho6p9tj4mm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1679038351922,
  "history_end_time" : 1679038385585,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kbn6afr12w5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678995375385,
  "history_end_time" : 1678995458333,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mx5pa68ybn9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678951818752,
  "history_end_time" : 1678951820416,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "r02v8vjd8f6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678941912675,
  "history_end_time" : 1678941995145,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "4vjeimk8xcs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678940231916,
  "history_end_time" : 1678940328495,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "psneiry835a",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678908619380,
  "history_end_time" : 1678908620908,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "32y5bnp7r0z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678822402725,
  "history_end_time" : 1678822428046,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rixfus8lhx5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678779341777,
  "history_end_time" : 1678779387129,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "63xean0vd0c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678693066777,
  "history_end_time" : 1678693179491,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xnackkblosa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678650869307,
  "history_end_time" : 1678651160171,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6nu6vw8vkg8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678608674550,
  "history_end_time" : 1678608992336,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8e5qvmiaqac",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678566772155,
  "history_end_time" : 1678566800703,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "j6tnhffgpts",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678523905708,
  "history_end_time" : 1678524020348,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z1im4errlf3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678480372006,
  "history_end_time" : 1678480399360,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rxm73rvlw7s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678437223085,
  "history_end_time" : 1678437259795,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "i8qi1c0u4w1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678393973836,
  "history_end_time" : 1678394000874,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "d6bavrzlejf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678350822933,
  "history_end_time" : 1678350856937,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2klxgylc05c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678307571041,
  "history_end_time" : 1678307597789,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "hzdg1la64yu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678264431184,
  "history_end_time" : 1678264474658,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2mKbJcEwe17o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678235234864,
  "history_end_time" : 1678235310903,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "977pkaan6ip",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678221166636,
  "history_end_time" : 1678221192643,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "p2xz21bp3da",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678178164322,
  "history_end_time" : 1678178243118,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yejb69kb8up",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1678134772176,
  "history_end_time" : 1678134798906,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "emuj7zjgteh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678091755359,
  "history_end_time" : 1678091833636,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4zfb8di2q1w",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678048564861,
  "history_end_time" : 1678048629422,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tr2tn9m3023",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1678005568580,
  "history_end_time" : 1678005669049,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "o4b2q2lsf2k",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677961967450,
  "history_end_time" : 1677961993736,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bnzkyex4yx9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677919001018,
  "history_end_time" : 1677919077519,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jp8irxhktvc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677875578802,
  "history_end_time" : 1677875606954,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "32085olnk9h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677832571210,
  "history_end_time" : 1677832643834,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t1zbad89iew",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677789180466,
  "history_end_time" : 1677789211112,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cy0npdzdqyv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677746299103,
  "history_end_time" : 1677746404332,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lapah14j37b",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677702793642,
  "history_end_time" : 1677702836456,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "h9w0t6mq0wt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677659758842,
  "history_end_time" : 1677659828530,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jy0v29o8non",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677616561731,
  "history_end_time" : 1677616614941,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rkdq0ovrpx4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677573215878,
  "history_end_time" : 1677573251192,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "l2zwt0gbnfc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677530921114,
  "history_end_time" : 1677531095269,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xnvki8bhz3m",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677486974090,
  "history_end_time" : 1677487042672,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6pqqp4wjjg2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677443569710,
  "history_end_time" : 1677443595572,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "hpqahh8qdbh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677400547472,
  "history_end_time" : 1677400615857,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0gbtshbifk9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677357171783,
  "history_end_time" : 1677357199414,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "deh2st0m17s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677314153864,
  "history_end_time" : 1677314226190,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "m5f6yzum4aa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677270775864,
  "history_end_time" : 1677270802276,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0mxrw3mo0m5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677227760474,
  "history_end_time" : 1677227829045,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "at6vzi4pm3s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677184385430,
  "history_end_time" : 1677184430734,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "zorug9hca18",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677141442540,
  "history_end_time" : 1677141518770,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vhfyr4k0k4q",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677097973329,
  "history_end_time" : 1677097999374,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pcgu8lz4x7l",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1677055013693,
  "history_end_time" : 1677055094428,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mfwj3t40qn4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1677011578455,
  "history_end_time" : 1677011606713,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nqifxho00o7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676968569531,
  "history_end_time" : 1676968644699,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3p1t8dg1kex",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676925180761,
  "history_end_time" : 1676925207882,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "27ut9mnjo6t",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676882198911,
  "history_end_time" : 1676882272903,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wwxjuusc8n7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676838771195,
  "history_end_time" : 1676838798618,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "541yc8ial0j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676795770476,
  "history_end_time" : 1676795842808,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u8w3b0k899o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676752368529,
  "history_end_time" : 1676752395495,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2383us3p00m",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676709367794,
  "history_end_time" : 1676709442556,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hgxyk4fj6od",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676666195841,
  "history_end_time" : 1676666224705,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bct52g48hni",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676623019880,
  "history_end_time" : 1676623103627,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pfflujph5y7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676579574364,
  "history_end_time" : 1676579601432,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "pfxzh2bkn50",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676537153595,
  "history_end_time" : 1676537307786,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jgs5yrlhmaq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676493178197,
  "history_end_time" : 1676493204969,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fs98ksn6asg",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676450185475,
  "history_end_time" : 1676450261945,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hwzohfltgim",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676407021147,
  "history_end_time" : 1676407087968,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kcgupxpaf30",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676363662925,
  "history_end_time" : 1676363711162,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fn4i0tggira",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676320392989,
  "history_end_time" : 1676320422416,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ha08upwoaij",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676277369479,
  "history_end_time" : 1676277443359,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bgrgl5ie9o3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676233958491,
  "history_end_time" : 1676233979844,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kbh4amv9bmj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676190946885,
  "history_end_time" : 1676191013440,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "74x1l0l25v5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676147549783,
  "history_end_time" : 1676147573730,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3kc1usaovbv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676104544426,
  "history_end_time" : 1676104616772,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "khhkwb9510o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1676061153566,
  "history_end_time" : 1676061181923,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "zh4sih1unin",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1676018169867,
  "history_end_time" : 1676018239733,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "vcpxrq95qoz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675975479661,
  "history_end_time" : 1675975607935,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3shufxqbs3j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675931758619,
  "history_end_time" : 1675931829680,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qrt2sx716j1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675888430392,
  "history_end_time" : 1675888458967,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gcj161qsvzk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675845372575,
  "history_end_time" : 1675845452655,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kRbcU3zT0L8K",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675827860735,
  "history_end_time" : 1675828192453,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "DMQyNf2bnstj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675826582334,
  "history_end_time" : 1675826689958,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "jq8gxsb6uy5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675825172816,
  "history_end_time" : 1675826081453,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "0oPiCIMTShR0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675817189393,
  "history_end_time" : 1675817260972,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "bywm2cwzihc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675801967712,
  "history_end_time" : 1675801993939,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7zb42cif33s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675759122231,
  "history_end_time" : 1675759192809,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5ohwfex9mhy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675715633912,
  "history_end_time" : 1675715671421,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "s4q931ue3lr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675672593297,
  "history_end_time" : 1675672665045,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "11f0kym3bvw",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675629148810,
  "history_end_time" : 1675629172151,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "q3bfw1cnxn8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675586084103,
  "history_end_time" : 1675586145806,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1zrayleof13",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675542741237,
  "history_end_time" : 1675542763642,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mp1by2x6gce",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675507784645,
  "history_end_time" : 1675509117812,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "m19k4fbdice",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675456364035,
  "history_end_time" : 1675456389718,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3cdznllur6q",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675413368819,
  "history_end_time" : 1675413440169,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qbe35o05ar7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675369975678,
  "history_end_time" : 1675370002527,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "i2tbr5xgsjx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675326954838,
  "history_end_time" : 1675327022696,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "leojmcppp9o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675283569751,
  "history_end_time" : 1675283595734,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "a3o2496famg",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675240554090,
  "history_end_time" : 1675240621263,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uboz66851fp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675197162402,
  "history_end_time" : 1675197188174,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cw03ehtxlfj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675154197960,
  "history_end_time" : 1675154266723,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wltenkndvk8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675110772993,
  "history_end_time" : 1675110799040,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uaos9nlqaky",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1675067758367,
  "history_end_time" : 1675067834090,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7vziluemtpx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1675024366975,
  "history_end_time" : 1675024393010,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "p65ve2dig86",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674981341668,
  "history_end_time" : 1674981405566,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l0ehvltx11s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674937969295,
  "history_end_time" : 1674937995686,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sk70oo3guxn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674894982037,
  "history_end_time" : 1674895058911,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ozmducpq3no",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674851565840,
  "history_end_time" : 1674851591712,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "q0sq3r3hjea",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674808585985,
  "history_end_time" : 1674808657420,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "e4arngmtnf3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674765178415,
  "history_end_time" : 1674765204256,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "iv57jxai8og",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674722141651,
  "history_end_time" : 1674722209175,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "es45bqox1qi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674678750728,
  "history_end_time" : 1674678773378,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0y51dvvn758",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674635768226,
  "history_end_time" : 1674635836347,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pgdls8zlwaa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674592343625,
  "history_end_time" : 1674592365583,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9eb3a2xn3db",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674549334858,
  "history_end_time" : 1674549400205,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x9ozd4bwfpv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674505949374,
  "history_end_time" : 1674505973939,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "klecpo70xj8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674462959007,
  "history_end_time" : 1674463027866,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cl7zrj7hn5h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674419546197,
  "history_end_time" : 1674419569125,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3thl7qdapia",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674376562939,
  "history_end_time" : 1674376629064,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "llios3onbe1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674333145825,
  "history_end_time" : 1674333168470,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "p5tzx7bh6ay",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674290145871,
  "history_end_time" : 1674290216461,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "omwh53lu2a8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674246749085,
  "history_end_time" : 1674246771770,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "z5mfbl3761j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674203744704,
  "history_end_time" : 1674203810875,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "k3njdeocesm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674160363314,
  "history_end_time" : 1674160387797,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6w8yb6hh3gn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674117354814,
  "history_end_time" : 1674117424970,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zfyux4gqj1k",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1674073971708,
  "history_end_time" : 1674073998357,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "w9mfpkjn0b4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1674030938338,
  "history_end_time" : 1674031005753,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mhf51drnmv8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673987563793,
  "history_end_time" : 1673987587474,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nax1lzpd93y",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673944578915,
  "history_end_time" : 1673944663465,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dwl8it8yd97",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673901160977,
  "history_end_time" : 1673901195256,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "v81ppea2ei0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673858178097,
  "history_end_time" : 1673858264195,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3kdajs9v8h9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673814755819,
  "history_end_time" : 1673814784851,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vk48az66i8z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673771767546,
  "history_end_time" : 1673771844431,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "89dxv9vfl27",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673728358014,
  "history_end_time" : 1673728385675,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sm1jmmm8fvy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673685372263,
  "history_end_time" : 1673685449691,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nqvc67rhub4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673641972844,
  "history_end_time" : 1673642004696,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xb4396w77cm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673599089073,
  "history_end_time" : 1673599187147,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f376pm27ujm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673555565412,
  "history_end_time" : 1673555595816,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "30j2cbqvcdu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673512562546,
  "history_end_time" : 1673512646399,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l6i6568w1bh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673469160102,
  "history_end_time" : 1673469187745,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mo7u88nu16o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673426170333,
  "history_end_time" : 1673426245413,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "a8qnofp5p3x",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673382761955,
  "history_end_time" : 1673382790354,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sf7bxv8krur",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673339856290,
  "history_end_time" : 1673339995146,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kb201x8drlc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673296357457,
  "history_end_time" : 1673296383937,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ydi1txq5cn7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673253363122,
  "history_end_time" : 1673253442581,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3t82u1if9jk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673209955227,
  "history_end_time" : 1673209983995,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "h2rq6wfkecd",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673167109114,
  "history_end_time" : 1673167234943,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x9hv37583kr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673123554768,
  "history_end_time" : 1673123582632,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "c2nsotk63x1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1673080566412,
  "history_end_time" : 1673080644518,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nbanhm6mlox",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1673037161386,
  "history_end_time" : 1673037188882,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ndzj6i9vi3e",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672994169467,
  "history_end_time" : 1672994246909,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6po5qiu30t1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672950771852,
  "history_end_time" : 1672950800105,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1j5cviqqwjq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672907756241,
  "history_end_time" : 1672907831080,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ztdopvk11wy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672864366196,
  "history_end_time" : 1672864393336,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ifhc6xsz912",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672821388474,
  "history_end_time" : 1672821459294,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yc604o4q6yh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672777962649,
  "history_end_time" : 1672777993273,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "q049mqzs4zq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672734949908,
  "history_end_time" : 1672735020484,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j48f9qk1q1z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672691562941,
  "history_end_time" : 1672691591577,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "imomur37jby",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672648567822,
  "history_end_time" : 1672648641929,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lw4fnc4mbd2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672605168147,
  "history_end_time" : 1672605194810,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3him4klskos",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672563199558,
  "history_end_time" : 1672563492531,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "32o3okswev3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672518763707,
  "history_end_time" : 1672518790106,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uhe44v65zuk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672476385533,
  "history_end_time" : 1672476600095,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ugipertsca8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672432349250,
  "history_end_time" : 1672432372900,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kc8wnvfe460",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672391440364,
  "history_end_time" : 1672391639168,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4wnmwvrnczz",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672345975224,
  "history_end_time" : 1672346002578,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mwq6o2740bm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672302994078,
  "history_end_time" : 1672303070503,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f46pdlxuh77",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672259578120,
  "history_end_time" : 1672259604835,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uexyx2jy5cs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672217363415,
  "history_end_time" : 1672217560441,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pv46tmul033",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672173993971,
  "history_end_time" : 1672174201807,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "autw5h8ftgc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672130930827,
  "history_end_time" : 1672131123949,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cs7vfdkyfqx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672086764717,
  "history_end_time" : 1672086790173,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jq5r6f5ouw4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1672043769522,
  "history_end_time" : 1672043843178,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "w14bb5sl5ew",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1672000360315,
  "history_end_time" : 1672000384808,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3mnh6gtzt76",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671957501105,
  "history_end_time" : 1671957587094,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2z0sryxmlh2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671913997153,
  "history_end_time" : 1671914029855,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "qs84idgw86w",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671871112527,
  "history_end_time" : 1671871197303,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mhjnr1gyqvu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671827566035,
  "history_end_time" : 1671827591370,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6atltmo4xoa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671784586428,
  "history_end_time" : 1671784762443,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fje888vj4eb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671741352950,
  "history_end_time" : 1671741417977,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hir56r5kwk3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671698158962,
  "history_end_time" : 1671698230495,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n8gaprlbmf7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671654763990,
  "history_end_time" : 1671654790074,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "t5qt0lsx51z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671611617495,
  "history_end_time" : 1671611650993,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "osqbzcdyy1h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671568361094,
  "history_end_time" : 1671568384798,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "76ztzy3s5il",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671525374199,
  "history_end_time" : 1671525444179,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zbxv1hjndxn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671482152806,
  "history_end_time" : 1671482219024,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lr52o9wnqi8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671395543979,
  "history_end_time" : 1671395566665,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "wcievlfcv5g",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671352553377,
  "history_end_time" : 1671352619937,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hmvfix33k95",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671309156393,
  "history_end_time" : 1671309179165,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "f50qwwp5yz2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671266147548,
  "history_end_time" : 1671266217619,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3b2zg4b3u7p",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671222759270,
  "history_end_time" : 1671222783740,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "yogkb7keoxo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671179751794,
  "history_end_time" : 1671179820029,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3q0uz62ylq7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671136350175,
  "history_end_time" : 1671136373724,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4c1xhogtymw",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671093354626,
  "history_end_time" : 1671093424634,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ptvin2po5ch",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1671049951620,
  "history_end_time" : 1671049974923,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ykc8jzeqm0h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1671006960637,
  "history_end_time" : 1671007028408,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f8cpur6k873",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670963562156,
  "history_end_time" : 1670963587763,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ny4qsnrzs8i",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670920555252,
  "history_end_time" : 1670920621677,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xsk2r1tq434",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670877154726,
  "history_end_time" : 1670877178672,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "hxg3lmp79zx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670834145198,
  "history_end_time" : 1670834213221,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3v4v3t7dym6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670790749913,
  "history_end_time" : 1670790773204,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "z5kgc0ksywb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670747749638,
  "history_end_time" : 1670747818921,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ezzgrxygf4m",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670704509137,
  "history_end_time" : 1670704572895,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qwix0g221sh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670661220667,
  "history_end_time" : 1670661255001,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jgzttwjo4f4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670617960115,
  "history_end_time" : 1670617985251,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mqy9is11483",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670574971590,
  "history_end_time" : 1670575037827,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xikrz5dhbbm",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670531740091,
  "history_end_time" : 1670531803297,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yezcsqs5z0g",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670488405189,
  "history_end_time" : 1670488441793,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "rv3m63cg7ri",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670445147689,
  "history_end_time" : 1670445171383,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8etf8ez4lma",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670402134046,
  "history_end_time" : 1670402199495,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7uf9l64640j",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670358923822,
  "history_end_time" : 1670359005449,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gndtj1y6qdp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670315817519,
  "history_end_time" : 1670315894151,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8ve0avlkmlh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670272606511,
  "history_end_time" : 1670272712567,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "abt2gmqd4y4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670229198680,
  "history_end_time" : 1670229235428,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ibotllygj7c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670185979126,
  "history_end_time" : 1670186005130,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xivgnvhybsv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670142817844,
  "history_end_time" : 1670142856199,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bf2o58kahpi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1670099568661,
  "history_end_time" : 1670099594318,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ctsgwgkpne7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670056567001,
  "history_end_time" : 1670056635788,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5n1ir1ji5qy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1670013370316,
  "history_end_time" : 1670013437139,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zt3ipdxqtqw",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669927731007,
  "history_end_time" : 1669927760231,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "alu0fg0vl0t",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669884260791,
  "history_end_time" : 1669884329144,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1bwn0k48d9c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669840375588,
  "history_end_time" : 1669840403788,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kviw344xed6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669797380871,
  "history_end_time" : 1669797453624,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fmff6ka4qnn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669753989965,
  "history_end_time" : 1669754020245,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "p4d0o79c33l",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669710976712,
  "history_end_time" : 1669711046800,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "a1szatq9eld",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669667585058,
  "history_end_time" : 1669667612931,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xlgxpgt966z",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669624569188,
  "history_end_time" : 1669624639748,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zan997rvpl9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669581175899,
  "history_end_time" : 1669581203196,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "shtzjof3vrs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669538165922,
  "history_end_time" : 1669538237954,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zoneohorzd0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669494933143,
  "history_end_time" : 1669494959170,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7sefhqkel37",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669451775780,
  "history_end_time" : 1669451844295,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qi1x1i4jv4t",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669408354265,
  "history_end_time" : 1669408378992,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o1r5dd5ene6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669365365368,
  "history_end_time" : 1669365432147,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "96enrt5h6wa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669321960859,
  "history_end_time" : 1669321986217,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "qt9uxsxop47",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669278968982,
  "history_end_time" : 1669279038945,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pbhkbq8jcpo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669235635466,
  "history_end_time" : 1669235665508,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "826ydm2zye2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669192566666,
  "history_end_time" : 1669192639141,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6bv2efa76g0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669149171022,
  "history_end_time" : 1669149197179,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kcw4o2bx7qq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669106213238,
  "history_end_time" : 1669106297937,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "12o8onep7d7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1669062763927,
  "history_end_time" : 1669062788283,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lcrg3oi51d5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1669019734336,
  "history_end_time" : 1669019798836,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2ova8zjsu58",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668976357526,
  "history_end_time" : 1668976380434,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "r16ekznmny8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668933343562,
  "history_end_time" : 1668933410682,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2ursh1ar6j7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668889960744,
  "history_end_time" : 1668889984577,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "5vq1mp80m89",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668880818680,
  "history_end_time" : 1668880837882,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "s6rlxwhwbqx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668875278744,
  "history_end_time" : 1668875297758,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "li2211jjwe2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668874733708,
  "history_end_time" : 1668874755101,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dun9l9j3b84",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668846943366,
  "history_end_time" : 1668847005407,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "odzri8nc4za",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668803556647,
  "history_end_time" : 1668803580483,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "yl4fh90s146",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668760541987,
  "history_end_time" : 1668760607328,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "92l6yzzsqhl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668717173531,
  "history_end_time" : 1668717198356,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6s0fueadkxy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668674143952,
  "history_end_time" : 1668674206200,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hrdxkzoarh8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668630764842,
  "history_end_time" : 1668630789570,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "y7bx8h04d41",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668587715879,
  "history_end_time" : 1668587775503,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "iad5x4tcxfy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668544447639,
  "history_end_time" : 1668544486017,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bqsqez3sj62",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668523496833,
  "history_end_time" : 1668523531082,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fkylve1obj1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668504236443,
  "history_end_time" : 1668505100951,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "e628d3juihq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668497708650,
  "history_end_time" : 1668498607944,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lrfvqw1qinq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/lrfvqw1qinq/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668494044043,
  "history_end_time" : 1668494070956,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k4j4eyqnso0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668490185723,
  "history_end_time" : 1668490244696,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "21x77jgmrqt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/21x77jgmrqt/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1668488910989,
  "history_end_time" : 1668488913914,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "stwqr7fr2rt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/stwqr7fr2rt/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668457995282,
  "history_end_time" : 1668458019564,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9ggyzc3hcoa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/9ggyzc3hcoa/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668414840148,
  "history_end_time" : 1668414874787,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "umc7u8oiul6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/umc7u8oiul6/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668414781179,
  "history_end_time" : 1668414807677,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "m87sfprcxst",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/m87sfprcxst/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1668393920868,
  "history_end_time" : 1668393922766,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "33ltbf96ymr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/33ltbf96ymr/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1668393595053,
  "history_end_time" : 1668393597320,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9dgwce1lijh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/9dgwce1lijh/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1668392278961,
  "history_end_time" : 1668392281608,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bxs6y8pj2af",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/bxs6y8pj2af/cmaq_ai_utils.py\", line 21, in <module>\n    days = get_days_list_for_prediction(sdate, edate)\nNameError: name 'get_days_list_for_prediction' is not defined\n",
  "history_begin_time" : 1668371578684,
  "history_end_time" : 1668371607847,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nm8rjsy03xg",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668328416441,
  "history_end_time" : 1668328448919,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gymihwqezgl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668328372603,
  "history_end_time" : 1668328397704,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "5ogeqs10t42",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668320545197,
  "history_end_time" : 1668321770746,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "hjac548a4uf",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668285170930,
  "history_end_time" : 1668285196418,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "d049unpz92y",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668242277304,
  "history_end_time" : 1668242378574,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j0jhet4u3g6",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1668242248940,
  "history_end_time" : 1668242326990,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "643qhdbaw7c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668198912181,
  "history_end_time" : 1668198975496,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0rzrsnhnocx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668158661811,
  "history_end_time" : 1668158752178,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "ishdom26iil",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668158230106,
  "history_end_time" : 1668158292303,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "xo6tzulqcg5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668157882766,
  "history_end_time" : 1668158199117,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "tk9dm8p173t",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : 1668157708073,
  "history_end_time" : 1668157816051,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "dq4fxey17jt",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668155744255,
  "history_end_time" : 1668155812249,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nt5p3lr513a",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668155729920,
  "history_end_time" : 1668155798435,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4j8iatayems",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668112384313,
  "history_end_time" : 1668112410005,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "llcn0krptkv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1668069338037,
  "history_end_time" : 1668069404860,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dvrmv3zgv2s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1668069337063,
  "history_end_time" : 1668069398540,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "877uzrzgogh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1668025969741,
  "history_end_time" : 1668025994897,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ib6n5dc9bpp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667982952141,
  "history_end_time" : 1667983017827,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t5h7bk3d7us",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667982922680,
  "history_end_time" : 1667982989065,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "sfk6wi22b9w",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667939569974,
  "history_end_time" : 1667939594786,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ucpg5pur0qu",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Running",
  "history_begin_time" : 1667925237509,
  "history_end_time" : 1667950923707,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "k8q4u3ycmag",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667896425170,
  "history_end_time" : 1667896457121,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o0z158qayi5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667896367064,
  "history_end_time" : 1667896391789,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7ytkdsmvs4k",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667892411074,
  "history_end_time" : 1667892496082,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "zya6b69vw5p",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667853177194,
  "history_end_time" : 1667853201554,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "l6mn4assg81",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667810153750,
  "history_end_time" : 1667810218640,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "waccmrg14kh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667810124730,
  "history_end_time" : 1667810197062,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r82y4mx7ko3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667766775577,
  "history_end_time" : 1667766801241,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bnzbr2eh5a9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667723720870,
  "history_end_time" : 1667723785468,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "htgdbrgfdum",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667723695246,
  "history_end_time" : 1667723759488,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0me31pd3i46",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667676773390,
  "history_end_time" : 1667676798053,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ml7n2a33md9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667633722397,
  "history_end_time" : 1667633792474,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "iwhcco87226",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 75, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1667633710708,
  "history_end_time" : 1667633770557,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "adc1d1s9g43",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667590381264,
  "history_end_time" : 1667590406757,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ff48t8x0cw7",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667547346424,
  "history_end_time" : 1667547409531,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "57t0l482o5f",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1667547340413,
  "history_end_time" : 1667547381758,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7lceqw0r6bv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667504006904,
  "history_end_time" : 1667504048088,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dob7kz3trk0",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667461063820,
  "history_end_time" : 1667461128854,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2xbm43si9tk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667461005198,
  "history_end_time" : 1667461079813,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d6g9bxybvna",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667417575611,
  "history_end_time" : 1667417601418,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "5su4td7xo8w",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667374680967,
  "history_end_time" : 1667374746405,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "706zpozl1w4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667374597542,
  "history_end_time" : 1667374665807,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8dttdgy6jdn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667331190332,
  "history_end_time" : 1667331216667,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ou2hhgvdp67",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1667288176190,
  "history_end_time" : 1667288233399,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "22gnrxblvpb",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667288166223,
  "history_end_time" : 1667288238461,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5zizr8gvfsq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667249030883,
  "history_end_time" : 1667249057433,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cshjikxpboc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667211440702,
  "history_end_time" : 1667212164071,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0wv2l8dq0ri",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667211289504,
  "history_end_time" : 1667212070312,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zmasr3pepf2",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667158371947,
  "history_end_time" : 1667158397037,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "oxkff84ecsc",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667115406785,
  "history_end_time" : 1667115472341,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zjaeaiq3a79",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667115371908,
  "history_end_time" : 1667115435639,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lfqw1rd7r6w",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1667071978628,
  "history_end_time" : 1667072004277,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "c8zw0qy3ic3",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1667028976479,
  "history_end_time" : 1667029038875,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jv4ol6ykj64",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1667028963459,
  "history_end_time" : 1667029012014,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "zwbehd3kdog",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1666985585275,
  "history_end_time" : 1666985611695,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6yme6lpijgx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666942582605,
  "history_end_time" : 1666942645582,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7r81ao403ft",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1666942569905,
  "history_end_time" : 1666942615961,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2qmqon78bwe",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1666899173791,
  "history_end_time" : 1666899199065,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4t5p5u0a4wg",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666856375674,
  "history_end_time" : 1666856477386,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7i8dm2ypqhl",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666856263552,
  "history_end_time" : 1666856358485,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fn8rdq7ei64",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666812978790,
  "history_end_time" : 1666813042096,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xh323exqp4h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666769769848,
  "history_end_time" : 1666769832813,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lvqg3p8178u",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nTraceback (most recent call last):\n  File \"test_data.py\", line 23, in <module>\n    cmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3563, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\", line 1180, in to_csv\n    csv_formatter.save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 261, in save\n    self._save()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 266, in _save\n    self._save_body()\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 304, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\", line 315, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"pandas/_libs/writers.pyx\", line 72, in pandas._libs.writers.write_csv_rows\nOSError: [Errno 5] Input/output error\n",
  "history_begin_time" : 1666769752258,
  "history_end_time" : 1666769803186,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "N9LLS96JY0iG",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666751229295,
  "history_end_time" : 1666751418943,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "m44s8z1zwgo",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1666726901767,
  "history_end_time" : 1666726992051,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "L2vJTXIgV0lD",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666685944094,
  "history_end_time" : 1666686058771,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "chdnceivlsj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666683318062,
  "history_end_time" : 1666683381359,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4nedfw94u9l",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666682532536,
  "history_end_time" : 1666683406498,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "l7zlfxff61y",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666681884328,
  "history_end_time" : 1666681975530,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "yqnrqtdzt9i",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1666681641223,
  "history_end_time" : 1666681691693,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Failed"
},{
  "history_id" : "l0f4j6o50ok",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666679099108,
  "history_end_time" : 1666679185966,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "k485nsa9omi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666640184029,
  "history_end_time" : 1666640248491,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mfptl83jze4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1666627449250,
  "history_end_time" : 1666627497232,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "evjvq1foasx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\n",
  "history_begin_time" : 1666553447721,
  "history_end_time" : 1666553446617,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Running"
},{
  "history_id" : "c3rkwz483ks",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666387100746,
  "history_end_time" : 1666387673721,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d7vkm832b0f",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666343993732,
  "history_end_time" : 1666344905430,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nxy4k0t60o4",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666294779805,
  "history_end_time" : 1666294913649,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7bssoi9ugpa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666259824497,
  "history_end_time" : 1666260789324,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "htvo8azd22v",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666208106803,
  "history_end_time" : 1666208169642,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fa78fivsjfy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666164914078,
  "history_end_time" : 1666164976788,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "w8bi0gc4f0a",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666121702223,
  "history_end_time" : 1666121765199,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3cqfp0a1k8f",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666078542179,
  "history_end_time" : 1666078606186,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "doxo1xa0jf8",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1666035308219,
  "history_end_time" : 1666035370369,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "55z4ut1838m",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665992119608,
  "history_end_time" : 1665992183377,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q28dwtmwi53",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/q28dwtmwi53/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1665964660623,
  "history_end_time" : 1665964665153,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "d11eeyrzwsj",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/d11eeyrzwsj/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1665963679866,
  "history_end_time" : 1665963685093,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9ae6pignlfi",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665962529970,
  "history_end_time" : 1665962597408,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j2xvwa5z40s",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/j2xvwa5z40s/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1665942675303,
  "history_end_time" : 1665942679647,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xg3cotd1bar",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 7, in <module>\n    from cmaq_ai_utils import *\n  File \"/home/zsun/gw-workspace/xg3cotd1bar/cmaq_ai_utils.py\", line 5, in <module>\n    import xarray as xr\nModuleNotFoundError: No module named 'xarray'\n",
  "history_begin_time" : 1665942225569,
  "history_end_time" : 1665942230414,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "qlplrf86oro",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665939035710,
  "history_end_time" : 1665939101709,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9r584uz7k2f",
  "history_input" : null,
  "history_output" : "No value present",
  "history_begin_time" : 1665937971293,
  "history_end_time" : 1665937971629,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7zyl4zg3wz5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665932276831,
  "history_end_time" : 1665934029282,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "pmikdz50vrv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665930999378,
  "history_end_time" : 1665931078612,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "65lsucfj2tp",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 346, in concat\n    op = _Concatenator(\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\", line 403, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1665930657639,
  "history_end_time" : 1665930705212,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "e48ni26fs6h",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665930350632,
  "history_end_time" : 1665930589634,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "3j4fgojjqa9",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665928781799,
  "history_end_time" : 1665928903147,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "p1gza8ce1zx",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665926809778,
  "history_end_time" : 1665926968414,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "df4d8f990qs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS3/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665024076767,
  "history_end_time" : 1665032721260,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "hg0y8d3q2gy",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS3/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665022136669,
  "history_end_time" : 1665023785744,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "piv4xup504c",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1665008242165,
  "history_end_time" : 1665008399895,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "gijgawso6bs",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1664983497260,
  "history_end_time" : 1665009008635,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "5kkkuvj74py",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1664950169135,
  "history_end_time" : 1664950293400,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "omsccgtffhq",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1664506163909,
  "history_end_time" : 1664506281019,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "f24zth2lug1",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1664428571199,
  "history_end_time" : 1664428692417,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "hzj7jgz2x1j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664427014349,
  "history_end_time" : 1664427014349,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Skipped"
},{
  "history_id" : "bdge7ypv9qs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1664426709383,
  "history_end_time" : 1664426992854,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "o8jub3ujz1d",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/o8jub3ujz1d/test_data.py\", line 14, in <module>\n    cmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 294, in concat\n    op = _Concatenator(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 351, in __init__\n    raise ValueError(\"No objects to concatenate\")\nValueError: No objects to concatenate\n",
  "history_begin_time" : 1663783489634,
  "history_end_time" : 1663783491101,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "IUQwHeJIOsfY",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660807107782,
  "history_end_time" : 1662171334464,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "xLVXqD5guYRk",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660788692106,
  "history_end_time" : 1662171335333,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "cPhNn3xlCvhW",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660785086280,
  "history_end_time" : 1662171336645,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "PpNqWQu9p1fB",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660779266826,
  "history_end_time" : 1662171337331,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "pv7r6fyxiok",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660777711434,
  "history_end_time" : 1660778171064,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "mAwHFcxtlhoH",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660773780759,
  "history_end_time" : 1662171341913,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "b6Vgld2gSBJh",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660766044478,
  "history_end_time" : 1662171342850,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "boFkBtXonPUg",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660762067798,
  "history_end_time" : 1662171343478,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "RrRdKZZQRh1o",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660760380116,
  "history_end_time" : 1662171344997,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "KiTAxehMeLuG",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660750556667,
  "history_end_time" : 1662171345780,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "mbjKNmQ0GC7S",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660708614348,
  "history_end_time" : 1662171349729,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "AHlNbxs7FMLX",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660707359745,
  "history_end_time" : 1662171350347,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "rGzunfOxGcfW",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660680650167,
  "history_end_time" : 1662171350965,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "YtelgumauTn5",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660673770066,
  "history_end_time" : 1662171351581,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "Fk6xKTjoLuUn",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660567212078,
  "history_end_time" : 1662171352244,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "mybVZmxthMqr",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660565468012,
  "history_end_time" : 1662171353099,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "TR2BsYIKnuqa",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/zsun/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660521106302,
  "history_end_time" : 1662171354084,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "i9edYmJWFu11",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\nremove_file(f\"{testing_path}/testing.csv\")\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "remove old files/groups/ESS/aalnaim/cmaq//testing_input_hourly/testing.csv\nDone with generating testing.csv!\n",
  "history_begin_time" : 1660371712556,
  "history_end_time" : 1662171355394,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "alcMaLRncL60",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Done with generating testing.csv!\n",
  "history_begin_time" : 1660311593937,
  "history_end_time" : 1662171356111,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "jge10ygs0ym",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Done with generating testing.csv!\n",
  "history_begin_time" : 1660300171181,
  "history_end_time" : 1660301768667,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "KcjHf94gR1jP",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))   \n# advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\ncmaq.to_csv(f\"{testing_path}/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Done with generating testing.csv!\n",
  "history_begin_time" : 1660279878836,
  "history_end_time" : 1660281309885,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "1qDhgq5b0agH",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\nfrom cmaq_ai_utils import *\n\ntesting_path = f'{cmaq_folder}/testing_input_hourly'\nall_hourly_files = glob.glob(os.path.join(testing_path, \"test_data_*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(f\"{cmaq_folder}/testing_input_hourly/testing.csv\",index=False)\n\nprint('Done with generating testing.csv!')",
  "history_output" : "Done with generating testing.csv!\n",
  "history_begin_time" : 1660275063289,
  "history_end_time" : 1660281306474,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "bQmcVkb16xlJ",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"test_data_*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1660190362856,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "utlvlq24cny",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"test_data_*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1660008288283,
  "history_end_time" : 1660008356626,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "DRXccA02Rcfv",
  "history_input" : "# merge all hourly testing data into daily files\n\nimport pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"test_data_*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659742206802,
  "history_end_time" : 1660281305887,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "BbFVf1hthJGp",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"test_data_*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659731017787,
  "history_end_time" : 1660281305334,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "CZzuoNc8rM2E",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"test_data_*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : null,
  "history_begin_time" : 1659730939724,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "6TcXF6w8pObc",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659721363240,
  "history_end_time" : 1660281304521,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "QJ0DeTuJ6y9B",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659664966980,
  "history_end_time" : 1660281303614,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "BwubXYzPf1Qh",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "test_data.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\nDone!\n",
  "history_begin_time" : 1659661767460,
  "history_end_time" : 1660281303053,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "FXbTYGE8n0Eu",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659582254360,
  "history_end_time" : 1660281302045,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "e7nkl9r1j85",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659578968916,
  "history_end_time" : 1659579040888,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "175q5ziJtWgx",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1659449256973,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "RNb4N7CDN7MF",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1657139578755,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "6nHtrluRC7Zw",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Done!\n",
  "history_begin_time" : 1657104262170,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "SuLCni8ifPwF",
  "history_input" : "import pandas as pd\nimport glob\nimport os\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq   = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'YYYYMMDDHH'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"test_data.py\", line 16, in <module>\n    cmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/aalnaim/CMAQAI/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 'YYYYMMDDHH'\n",
  "history_begin_time" : 1657103824151,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "DFvLKuZVIu5O",
  "history_input" : "import pandas as pd\nimport glob\nfrom pathlib import Path\n\n# home directory\n# home = str(Path.home())\n\npath = '/groups/ESS/aalnaim/cmaq/input_hourly'\nall_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n\ndf_from_each_hourly_file = (pd.read_csv(f) for f in all_hourly_files)\ncmaq   = pd.concat(df_from_each_hourly_file, ignore_index=True)\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/input_hourly/testing.csv\",index=False)\n\nprint('Done!')",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 9, in <module>\n    all_hourly_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\nNameError: name 'os' is not defined\n",
  "history_begin_time" : 1657103783810,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "h2sxykdhd89",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/testing.csv\",index=False)",
  "history_output" : "Running",
  "history_begin_time" : 1656428784905,
  "history_end_time" : 1656450968069,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "gs063ewii5p",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/testing.csv\",index=False)",
  "history_output" : "bash: python: command not found\n",
  "history_begin_time" : 1656428417899,
  "history_end_time" : 1656428429386,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "z2OTrDQfbKG1",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/testing.csv\",index=False)",
  "history_output" : "Running",
  "history_begin_time" : 1655490516867,
  "history_end_time" : 1656318988073,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "vmsgxwkDgAX9",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/testing.csv\",index=False)",
  "history_output" : "Running",
  "history_begin_time" : 1655276958434,
  "history_end_time" : 1656318987456,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "4UMZNmWINDCi",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Running",
  "history_begin_time" : 1655078033924,
  "history_end_time" : 1656318986937,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "c3xunsstl48",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Running",
  "history_begin_time" : 1655073498802,
  "history_end_time" : 1655073601651,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "s3n71qjywwp",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/s3n71qjywwp/test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joe/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654726164061,
  "history_end_time" : 1654726164727,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "119svvm2n58",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Running",
  "history_begin_time" : 1654618783653,
  "history_end_time" : 1654618899620,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Done"
},{
  "history_id" : "6xqknj4ocjw",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 452, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 946, in __init__\n    self._make_engine(self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] No such file or directory: '/home/zsun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654616729016,
  "history_end_time" : 1654616755246,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Failed"
},{
  "history_id" : "87p1pyxeyia",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 452, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 946, in __init__\n    self._make_engine(self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] No such file or directory: '/home/zsun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654477449165,
  "history_end_time" : 1654477477629,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "roeaa3",
  "indicator" : "Failed"
},{
  "history_id" : "dr9onztcfzr",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 676, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 448, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 880, in __init__\n    self._make_engine(self.engine)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1114, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1891, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas\\_libs\\parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas\\_libs\\parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] File C:\\Users\\JensenSun/cmaq/test_data.csv does not exist: 'C:\\\\Users\\\\JensenSun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654465999479,
  "history_end_time" : 1654466000025,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kg1t6le7j3s",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 452, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 946, in __init__\n    self._make_engine(self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] No such file or directory: '/home/zsun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654456069764,
  "history_end_time" : 1654456095482,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "roeaa3",
  "indicator" : "Failed"
},{
  "history_id" : "79k5igd3lip",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1654319745196,
  "history_end_time" : 1654319833416,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "43g0l0snuv0",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 452, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 946, in __init__\n    self._make_engine(self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] No such file or directory: '/home/zsun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654317918359,
  "history_end_time" : 1654317950935,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "roeaa3",
  "indicator" : "Done"
},{
  "history_id" : "uaf4sbot356",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 452, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 946, in __init__\n    self._make_engine(self.engine)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"/home/zsun/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] No such file or directory: '/home/zsun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1654314692985,
  "history_end_time" : 1654314735195,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "roeaa3",
  "indicator" : "Done"
},{
  "history_id" : "vgq2339nmrc",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1653698490119,
  "history_end_time" : 1653698615352,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "qz78x01107q",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1653698392955,
  "history_end_time" : 1653698475052,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "etusm6ishr9",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 676, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 448, in _read\n    parser = TextFileReader(fp_or_buf, **kwds)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 880, in __init__\n    self._make_engine(self.engine)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1114, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1891, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas\\_libs\\parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas\\_libs\\parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\nFileNotFoundError: [Errno 2] File C:\\Users\\JensenSun/cmaq/test_data.csv does not exist: 'C:\\\\Users\\\\JensenSun/cmaq/test_data.csv'\n",
  "history_begin_time" : 1652934716546,
  "history_end_time" : 1652934717102,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2djxmnhsg7q",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/2djxmnhsg7q/test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joe/cmaq/test_data.csv'\n",
  "history_begin_time" : 1652897343432,
  "history_end_time" : 1652897344120,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pqwcp469fyi",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1652832229164,
  "history_end_time" : 1652832313323,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "z6ke7lqrm2q",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1652831359623,
  "history_end_time" : 1652831447653,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "65isind7el0",
  "history_input" : null,
  "history_output" : "Remote SCP command had error: scp: 65isind7el0.tar: Disk quota exceeded",
  "history_begin_time" : 1652786139673,
  "history_end_time" : 1652786141679,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Failed"
},{
  "history_id" : "f8b1qxzw08d",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1652055212953,
  "history_end_time" : 1652055297109,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "tk97p0j88kq",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1652048118351,
  "history_end_time" : 1652048197065,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Done"
},{
  "history_id" : "1dtvzy8f0c1",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/1dtvzy8f0c1/test_data.py\", line 6, in <module>\n    cmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joe/cmaq/test_data.csv'\n",
  "history_begin_time" : 1651361418083,
  "history_end_time" : 1651361418783,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9jnwki7e9s7",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1650480846339,
  "history_end_time" : 1650480978174,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "mk7uon7ya8f",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1650473789759,
  "history_end_time" : 1650473915149,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "z20aw1llntk",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1650252523102,
  "history_end_time" : 1650252619157,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "aosgbkzntki",
  "history_input" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(home+\"/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(home+\"/cmaq/testing.csv\",index=False)",
  "history_output" : "",
  "history_begin_time" : 1650215097103,
  "history_end_time" : 1650215191122,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "3wgogh",
  "indicator" : "Done"
},{
  "history_id" : "v1z8t5i8d44",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664422603476,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "3dihkxjne9j",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660777307078,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "ex3kdzpfxhs",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660189690461,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "01xvs5vv6tv",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660166319945,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "j4vyewex40p",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660294477710,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "2hlnp5r6jxo",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660786975146,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "rwec5q2n2ab",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660853992781,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "xtfgdwn3ncp",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660854222329,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "jgxmctru2yp",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660786903455,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "7bohn572a2o",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1660295756111,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "p6wvf2",
  "indicator" : "Stopped"
},{
  "history_id" : "01kn0iblloz",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664422878608,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "ilo9ykryvaf",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1666577007670,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "d1pobcesnvw",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1666553384682,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},{
  "history_id" : "7ia09nq54cb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1666685918687,
  "history_notes" : null,
  "history_process" : "b8uv5z",
  "host_id" : "aqt8fv",
  "indicator" : "Stopped"
},]
