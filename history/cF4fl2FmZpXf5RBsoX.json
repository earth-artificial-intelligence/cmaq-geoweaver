[{
  "history_id" : "tho7e54gqw7",
  "history_input" : "## importing necessary libraries\nimport glob\nimport pandas as pd\nfrom pathlib import Path\n# home directory\nhome = str(Path.home())\nfiles=glob.glob(r'/groups/ESS/mislam25/cmaq_results_2020_2021/*.txt')\n#files=glob.glob(r'D:/Research/CMAQ/2021/text/*.txt')\ndata_frame = pd.DataFrame()\nmerged=[]\nfor file in files:\n    df=pd.read_csv(file)\n    merged.append(df)\ndata_frame = pd.concat(merged)\ndata_frame['YYYYMMDDHH'] = data_frame['YYYYMMDDHH'].map(str)\ndata_frame['year'] = data_frame['YYYYMMDDHH'].str[:4]\ndata_frame['month'] = data_frame['YYYYMMDDHH'].str[4:6]\ndata_frame['day'] = data_frame['YYYYMMDDHH'].str[6:8]\ndata_frame['hours'] = data_frame['YYYYMMDDHH'].str[8:10]\nnew_df=data_frame.drop(['Station ID','CMAQ_NO(ppb)','AirNOW_NO2(ppb)','AirNOW_CO(ppm)'],axis=1)\nfinal_df = new_df.rename(columns={new_df.columns[3]: 'AirNOW_O3'})\nfinal_df = final_df[final_df.AirNOW_O3!= -999]\nfinal_df.to_csv(home+'/cmaq/cmaq_2020_2021.csv',index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1648001402336,
  "history_end_time" : 1648001447127,
  "history_notes" : null,
  "history_process" : "55afa1",
  "host_id" : "vneyuq",
  "indicator" : "Done"
},{
  "history_id" : "k4zh4f5i0ls",
  "history_input" : "# NASA-GEOWEAVER: Environment setting\n\nimport os\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Required packages to run this process.\nrequired = {'pandas','pathlib','sklearn','numpy','keras','tensorflow','tensorflow-gpu','autokeras','kaleido','glob2'}\ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\nif missing:\n    print(\"Packages missing and will be installed: \", missing)\n    python = sys.executable\n    subprocess.check_call(\n        [python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n\n################################\n#  END OF PACKAGES Installation  #\n\n\n# Creating directoris \nfrom pathlib import Path\nhome = str(Path.home())\nfolders = ['cmaq/exploratory_analysis', 'cmaq/prediction_maps', 'cmaq/prediction_files','cmaq/models']\nfor folder in folders:\n  paths=Path(home+'/'+folder)\n  paths.mkdir(parents=True,exist_ok=True)\n  \n  ###############################\n  # END OF DIRECTORY CREATION #",
  "history_output" : "",
  "history_begin_time" : 1648001367095,
  "history_end_time" : 1648001401828,
  "history_notes" : null,
  "history_process" : "9xdvh6",
  "host_id" : "vneyuq",
  "indicator" : "Done"
},{
  "history_id" : "kiz7hga2apg",
  "history_input" : "# NASA GEOWEAVER\n# CMAQ-AI Model: Poocessing the data - shifting columns of NO2\n\n## importing necessary libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\nyear_2020=final.loc[final['year']==2020]\n\n# Processing training  data\nselected_vars = year_2020.drop(['YYYYMMDDHH','year'],axis=1)\n\n########################################################\n## Correlation matrix heatmap\n# Correlation between different variables\ncorr = selected_vars.corr()\n# Set up the matplotlib plot configuration\nf, ax = plt.subplots(figsize=(18, 10))\n# Generate a mask for upper traingle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n# Configure a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n# Draw the heatmap\nsns.heatmap(corr, annot=True, mask = mask, cmap=cmap)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top + 0.5)\n#ax.set(xlim=(0, 12))\nplt.savefig(home+'/cmaq/exploratory_analysis/correlation.png')\n########################################################\n\n# plotting r2 values of different variables vs AirNOW_O3\n########################################################\ncolumns=list(selected_vars)\nfor i in columns:\n  try:\n  \tsns.lmplot(x=i, y=\"AirNOW_O3\", data=selected_vars);\n  \tplt.savefig(home+'/cmaq/exploratory_analysis/'+i+'_AirNOW_O3.png')\n  except FileNotFoundError:\n    pass\n    \n########################################################\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/mislam25/gw-workspace/kiz7hga2apg/exploratory_data_analysis.py\", line 16, in <module>\n    final=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1648001447212,
  "history_end_time" : 1648001487188,
  "history_notes" : null,
  "history_process" : "smwp7r",
  "host_id" : "vneyuq",
  "indicator" : "Done"
},{
  "history_id" : "2okv8c2gcsa",
  "history_input" : "# NASA GEOWEAVER\n# CMAQ-AI Model: Training Voting-XGBoost model\nprint(\"training_xgboost\")\n# Importing necessary libraries\nimport pandas as pd\nimport sklearn\nfrom sklearn.ensemble import VotingRegressor\nfrom xgboost.sklearn import XGBRegressor\nimport pickle\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\n#train=final.loc[final['year']==2022]\ntrain=final[final['year'].isin([2020,2021])]\n\n# Processing training  data\nX = train.drop(['AirNOW_O3','YYYYMMDDHH','year'],axis=1)\ny = train['AirNOW_O3']\n\n# Defining voting-ensemble based xgboost model\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n# save the model to disk\nfilename = home+'/cmaq/models/xgboost.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(ensemble, open(filename, 'wb'))\n",
  "history_output" : "training_xgboost\nTraceback (most recent call last):\n  File \"/home/mislam25/gw-workspace/2okv8c2gcsa/training_xgboost.py\", line 16, in <module>\n    final=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1648001487430,
  "history_end_time" : 1648001537022,
  "history_notes" : null,
  "history_process" : "106i1i",
  "host_id" : "vneyuq",
  "indicator" : "Done"
},{
  "history_id" : "1ahyunvb7jk",
  "history_input" : "# NASA Geoweaver\n# CMAQ-AI Model: Voting-Random Forest\nprint(\"training_rf\")\n# Importing necessary libraries\nimport pandas as pd\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\ntrain=final[final['year'].isin([2020,2021])]\n\n# Processing training  data\nX = train.drop(['AirNOW_O3','YYYYMMDDHH','year'],axis=1)\ny = train['AirNOW_O3']\n\n# define the voting-random forest model\nmodels = list()\nmodels.append(('cart1', RandomForestRegressor(max_depth=1)))\nmodels.append(('cart2', RandomForestRegressor(max_depth=2)))\nmodels.append(('cart3', RandomForestRegressor(max_depth=3)))\nmodels.append(('cart4', RandomForestRegressor(max_depth=4)))\nmodels.append(('cart5', RandomForestRegressor(max_depth=5)))\nmodels.append(('cart6', RandomForestRegressor(max_depth=6)))\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n\n# fit the model on all available data\nensemble.fit(X, y)\n\n# save the model to disk\nfilename = home+'/cmaq/models/rf.sav'\n#filename = 'D:/Research/CMAQ/local_test/rf.sav'\npickle.dump(ensemble, open(filename, 'wb'))\n\n",
  "history_output" : "training_rf\nTraceback (most recent call last):\n  File \"/home/mislam25/gw-workspace/1ahyunvb7jk/training_random_forest.py\", line 16, in <module>\n    final=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/merged_2020_2021.csv'\n",
  "history_begin_time" : 1648001537549,
  "history_end_time" : 1648001585890,
  "history_notes" : null,
  "history_process" : "q2io1w",
  "host_id" : "vneyuq",
  "indicator" : "Done"
},{
  "history_id" : "hnqhwtwma85",
  "history_input" : "# NASA Geoweaver\n# CMAQ-AI Model: Autokeras for Automated-Deep Learning\nprint(\"training_autokeras\")\n# Importing necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom autokeras import StructuredDataRegressor\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.models import model_from_json\nimport tensorflow as tf\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n\n# load dataset\nfinal=pd.read_csv(home+'/cmaq/merged_2020_2021.csv')\n\n# defining training variables\ntrain=final[final['year'].isin([2020,2021])]\n\n# processing training  data\nX = train.drop(['AirNOW_O3','YYYYMMDDHH','year'],axis=1)\ny = train['AirNOW_O3']\nX.head()\nX=X.values.astype('float32')\ny=y.values.astype('float32')\n\n# load dataset\n# separate into train and test sets\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n# define the search\nsearch = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')\n# perform the search\n#search.fit(x=X_train, y=y_train, verbose=0)\nsearch.fit(x=X, y=y, verbose=0)\n# evaluate the model\n#mae, _ = search.evaluate(X_test, y_test, verbose=0)\n#print('MAE: %.3f' % mae)\n# use the model to make a prediction\n#X_new = asarray([[108]]).astype('float32')\n#yhat = search.predict(X_new)\n#print('Predicted: %.3f' % yhat[0])\n# get the best performing model\nmodel = search.export_model()\n# summarize the loaded model\nmodel.summary()\nprint(search)\n# save the best performing model to file\nmodel.save(home+'/cmaq/models/autokeras',save_format=\"tf\")\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1648001594230,
  "history_end_time" : 1648001586341,
  "history_notes" : null,
  "history_process" : "5o4fxj",
  "host_id" : "vneyuq",
  "indicator" : "Running"
}]
