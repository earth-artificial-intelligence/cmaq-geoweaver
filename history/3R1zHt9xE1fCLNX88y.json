[{
  "history_id" : "7f6mlvzss4j",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n\npython cmaq/pre_processing.py\nexit",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/zkvtPP4O3wwnaE8qEhqdT4NNVt/cmaq/pre_processing.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646115570185,
  "history_end_time" : 1646115593265,
  "history_notes" : null,
  "history_process" : "ftn2kp",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "ckffjmmcxkd",
  "history_input" : "#!/bin/bash\n\n#SBATCH --partition=normal                 # will run on any cpus in the 'normal' partition\n#SBATCH --job-name=python-cpu\n#SBATCH --output=python-cpu.%j.out\n#SBATCH --error=python-cpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1                   # up to 48 per node\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; maximum is 180GB per node\n#SBATCH --export=ALL\n#SBATCH --time=0-00:05:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n\npython cmaq/exploratory_data_analysis.py\nexit",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/zkvtPP4O3wwnaE8qEhqdT4NNVt/cmaq/exploratory_data_analysis.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646115594225,
  "history_end_time" : 1646115618425,
  "history_notes" : null,
  "history_process" : "wfd3c5",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "6dn8afr0fpx",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_xgboost.py",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/zkvtPP4O3wwnaE8qEhqdT4NNVt/cmaq/training_xgboost.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646115618463,
  "history_end_time" : 1646115644273,
  "history_notes" : null,
  "history_process" : "j7uo3v",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "e7e2u5kd4mm",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_xgboost.py",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/zkvtPP4O3wwnaE8qEhqdT4NNVt/cmaq/prediction_xgboost.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646115644375,
  "history_end_time" : 1646115670816,
  "history_notes" : null,
  "history_process" : "zt10an",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "3wj4zo4nv4b",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_random_forest.py",
  "history_output" : "C:\\Users\\didar\\gw-workspace\\temp\\zkvtPP4O3wwnaE8qEhqdT4NNVt.tar is not a regular file or directory",
  "history_begin_time" : 1646115619324,
  "history_end_time" : 1646115631718,
  "history_notes" : null,
  "history_process" : "48iyth",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "a1h52jx43qv",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_random_forest.py",
  "history_output" : "Received unknown response code",
  "history_begin_time" : 1646115632698,
  "history_end_time" : 1646115633142,
  "history_notes" : null,
  "history_process" : "bembwt",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "gaujunbx4l5",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/training_autokeras.py",
  "history_output" : "C:\\Users\\didar\\gw-workspace\\temp\\zkvtPP4O3wwnaE8qEhqdT4NNVt.tar is not a regular file or directory",
  "history_begin_time" : 1646115619404,
  "history_end_time" : 1646115631683,
  "history_notes" : null,
  "history_process" : "l0t844",
  "host_id" : "w6jk5o",
  "indicator" : "Failed"
},{
  "history_id" : "2yky11meoio",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/prediction_autokeras.py",
  "history_output" : "Too many logins for 'mislam25'.\nLast login: Tue Mar  1 01:20:32 2022 from 71.191.159.128\n\n",
  "history_begin_time" : 1646115632544,
  "history_end_time" : 1646115643363,
  "history_notes" : null,
  "history_process" : "zmy3vb",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "93e38em8wcc",
  "history_input" : "#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=python-gpu\n#SBATCH --output=python-gpu.%j.out\n#SBATCH --error=python-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1                 # up to 128; \n#SBATCH --gres=gpu:A100.40gb:1              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL \n#SBATCH --time=0-00:20:00                   # set to 1hr; please choose carefully\n\nset echo\numask 0027\n\n#module load python                          # load the default python version\n\npython cmaq/model_comparison.py",
  "history_output" : "python: can't open file '/home/mislam25/gw-workspace/zkvtPP4O3wwnaE8qEhqdT4NNVt/cmaq/model_comparison.py': [Errno 2] No such file or directory\n",
  "history_begin_time" : 1646115671518,
  "history_end_time" : 1646115696970,
  "history_notes" : null,
  "history_process" : "z1t6b2",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
},{
  "history_id" : "i69l2b4kx11",
  "history_input" : "\n## importing necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\n# importing data\npred=pd.read_csv('/home/mislam25/cmaq/prediction/prediction_xgboost.csv')\ntime_=pred['YYYYMMDDHH'].unique()\ndfs = dict(tuple(pred.groupby('YYYYMMDDHH'))) # grouping the data by YYMMDDHH\n\nfor t in time_:\n  subset=dfs[t]\n  fig = px.density_mapbox(subset, lat='Latitude', lon='Longitude', z='prediction', radius=10,\n                        center=dict(lat=32.777701, lon=-111.358871), zoom=6.5,\n                        mapbox_style=\"stamen-terrain\")\n  # Set figure title\n  fig.update_layout(title_text=\"Date-time: \"+str(t)+\"(YY:MM:DD:HH)\", title_x=0.5)\n  # saving figures\n  fig.write_image(\"/home/mislam25/cmaq/maps/\"+\"pred\"+str(t)+\".png\")",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/mislam25/gw-workspace/zkvtPP4O3wwnaE8qEhqdT4NNVt/prediction_visualization.py\", line 8, in <module>\n    pred=pd.read_csv('/home/mislam25/cmaq/prediction/prediction_xgboost.csv')\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n    self._engine = self._make_engine(self.engine)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n    self._open_handles(src, kwds)\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n    self.handles = get_handle(\n  File \"/home/mislam25/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mislam25/cmaq/prediction/prediction_xgboost.csv'\n",
  "history_begin_time" : 1646115697084,
  "history_end_time" : 1646115752345,
  "history_notes" : null,
  "history_process" : "uzx599",
  "host_id" : "w6jk5o",
  "indicator" : "Done"
}]
