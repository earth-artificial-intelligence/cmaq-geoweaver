[{
  "id" : "6up921",
  "name" : "preparing_cmaq_training_data",
  "description" : null,
  "code" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\nfrom datetime import date, timedelta\n\nsdate = date(2022, 3, 1)   # start date\nedate = date(2021, 6, 1)   # end date\n\ndelta = edate - sdate       # as timedelta\n\nfor i in range(delta.days + 1):\n    day = sdate + timedelta(days=i)\n    list_day=day.strftime('%Y%m%d')\n    days.append(list_day)\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=(\n    [] for i in range(19))\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv('/groups/ESS/aalnaim/cmaq/training_data.csv',index=False)\n\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "xpdg66",
  "name" : "observation",
  "description" : null,
  "code" : "\nimport xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import datetime, timedelta, date\n# home directory\nhome = str(Path.home())\n\n\ndays=[]\n\nbase = datetime.today() - timedelta(days=2)\ndate_list = [base - timedelta(days=x) for x in range(2)]\ndays = [date.strftime('%Y%m%d') for date in date_list]\n\n\ntime = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for t in time:\n    files = \"/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X/\"+\"AQF5X_Hourly_\"+i+t+\".dat\"\n    with open(files, 'r') as file:\n      text = file.read()\n    new_string = text.replace('\"', '')\n\n    outF = open(\"/groups/ESS/aalnaim/cmaq/observation/AQF5X_Hourly_\"+i+t+\".txt\", \"w\")\n    for line in new_string:\n      # write line to output file\n      outF.write(line)\n    outF.close()",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "xlayd5",
  "name" : "processing_observation_data",
  "description" : null,
  "code" : "## importing necessary libraries\nimport glob\nimport pandas as pd\nfrom pathlib import Path\nimport numpy as np\nfrom datetime import datetime, date, timedelta\n# home directory\nhome = str(Path.home())\n\ndays=[]\n\nbase = datetime.today() - timedelta(days=2)\ndate_list = [base - timedelta(days=x) for x in range(2)]\ndays = [date.strftime('%Y%m%d') for date in date_list]\n\n    \ndata_frame = pd.DataFrame()\nmerged=[]\ndate_time=[]\ntime = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor d in days:\n  for t in time:\n\n    files=glob.glob(\"/groups/ESS/aalnaim/cmaq/observation/AQF5X_Hourly_\"+d+t+\".txt\")\n    for file in files:\n      print(file)\n\n      data = np.loadtxt(file, skiprows=1,dtype='str')\n      dt=d+t\n      print(dt)\n      dt=np.tile(dt,len(data)) # 2822 total station number\n      date_time.append(dt)\n      merged.append(data)\ndata_frame = np.concatenate(merged)\ndata_frame =np.delete(data_frame, np.s_[4:9], axis=1) \n#data_frame.drop(data_frame.columns[[4, 5,6,7,8]], axis = 1, inplace = True)\ndf = pd.DataFrame(data_frame, columns = ['StationID','Latitude','Longitude','AirNOW_O3'])\nprint(len(days))\nprint(df.shape)\ndt = np.concatenate(date_time)\nprint(dt.shape)\n#dt = np.concatenate(date_time)\n#print(len(dt))\ndff=df.replace(',','', regex=True)\ndff['YYYYMMDDHH'] = dt.tolist()\ndff.to_csv(\"/groups/ESS/aalnaim/cmaq/observation.csv\",index=False)\n\n\n\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "argv3i",
  "name" : "training_data",
  "description" : null,
  "code" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/training_data.csv\")\nobs=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/observation.csv\")\nref_stations=pd.read_csv(\"/groups/ESS/mislam25/station_cmaq_location.csv\")\n\nnew_df = pd.merge(ref_stations, cmaq,  how='left', left_on=['Latitude_y','Longitude_y'], right_on = ['Latitude','Longitude'])\nnew_df.to_csv(home+\"/cmaq/subset.csv\")\nfinal = pd.merge(obs, new_df,  how='left', left_on=['Latitude','Longitude','YYYYMMDDHH'], right_on = ['Latitude_x','Longitude_x','YYYYMMDDHH'])\n#final.to_csv(home+\"/cmaq/subset.csv\",index=False)\nfinal=final.drop_duplicates(keep=False)\ntraining_data = final.loc[:,~final.columns.duplicated()]\n# dropping unnecessary variables\ntraining_data['YYYYMMDDHH'] = training_data['YYYYMMDDHH'].map(str)\ntraining_data['month'] = training_data['YYYYMMDDHH'].str[4:6]\ntraining_data['day'] = training_data['YYYYMMDDHH'].str[6:8]\ntraining_data['hours'] = training_data['YYYYMMDDHH'].str[8:10]\n\nnew_df=training_data.drop(['StationID','Latitude_y','Longitude_y','YYYYMMDDHH'],axis=1)\nfinal_df = new_df[new_df.AirNOW_O3!= -999]\nfinal_df.to_csv(\"/groups/ESS/aalnaim/cmaq/training.csv\",index=False)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "l8vlic",
  "name" : "rf_prediction",
  "description" : null,
  "code" : "\n# Importing necessary libraries\nimport pandas as pd\nimport pickle\nfrom pathlib import Path\nfrom time import sleep\n\n# home directory\nhome = str(Path.home())\n# importing data\nfinal=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/testing.csv\")\nprint(final.head())\nX = final.drop(['YYYYMMDDHH','Latitude','Longitude',],axis=1)\n# defining  testing variables\n# processing test data\n\n# load the model from disk\nfilename = '/groups/ESS/aalnaim/cmaq/models/rfOLD_Jun13.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\n\n# making prediction\npred = loaded_model.predict(X)\n\n# adding prediction values to test dataset\nfinal['prediction'] = pred.tolist()\n\nfinal = final[['Latitude', 'Longitude','YYYYMMDDHH','prediction']]\n# saving the dataset into local drive\nfinal.to_csv('/groups/ESS/aalnaim/cmaq/prediction_files/prediction_rf.csv',index=False)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "g7endl",
  "name" : "cmaq_rf_vis",
  "description" : null,
  "code" : "# importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport geopandas as gpd\nimport cmaps\nfrom datetime import datetime\n\nimport imageio\nimport glob\nimport os\n\n\nmpl.rcParams['font.size'] = 25\n#os.system('module load ffmpeg') # Uncomment if running on HOPPER\n\n# home directory\nhome = str(Path.home())\n\n# Delete previous .tif images only (not folder) to reduce space if folder and files exist already.\nif Path(home + \"/cmaq/prediction_maps/\"):\n    for file in Path(home + \"/cmaq/prediction_maps/\").glob(\"*\"):\n        if file.is_file():\n          [f.unlink() for f in Path(home + \"/cmaq/prediction_maps/\").glob(\"*\") if f.is_file()] \n\n# importing data\ndf = raw_df = pd.read_csv(home + '/cmaq/prediction_files/prediction_rf.csv')\n\ntime_ = df['YYYYMMDDHH'].unique()\ndfs = dict(tuple(df.groupby('YYYYMMDDHH')))  # grouping the data by YYMMDDHH\n\ncmap = cmaps.WhiteBlueGreenYellowRed[0:262:12]\n\ncount = 0\n\nfor t in time_:\n  \n    dateObj = datetime.strptime(str(t), \"%Y%m%d%H\")\n    print(t)\n    \n    single_hour_df = raw_df.loc[raw_df['YYYYMMDDHH']==t]\n    #print(single_hour_df)\n    print(\"max: \", single_hour_df[\"prediction\"].max())\n    print(\"min: \", single_hour_df[\"prediction\"].min())\n    print(\"median: \", single_hour_df[\"prediction\"].median())\n    print(\"mean: \", single_hour_df[\"prediction\"].mean())\n    \n    count += 1\n    \n    df = dfs[t]\n    \n    gdf = gpd.GeoDataFrame(\n        df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n    gdf = gdf.set_crs(\"EPSG:4326\")\n    #gdf = gdf.to_crs(\"+proj=lcc +lat_1=2 +lat_2=33.000 +lat_0=45.000 +lon_0=-97.000 +x_0=-97.000 +y_0=40.000 +datum=NAD83 +units=m +no_defs\")\n\n    gdf.plot(column='prediction', legend=True, figsize=(20, 18),\n         cmap=cmap, vmin=0,vmax=80,)\n    \n    plotTitle = datetime.strftime(dateObj, \"%Y-%m-%d (Time: %H)\")\n    plt.title(plotTitle, fontdict={'fontsize': 35})\n    plt.savefig(home + \"/cmaq/prediction_maps/CMAQ_\" + str(t) + \".tif\")\n    \n    if count > 5:\n         break;\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "wny2dz",
  "name" : "rf_pyCaret_gpu",
  "description" : null,
  "code" : "echo \"#!/bin/bash\n#SBATCH --partition=gpuq                    # the DGX only belongs in the 'gpu'  partition\n#SBATCH --qos=gpu                           # need to select 'gpu' QoS\n#SBATCH --job-name=cmaq-gpu\n#SBATCH --output=cmaq-gpu.%j.out\n#SBATCH --error=cmaq-gpu.%j.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=64                 # up to 128;\n#SBATCH --gres=gpu:A100.40gb:4              # up to 8; only request what you need\n#SBATCH --mem-per-cpu=3500M                 # memory per CORE; total memory is 1 TB (1,000,000 MB)\n#SBATCH --export=ALL\n#SBATCH --time=0-04:00:00                   # set to 1hr; please choose carefully\nset echo\numask 0027\n# to see ID and state of GPUs assigned\nnvidia-smi\n\nmodule load python\nsource /home/aalnaim/CMAQAI/bin/activate\n\ncat <<EOF >>/groups/ESS/aalnaim/cmaq/rf_pyCaret.py\n# Write first python in Geoweaver# NASA GEOWEAVER\n# CMAQ-AI Model: Training Voting-XGBoost model\n\n# Importing necessary libraries\nimport pandas as pd\nimport sklearn\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost.sklearn import XGBRegressor\nimport pickle\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\n\n# importing data\nfinal=pd.read_csv('/groups/ESS/mislam25/processed_training/agg_data_2021_03_15_to_22_4_30.csv')\nprint(final.head())\nfinal=final.dropna()\n\n# Processing training  data\nX = final.drop(['AirNOW_O3','Latitude_x','Longitude_x'],axis=1)\ny = final['AirNOW_O3']\n\nrf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n                      max_samples=None, min_impurity_decrease=0.0,\n                      min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      n_estimators=100, n_jobs=-1, oob_score=False,\n                      random_state=3086, verbose=0, warm_start=False)\n\nrf.fit(X, y)\n\n# save the model to disk\nfilename = '/groups/ESS/aalnaim/cmaq/models/rf_Jun14.sav'\n#filename = 'D:/Research/CMAQ/local_test/xgboost.sav'\npickle.dump(rf, open(filename, 'wb'))\nEOF\npython /groups/ESS/aalnaim/cmaq/rf_pyCaret.py\" >> /groups/ESS/aalnaim/cmaq/cmaq_gpu.slurm\n\nsbatch /groups/ESS/aalnaim/cmaq/cmaq_gpu.slurm\n\nsleep 20",
  "lang" : "shell",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "3asyzj",
  "name" : "processing_test_netcdf",
  "description" : null,
  "code" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nimport datetime\nfrom datetime import timedelta\n# home directory\nhome = str(Path.home())\n\nbase = datetime.datetime.today() - timedelta(days=2)\ndate_list = [base - timedelta(days=x) for x in range(3)]\ndays = [date.strftime('%Y%m%d') for date in date_list]\n\n# nc file need to correspond to the same prediction date in \"/groups/ESS/aalnaim/cmaq/prediction_files/prediction_rf_Jun13.csv\"\ndf_cdf = xr.open_dataset(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/COMBINE3D_ACONC_v531_gcc_AQF5X_\"+days[2]+\"_extracted.nc\")\n\ndf_csv = pd.read_csv(\"/groups/ESS/aalnaim/cmaq/prediction_files/prediction_rf.csv\")\ndf_csv['YYYYMMDDHH'] = df_csv['YYYYMMDDHH'].astype(str)\ndf_filt = df_csv[df_csv['YYYYMMDDHH'].str.contains(days[1]+\"|\"+days[0], case = False, regex=True)]\ndf_filt = df_filt[(df_filt['YYYYMMDDHH'] > days[1]+'11') & (df_filt['YYYYMMDDHH'] < days[0]+'12')]\n\n# Reshape \"prediction/Latitude/Longitude\" columns to (TSTEP, ROW, COL), these lines will reshape data into (24, 265, 442)\nreshaped_prediction = np.atleast_3d(df_filt['prediction']).reshape(-1, 265, 442)\n\n# Remove \"LAY\" Dimension in O3 variable already in nc file.\nreduced_dim = df_cdf['O3'].sel(LAY=1, drop=True)\n# Swap values from original nc file with new prediction data\nreduced_dim.values = reshaped_prediction\n\n# Apply changes to data variable in nc file\ndf_cdf['O3'] = (['TSTEP', 'ROW', 'COL'], reshaped_prediction)\n\ndf_cdf.to_netcdf('/groups/ESS/aalnaim/cmaq/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+days[1]+'_ML_extracted.nc')\n\nprint('Saved updated netCDF file: /groups/ESS/aalnaim/cmaq/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_'+days[1]+'_ML_extracted.nc')",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "9xdvh6",
  "name" : "environment_setting",
  "description" : null,
  "code" : "# NASA-GEOWEAVER: Environment setting\n\nimport os\nimport sys\nimport subprocess\nimport pkg_resources\n\nwith open('requirements.txt','w') as out:\n  out.write('''\nabsl-py==1.0.0\naffine==2.3.1\nasttokens==2.0.5\nastunparse==1.6.3\nattrs==21.4.0\nautokeras==1.0.18\nbackcall==0.2.0\ncachetools==5.0.0\ncertifi==2021.10.8\ncftime==1.6.0\ncharset-normalizer==2.0.12\nclick==8.1.3\nclick-plugins==1.1.1\ncligj==0.7.2\ncmaps==1.0.5\ncycler==0.11.0\ndecorator==5.1.1\nearthpy==0.9.4\nexecuting==0.8.3\nFiona==1.8.21\nflatbuffers==2.0\nfonttools==4.29.1\ngast==0.5.3\ngeopandas==0.10.2\nglob2==0.7\ngoogle-auth==2.6.0\ngoogle-auth-oauthlib==0.4.6\ngoogle-pasta==0.2.0\ngrpcio==1.44.0\nh5py==3.6.0\nidna==3.3\nimageio==2.19.0\nimageio-ffmpeg==0.4.7\nimportlib-metadata==4.11.2\nipython==8.1.1\njedi==0.18.1\njoblib==1.1.0\nkaleido==0.2.1\nkeras==2.8.0\nKeras-Preprocessing==1.1.2\nkeras-tuner==1.1.0\nkiwisolver==1.3.2\nkt-legacy==1.0.4\nlibclang==13.0.0\nMarkdown==3.3.6\nmatplotlib==3.5.1\nmatplotlib-inline==0.1.3\nmunch==2.5.0\nnetCDF4==1.5.8\nnetworkx==2.8\nnumpy==1.22.2\noauthlib==3.2.0\nopencv-python==4.5.5.64\nopt-einsum==3.3.0\npackaging==21.3\npandas==1.4.1\nparso==0.8.3\npathlib==1.0.1\npathlib2==2.3.7.post1\npexpect==4.8.0\npickleshare==0.7.5\nPillow==9.0.1\nplotly==5.7.0\nprompt-toolkit==3.0.28\nprotobuf==3.19.4\nptyprocess==0.7.0\npure-eval==0.2.2\npyasn1==0.4.8\npyasn1-modules==0.2.8\nPygments==2.11.2\npyparsing==3.0.7\npyproj==3.3.1\npython-dateutil==2.8.2\npytz==2021.3\nPyWavelets==1.3.0\nrasterio==1.2.10\nrequests==2.27.1\nrequests-oauthlib==1.3.1\nrsa==4.8\nscikit-image==0.19.2\nscikit-learn==1.0.2\nscipy==1.8.0\nseaborn==0.11.2\nShapely==1.8.2\nsix==1.16.0\nsklearn==0.0\nsnuggs==1.4.7\nstack-data==0.2.0\ntenacity==8.0.1\ntensorboard==2.8.0\ntensorboard-data-server==0.6.1\ntensorboard-plugin-wit==1.8.1\ntensorflow==2.8.0\ntensorflow-gpu==2.8.0\ntensorflow-io-gcs-filesystem==0.24.0\ntermcolor==1.1.0\ntf-estimator-nightly==2.8.0.dev2021122109\nthreadpoolctl==3.1.0\ntifffile==2022.5.4\ntraitlets==5.1.1\ntyping_extensions==4.1.1\nurllib3==1.26.8\nwcwidth==0.2.5\nWerkzeug==2.0.3\nwrapt==1.13.3\nxarray==2022.3.0\nxgboost==1.6.0\nzipp==3.7.0''')\n  \npython = sys.executable\nsubprocess.check_call([python, '-m', 'pip', 'install', '-r', 'requirements.txt'], stdout=subprocess.DEVNULL)\n    #subprocess.check_call(\n        #[python, '-m', 'conda', 'install', '-c','conda-forge','xgboost'],\n      #stdout=subprocess.DEVNULL)\n\n\n################################\n#  END OF PACKAGES Installation  #\n\n\n# Creating directoris \nfrom pathlib import Path\nhome = str(Path.home())\nfolders = ['cmaq/exploratory_analysis', 'cmaq/prediction_maps', 'cmaq/prediction_files','cmaq/models','cmaq/observation']\nfor folder in folders:\n  paths=Path(home+'/'+folder)\n  paths.mkdir(parents=True,exist_ok=True)\n  \n  ###############################\n  # END OF DIRECTORY CREATION #",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "ex3vh9",
  "name" : "processing_test_data",
  "description" : null,
  "code" : "import xarray as xr\nimport pandas as pd\nimport glob, os\nimport numpy as np\nfrom pathlib import Path\nimport datetime\nfrom datetime import timedelta\n# home directory\nhome = str(Path.home())\n\nbase = datetime.datetime.today() - timedelta(days=2)\ndate_list = [base - timedelta(days=x) for x in range(2)]\ndays = [date.strftime('%Y%m%d') for date in date_list]\n\naa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo1,pp,qq,rr,ss=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n#ff=[]\n# k = time dimension - start from 12 to match with data\nt = [12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5,6,7,8,9,10,11]\nfor i in days:\n  print(i)\n  # read cmaq results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20210315 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  else:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/CCTMout/12km/POST/\"+\"COMBINE3D_ACONC_v531_gcc_AQF5X_\"+i+\"_extracted.nc\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# O3 variable\n  \t# O3 variable\n      oo=df.variables['O3'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)      \n      aa.append(o3tp)\n  \t# NO2\n      oo=df.variables['NO2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      bb.append(o3tp)\n      # CO\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      cc.append(o3tp)\n\n      # PM25_CO\n      oo=df.variables['PM25_OC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ee.append(o3tp)\n      \n      \n  # read emission results\n  # old files before 20210315 are not in diractory. must choose later date.\n  if int(i)>=20191231 and int(i)<=20210902:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_nobeis_2016fh_16j.ncf\")\n  elif int(i)==20220303:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n\n# set todays date if they don't change dataformate    \n#  else if int(i)>=20220313 and int(i)<=int(today):\n  elif int(i)>=20220313 and int(i)<=20220331:\n    files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/emis2021/12km/all/\"+\"emis_mole_all_\"+i+\"_AQF5X_cmaq_cb6ae7_2017gb_17j.ncf\")\n  for j in files:\n\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['CO'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ff.append(o3tp)\n\n      # NO\n#      oo=df.variables['NO'][:].values[k,0]\n#      oo3=np.ravel(oo)\n#      o3tp=np.transpose(oo3)\n#      o3tp=np.round(o3tp)\n#      hh.append(o3tp)  \n      \n# read mcip results \n# date must be later of 20210101\n  files = glob.glob(\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/\"+\"METCRO2D_\"+i+\".nc\")\n  for j in files:\n    df = xr.open_dataset(j)\n    for k in t:\n  \t# CO variable\n      oo=df.variables['PRSFC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ii.append(o3tp)\n  \t# NO2\n      oo=df.variables['PBL'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      jj.append(o3tp)\n      # NO\n      oo=df.variables['TEMP2'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      kk.append(o3tp)\n            # NO\n      oo=df.variables['WSPD10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      ll.append(o3tp)\n            # NO\n      oo=df.variables['WDIR10'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      mm.append(o3tp)\n\n            # NO\n      oo=df.variables['RGRND'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      oo1.append(o3tp)\n\n        \t# NO2\n      oo=df.variables['CFRAC'][:].values[k,0]\n      oo3=np.ravel(oo)\n      o3tp=np.transpose(oo3)\n      o3tp=np.round(o3tp)\n      rr.append(o3tp)\n      \n      \ncmaq_O3=list(np.concatenate(aa).flat) \nprint(len(cmaq_O3))\ndel aa\ncmaq_NO2=list(np.concatenate(bb).flat) \nprint(len(cmaq_NO2))\ndel bb\ncmaq_CO=list(np.concatenate(cc).flat) \nprint(len(cmaq_CO))\ndel cc\n\ncmaq_PM25_CO=list(np.concatenate(ee).flat)\n\ndel ee\nCO_emi=list(np.concatenate(ff).flat) \nprint(len(CO_emi))\ndel ff\n\n#NO_emi=list(np.concatenate(hh).flat) \n#del hh\nPRSFC=list(np.concatenate(ii).flat) \ndel ii\nPBL=list(np.concatenate(jj).flat) \ndel jj\nTEMP2=list(np.concatenate(kk).flat) \ndel kk\nWSPD10=list(np.concatenate(ll).flat) \ndel ll\nWDIR10=list(np.concatenate(mm).flat)\ndel mm\n\nRGRND=list(np.concatenate(oo1).flat) \ndel oo1\n#RN=list(np.concatenate(pp).flat)\n#del pp\n#RC=list(np.concatenate(qq).flat)\n#del qq\nCFRAC=list(np.concatenate(rr).flat)\nprint(len(CFRAC))\ndel rr\n\n## selecting lat and long\ndf = xr.open_dataset('/home/yli74/scripts/plots/2020fire/GRIDCRO2D')\nlat_1 = df.variables['LAT'][:].values[0,0]\nlat_flt=np.ravel(lat_1)\n# need to manipulate 48 values if the next day data is available\nLAT=np.tile(lat_flt,len(days)*24)\nprint(len(LAT))\n# long\nlon_1 = df.variables['LON'][:].values[0,0]\nlon_flt=np.ravel(lon_1)\n# need to manipulate 48 values if the next day data is available\nLON=np.tile(lon_flt,len(days)*24)\nprint(len(LON))\n# creating dataframe\n\n## creatime date-time dimension\n# date-time dimension for today\ntime0=[]\nt = ['12','13','14','15','16','17','18','19','20','21','22','23','00','01','02','03','04','05','06','07','08','09','10','11']\nfor i in days:\n  for j in t:\n    time_0=np.full((265,442),i+j)\n    time0.append(time_0)\nYYMMDDHH=list(np.concatenate(time0).flat)  \nprint(len(YYMMDDHH))\n\n\n# saving variables\ndat=pd.DataFrame({'Latitude':LAT,'Longitude':LON,'YYYYMMDDHH':YYMMDDHH,'CMAQ12KM_O3(ppb)':cmaq_O3,'CMAQ12KM_NO2(ppb)':cmaq_NO2,'CMAQ12KM_CO(ppm)':cmaq_CO,'CMAQ_OC(ug/m3)':cmaq_PM25_CO,'CO(moles/s)':CO_emi,'PRSFC(Pa)':PRSFC,'PBL(m)':PBL,'TEMP2(K)':TEMP2,'WSPD10(m/s)':WSPD10,'WDIR10(degree)':WDIR10,'RGRND(W/m2)':RGRND,'CFRAC':CFRAC})\nprint(dat.head())\ndat.to_csv('/groups/ESS/aalnaim/cmaq/test_data.csv',index=False)\n\n\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "b8uv5z",
  "name" : "test_data",
  "description" : null,
  "code" : "import pandas as pd\nfrom pathlib import Path\n\n# home directory\nhome = str(Path.home())\ncmaq=pd.read_csv(\"/groups/ESS/aalnaim/cmaq/test_data.csv\")\n\n# dropping unnecessary variables\ncmaq['YYYYMMDDHH'] = cmaq['YYYYMMDDHH'].map(str)\ncmaq['month'] = cmaq['YYYYMMDDHH'].str[4:6]\ncmaq['day'] = cmaq['YYYYMMDDHH'].str[6:8]\ncmaq['hours'] = cmaq['YYYYMMDDHH'].str[8:10]\n\n#new_df=cmaq.drop(['YYYYMMDDHH'],axis=1)\ncmaq.to_csv(\"/groups/ESS/aalnaim/cmaq/testing.csv\",index=False)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "iicy7w",
  "name" : "generate_images_ncl",
  "description" : null,
  "code" : "#!/bin/bash\n\n# Setting env variables\nexport YYYYMMDD_POST=20220612 #This needs to be auto date `date -d \"-2 day ${1}\" +%Y%m%d`\nexport stdate_post=2022-06-12 #This needs to be auto date\nexport eddate_post=2022-06-13 #This needs to be auto date\n\nexport postdata_dir=\"/groups/ESS/aalnaim/cmaq/prediction_nc_files\"\nexport mcip_dir=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km\"\nexport dir_graph=\"/groups/ESS/aalnaim/cmaq/plots\"\n\nmodule load ncl\n\ncat <<EOF >>/groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3.ncl\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\n\ndate = getenv(\"YYYYMMDD_POST\")\nd1 = getenv(\"stdate_post\")\nd2 = getenv(\"eddate_post\")\n\n;print(\"Passed Date: \"+date)\n\n;aconc_dir = getenv(\"postdata_dir\")\ngrid_dir = getenv(\"mcip_dir\")\nplot_dir = getenv(\"dir_graph\")\n\ncdf_file1 = addfile(\"/groups/ESS/aalnaim/cmaq/prediction_nc_files/COMBINE3D_ACONC_v531_gcc_AQF5X_20220612_ML_extracted.nc\",\"r\")\ncdf_file= addfile(grid_dir+\"/GRIDCRO2D_\"+date+\".nc\",\"r\")\n\nptime = (/\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"00\",\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\"/)\n\ntime = cdf_file1->TFLAG(:,0,:)\no3 = cdf_file1->O3(:,:,:) ;ppb\n;pm25 = cdf_file1->PM25_TOT(:,0,:,:)\n\n\nnt = dimsizes(o3(:,0,0))\nny = dimsizes(o3(0,:,0))\nnx = dimsizes(o3(0,0,:))\n\nprint(nt+\" \"+ny+\" \"+nx)\nprint(max(o3))\nprint(min(o3))\nprint(avg(o3))\n\n;print(max(pm25))\n;print(min(pm25))\n;print(avg(pm25))\n\n;print(time)\n\nlat = cdf_file->LAT(0,0,:,:)\nlon = cdf_file->LON(0,0,:,:)\n\no3@lat2d = lat\no3@lon2d = lon\n\nres = True\nres@gsnMaximize = True                ; maximize pot in frame\nres@gsnFrame = False               ; don't advance frame\nres@gsnDraw = False\n;res@gsnSpreadColors = True\nres@lbLabelAutoStride = True\n;res@lbBoxLinesOn = False\nres@pmLabelBarHeightF = 0.1\nres@pmLabelBarWidthF = 0.5\nres@cnFillOn=True\n;res@cnMonoFillPattern=True\n;res@cnMonoLineColor=True\nres@cnLinesOn=False\n;res@pmLabelBarDisplayMode=\"never\"\nres@gsnLeftString  = \"\";\nres@gsnRightString = \"\"\n\nres@mpLimitMode = \"LatLon\"\nres@mpMinLonF = -120 ;min(lon)+0.2\nres@mpMaxLonF = -70 ;max(lon)-0.2\nres@mpMinLatF = 25 ;min(lat)+0.05\nres@mpMaxLatF = 50 ;max(lat)-0.05\nres@mpDataBaseVersion = \"MediumRes\"\n;res@tiMainString = times(it)\nres@mpDataBaseVersion       = \"MediumRes\"\nres@mpDataSetName           = \"Earth..4\"\nres@mpAreaMaskingOn         = True\nres@mpOutlineBoundarySets = \"GeophysicalAndUSStates\"\nres@mpOutlineSpecifiers=\"United States : States\"\nres@mpLandFillColor         = \"white\"\nres@mpInlandWaterFillColor  = \"white\"\nres@mpOceanFillColor        = \"white\"\nres@mpGeophysicalLineColor    = \"Black\"\nres@mpGeophysicalLineThicknessF = 1.5\n\n;res@gsnSpreadColors         = True\nres@lbLabelAutoStride       = True\nres@lbLabelFont             = 25\nres@tiXAxisFont             = 25\nres@pmTickMarkDisplayMode   = \"Always\"\nres@tmXBLabelFont           = 25\nres@tmXBLabelFontHeightF    = 0.013\nres@tmXBLabelDeltaF         = -0.5\nres@tmYLLabelFont           = 25\nres@tmYLLabelFontHeightF    = 0.013\nres@tmXBLabelDeltaF         = -0.5\nres@tmXTLabelsOn            = False\nres@tmXTLabelFont           = 25\nres@tmXTLabelFontHeightF    = 0.013\nres@tmYRLabelsOn            = False\nres@tmYRLabelFont           = 25\nres@tmYRLabelFontHeightF    = 0.013\n\n\nres@mpProjection           = \"LambertConformal\" ;\"CylindricalEquidistant\"\nres@mpLambertParallel1F    = 33.\nres@mpLambertParallel2F    = 45.\nres@mpLambertMeridianF     = -98.\n\nres@cnLevelSelectionMode = \"ManualLevels\"\nres@cnMinLevelValF          = 0.\nres@cnMaxLevelValF          = 80\nres@cnLevelSpacingF         = 4\n\nres@txFont   = \"times-roman\"\nres@tiMainFont   = \"times-roman\"\n\ndo it = 0, nt-1\n  if (it .lt. 12) then\n    pdate=d1\n  else\n    pdate=d2\n  end if\n\n  pname=plot_dir+\"/testPlot_\"+pdate+\"_\"+ptime(it)\n  wks = gsn_open_wks(\"png\",pname)\n  gsn_define_colormap(wks, \"WhiteBlueGreenYellowRed\")\n\n  res@tiMainString = pdate+\" \"+ptime(it)+\" UTC O~B~3~N~ Forecast (ppbV)\"\n  plot = gsn_csm_contour_map(wks,o3(it,:,:),res)\n  draw(plot)\n  frame(wks)\n  delete(wks)\n  system(\"composite -geometry 100x70+900+900 /groups/ESS/aalnaim/cmaq/mason-logo-green.png \"+pname+\".png \"+pname+\".png\")\nend do\ndelete(res)\n\nend\nEOF\n\n\nncl /groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3.ncl\n\n# convert -delay 100 *.png 20220613_20220614.gif\nconvert -delay 100 /groups/ESS/aalnaim/cmaq/plots/testPlot*.png /groups/ESS/aalnaim/cmaq/plots/Map_$YYYYMMDD_POST_correct.gif\n\nif [ $? -eq 0 ]; then\n    echo \"Generating images/gif Completed Successfully\"\n\techo \"Removing ncl file: geoweaver_plot_daily_O3.ncl...\"\n\trm /groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3.ncl\nelse\n    echo \"Generating images/gif Failed!\"\n    echo \"Removing ncl file: geoweaver_plot_daily_O3.ncl...\"\n\trm /groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3.ncl\nfi\n",
  "lang" : "shell",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "fsk7f2",
  "name" : "evaluate_prediction_ncl",
  "description" : null,
  "code" : "#!/bin/bash\n\n# Setting env variables\nexport YYYYMMDD_POST=20220612 #This needs to be auto date\nexport wfname=\"/groups/ESS/aalnaim/cmaq/results/geoweaver_evalution_\"$YYYYMMDD_POST\"_results.txt\"\n\nexport obs_dir_NCL=\"/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X\"\nexport ofname=\"/AQF5X_Hourly_\"\n\nexport postdata_dir=\"/groups/ESS/aalnaim/cmaq/prediction_nc_files/\"\n\nexport mfname=\"COMBINE3D_ACONC_v531_gcc_AQF5X_20220612_ML_extracted.nc\"\n\nexport grid_fname=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km/GRIDCRO2D_20220612.nc\" #This needs to be auto date\n\nexport dx=12000\n\nmodule load ncl\n\ncat <<EOF >>/groups/ESS/aalnaim/cmaq/geoweaver_eva_daily_O3.ncl\n\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\nsdate=getenv(\"YYYYMMDD_POST\")\nwfname=getenv(\"wfname\")\nobs_dir=getenv(\"obs_dir_NCL\")\nofname=getenv(\"ofname\")\nmod_dir=getenv(\"postdata_dir\")\nmfname=getenv(\"mfname\")\ndkm=tofloat(getenv(\"dx\"))\ngrid_fname=(getenv(\"grid_fname\"))\n\nmaxdist=dkm/90000.0*1.414\nmaxarea=0.25\nthd=70\n\n;-----read model lat lon------\n;read lat lon\nf1 = addfile(grid_fname,\"r\")\nmlat = f1->LAT(0,0,:,:)\nmlon = f1->LON(0,0,:,:)\ndelete(f1)\nmlat1d = ndtooned(mlat)\nmlon1d = ndtooned(mlon)\ndelete([/mlat,mlon/])\n\n;-----read cmaq results-----\nf2 = addfile(mod_dir+mfname,\"r\")\nmO3 = f2->O3(:,:,:) ;ppb\n\n\nnt = dimsizes(mO3(:,0,0))\nny = dimsizes(mO3(0,:,0))\nnx = dimsizes(mO3(0,0,:))\n\nm8O3 = new((/17,ny,nx/),\"double\")\nm8maxO3 = new((/ny,nx/),\"double\")\n\ndo ih=0,16\n  m8O3(ih,:,:)=dim_avg_n(mO3(ih:ih+7,:,:),0)\nend do\nm8maxO3 = dim_max_n(m8O3,0) ;type double\nmO31d_d=ndtooned(m8maxO3) ; type double\nmO31d=tofloat(mO31d_d)\n\ndelete([/f2,mO3,m8O3,m8maxO3/])\n\n;-----read obs-----\nsyyyy1=str_get_cols(sdate,0,3)\nsmm1=str_get_cols(sdate,4,5)\nsdd1=str_get_cols(sdate,6,7)\n\nymd=jul2greg(greg2jul(tointeger(syyyy1),tointeger(smm1),tointeger(sdd1),-1)+1)\nsyyyy2=tostring_with_format(ymd(0),\"%0.4i\")\nsmm2=tostring_with_format(ymd(1),\"%0.2i\")\nsdd2=tostring_with_format(ymd(2),\"%0.2i\")\n\ntolat=(/-999.0/) ;set the first data to 0\ntolon=tolat\ntoO3=tolat\n\ndo ih=12,35\n  if (ih.lt.24) then\n    shh=tostring_with_format(ih,\"%0.2i\")\n    syyyy=syyyy1\n    smm=smm1\n    sdd=sdd1\n  else\n    shh=tostring_with_format(ih-24,\"%0.2i\")\n    syyyy=syyyy2\n    smm=smm2\n    sdd=sdd2\n  end if\n  data=asciiread(obs_dir+ofname+syyyy+smm+sdd+shh+\".dat\",-1,\"string\")\n  xx=array_append_record(tolat,stringtofloat(str_get_field(data(1::), 2,\",\")),0)\n  yy=array_append_record(tolon,stringtofloat(str_get_field(data(1::), 3,\",\")),0)\n  zz=array_append_record(toO3,stringtofloat(str_get_field(data(1::), 4,\",\")),0)\n  delete([/tolat,tolon,toO3/])\n  tolat=xx\n  tolon=yy\n  toO3=zz\n  delete([/xx,yy,zz/])\n  delete(data)\nend do\n\ntoO3@_FillValue = -999.0\n\n;-----calculate max ave 8 hour o3-----\noflag=tolat*0+1\naa=ind((oflag.gt.0).and.(toO3.ge.0))\nii=0\nprint(\"8h start\")\nif (any(ismissing(aa))) then\n  iflag=0\nelse\n  iflag=1\n  olat=(/tolat(aa(0))/)\n  olon=(/tolon(aa(0))/)\n  oO3=(/-999.0/)\n  o8O3 = new(17,\"float\")\n  o8O3 = -999.0\nend if\ndelete(aa)\ndo while (iflag.gt.0)\n  aa=ind((tolat.eq.olat(ii)).and.(tolon.eq.olon(ii)).and.(toO3.ge.0))\n  oflag(aa)=0\n  if (dimsizes(aa).eq.24) then  ; calculate 24 h, so calculate 8hr ozone here\n    do ih = 0, 16\n      o8O3(ih) = avg(toO3(aa(ih:ih+7)))\n    end do\n    oO3(ii)=max(o8O3)\n  end if\n  o8O3 = -999.0\n  delete(aa)\n  aa=ind((oflag.gt.0).and.(toO3.ge.0))\n  if (any(ismissing(aa))) then\n    iflag=0\n  else\n    xx=array_append_record(olat,(/tolat(aa(0))/),0)\n    yy=array_append_record(olon,(/tolon(aa(0))/),0)\n    zz=array_append_record(oO3,(/-999.0/),0)\n    delete([/olat,olon,oO3/])\n    olat=xx\n    olon=yy\n    oO3=zz\n    delete([/xx,yy,zz/])\n    ii=ii+1\n  end if\n  delete(aa)\nend do\nprint(\"obs 8hour max end\")\naa=ind(oO3.ge.0)\nnobs=dimsizes(aa)\nolat24=olat(aa)\nolon24=olon(aa)\noO324=oO3(aa)\nprint(\"TYPE of oO324: \"+typeof(oO324))\ndelete([/aa,olat,olon,oO3/])\nmO324=oO324*0-999.0\nprint(\"TYPE of mO324: \"+typeof(mO324))\nprint(\"TYPE of mO31d: \"+typeof(mO31d))\nareaa=oO324*0-999.0\nareab=areaa\naread=areaa\n\n;-----find model point-----\ndo in=0,nobs-1\n  dis=sqrt((mlat1d-olat24(in))^2+(mlon1d-olon24(in))^2)\n  aa=minind(dis)\n ;print(in+\" \"+aa)\n  if (dis(aa).lt.maxdist) then\n    mO324(in)=mO31d(aa)\n    cc=ind((mlat1d.ge.(olat24(in)-maxarea)).and.(mlat1d.le.(olat24(in)+maxarea)).and.\\\n           (mlon1d.ge.(olon24(in)-maxarea)).and.(mlon1d.le.(olon24(in)+maxarea)))\n    areaa(in)=0\n    areab(in)=0\n    if (oO324(in).ge.thd) then\n      aread(in)=0\n      if (max(mO31d(cc)).ge.thd) then\n        areab(in)=1\n      else\n        aread(in)=1\n      end if\n    else\n      bb=ind((olat24.ge.(olat24(in)-maxarea)).and.(olat24.le.(olat24(in)+maxarea)).and.\\\n             (olon24.ge.(olon24(in)-maxarea)).and.(olon24.le.(olon24(in)+maxarea)))\n      if (max(mO31d(aa)).ge.thd) then\n        if (max(oO324(bb)).ge.thd) then\n          areaa(in)=0\n        else\n          areaa(in)=1\n        end if\n      else\n        areaa(in)=0\n      end if\n      delete(bb)\n    end if\n    delete(cc)\n  end if\n  delete(aa)\nend do\n\n;-----cal rmse corr nme nmb me mb-----\ntt=ind((mO324.ge.0).and.(oO324.ge.0))\n\nif (any(ismissing(tt))) then\n  rmse=-999.0\n  corr=-999.0\n  nmb=-999.0\n  nme=-999.0\n  me=-999.0\n  mb=-999.0\nelse\n  rmse=dim_rmsd_n(oO324(tt),mO324(tt),0)\n  corr=esccr(oO324(tt),mO324(tt),0)\n  nmb=sum((mO324(tt)-oO324(tt)))/sum(oO324(tt))\n  nme=sum(abs(oO324(tt)-mO324(tt)))/sum(oO324(tt))\n  me=avg(abs(oO324(tt)-mO324(tt)))\n  mb=avg((mO324(tt)-oO324(tt)))\nend if\n;-----cal ah afar-----\naa=ind((areaa+areab).gt.0)\nbb=ind((aread+areab).gt.0)\nif (any(ismissing(aa))) then\n  afar=0.\nelse\n  afar=tofloat(sum(areaa(aa)))/tofloat(sum(areab(aa))+sum(areaa(aa)))*100\nend if\ndelete(aa)\nif (any(ismissing(bb))) then\n  ah=-999.0\nelse\n  ah=tofloat(sum(areab(bb)))/tofloat(sum(areab(bb))+sum(aread(bb)))*100\nend if\ndelete(bb)\nwrite_table(wfname,\"a\",[/sdate,dimsizes(tt),avg(oO324(tt)),avg(mO324(tt)),rmse,corr,nmb,nme,mb,me,ah,afar/],\\\n            \"%s,%i,%f,%f,%f,%f,%f,%f,%f,%f,%f,%f\")\ndelete(tt)\nend\n\nEOF\n\n\nncl /groups/ESS/aalnaim/cmaq/geoweaver_eva_daily_O3.ncl\n\nif [ $? -eq 0 ]; then\n    echo \"Evaluation Completed Successfully\"\n\techo \"Removing ncl file: geoweaver_eva_daily_O3.ncl...\"\n\trm /groups/ESS/aalnaim/cmaq/geoweaver_eva_daily_O3.ncl\nelse\n    echo \"Evaluation Failed!\"\nfi\n",
  "lang" : "shell",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "is1w3m",
  "name" : "generate_AirNow_ncl",
  "description" : null,
  "code" : "#!/bin/bash\n\n# Setting env variables\nexport YYYYMMDD_POST=20220612 #This needs to be auto date\nexport stdate_post=2022-06-12 #This needs to be auto date\nexport eddate_post=2022-06-13 #This needs to be auto date\n\nexport postdata_dir=\"/groups/ESS/aalnaim/cmaq/prediction_nc_files\"\nexport mcip_dir=\"/groups/ESS/share/projects/SWUS3km/data/cmaqdata/mcip/12km\"\nexport graph_dir=\"/groups/ESS/aalnaim/cmaq/plots\"\n\nexport obs_dir_NCL=\"/groups/ESS/share/projects/SWUS3km/data/OBS/AirNow/AQF5X\"\n\nmodule load ncl\n\ncat <<EOF >>/groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3_Airnow.ncl\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_code.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/gsn_csm.ncl\"\nload \"/opt/sw/spack/apps/linux-centos8-cascadelake/gcc-9.3.0-openmpi-4.0.4/ncl-6.6.2-fr/lib/ncarg/nclscripts/csm/contributed.ncl\"\n\nsetvalues NhlGetWorkspaceObjectId()\n\"wsMaximumSize\": 600000000\nend setvalues\n\nbegin\n\ndate = getenv(\"YYYYMMDD_POST\") \nd1 = getenv(\"stdate_post\") \nd2 = getenv(\"eddate_post\") \n\nobs_dir = getenv(\"obs_dir_NCL\")\nplot_dir = getenv(\"graph_dir\") \n\nhr=new(24,\"string\")\nhr=(/\"00\",\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"/)\n\nprint(plot_dir)\naconc_dir = getenv(\"postdata_dir\") \ngrid_dir = getenv(\"mcip_dir\") \n\ncdf_file1 = addfile(aconc_dir+\"/COMBINE3D_ACONC_v531_gcc_AQF5X_20220612_ML_extracted.nc\",\"r\")\ncdf_file= addfile(grid_dir+\"/GRIDCRO2D_\"+date+\".nc\",\"r\")\ncdf_file2= addfile(grid_dir+\"/METCRO2D_\"+date+\".nc\",\"r\")\n\ntime = cdf_file1->TFLAG(:,0,:)\no3 = cdf_file1->O3(:,:,:) ;ppb\nwspd10=cdf_file2->WSPD10(:,0,:,:)\nwdir10=cdf_file2->WDIR10(:,0,:,:)\n\ntemp = cdf_file2->TEMP2\n\nnt = dimsizes(o3(:,0,0))\nny = dimsizes(o3(0,:,0))\nnx = dimsizes(o3(0,0,:))\n\nprint(max(temp))\nprint(min(temp))\nprint(avg(temp))\n\n\n\nprint(nt+\" \"+ny+\" \"+nx)\nprint(max(o3))\nprint(min(o3))\nprint(avg(o3))\n\nlat = cdf_file->LAT(0,0,:,:)\nlon = cdf_file->LON(0,0,:,:)\n\no3@lat2d = lat\no3@lon2d = lon\no3@unit = \"ppbv\"\n\nUV10=wind_component(wspd10,wdir10,0)\nUV10@lat2d = lat\nUV10@lon2d = lon\n\n\nres = True\nres@gsnMaximize = True                ; maximize pot in frame\nres@gsnFrame = False               ; dont advance frame\nres@gsnDraw = False\nres@gsnLeftString  = \"\"\nres@gsnRightString = \"\"\nres@txFont   = \"times-roman\"\nres@tiMainFont   = \"times-roman\"\n;res@tiMainFontHeightF = 0.02\n;res@vpWidthF        = 0.7\n;res@vpHeightF       = 0.7\n\n;;set map;;\nmpres                             = res\nmpres@mpLimitMode = \"LatLon\"\nmpres@mpDataSetName               = \"Earth..4\"\nmpres@mpDataBaseVersion           = \"MediumRes\"\nmpres@mpOutlineOn                 = True\nmpres@mpGeophysicalLineThicknessF = 1.5\nmpres@mpFillDrawOrder             = \"PostDraw\"\nmpres@mpFillOn                    = False\nmpres@mpAreaMaskingOn         = True\nmpres@mpOutlineBoundarySets = \"GeophysicalAndUSStates\"\nmpres@mpOutlineSpecifiers         = \"United States:States\"\nmpres@mpProjection           = \"LambertConformal\"\nmpres@mpLambertParallel1F    = 33.\nmpres@mpLambertParallel2F    = 45.\nmpres@mpLambertMeridianF     = -98.\nmpres@mpMinLonF = -120 ;min(lon)+0.2\nmpres@mpMaxLonF = -70 ;max(lon)-0.2\nmpres@mpMinLatF = 25 ;min(lat)+0.05\nmpres@mpMaxLatF = 50 ;max(lat)-0.05\nmpres@pmTickMarkDisplayMode   = \"Always\"\nmpres@mpLandFillColor         = \"white\"\nmpres@mpInlandWaterFillColor  = \"white\"\nmpres@mpOceanFillColor        = \"white\"\nmpres@mpGeophysicalLineColor    = \"Black\"\n\n;mpres@lbLabelAutoStride       = True\nmpres@tiXAxisFont             = 25\nmpres@pmTickMarkDisplayMode   = \"Always\"\nmpres@tmXBLabelFont           = 25\nmpres@tmXBLabelFontHeightF    = 0.013\nmpres@tmXBLabelDeltaF         = -0.5\nmpres@tmYLLabelFont           = 25\nmpres@tmYLLabelFontHeightF    = 0.013\nmpres@tmXBLabelDeltaF         = -0.5\nmpres@tmXTLabelsOn            = False\nmpres@tmXTLabelFont           = 25\nmpres@tmXTLabelFontHeightF    = 0.013\nmpres@tmYRLabelsOn            = False\nmpres@tmYRLabelFont           = 25\nmpres@tmYRLabelFontHeightF    = 0.013\n\n;;set contour;;\ncnres                         = res\ncnres@cnFillDrawOrder         = \"PreDraw\"\ncnres@cnFillOn                = True\ncnres@cnLinesOn               = False\ncnres@cnLineLabelsOn          = False\ncnres@lbLabelFont             = 25\ncnres@lbLabelFontHeightF      = 0.013\ncnres@tiXAxisFont             = 25\ncnres@pmLabelBarWidthF        = 0.5\ncnres@pmLabelBarHeightF       = 0.1\n;cnres@pmLabelBarOrthogonalPosF = -0.02\ncnres@lbLabelAutoStride       = True\n\n;set vector;;\nres_vc                        = res\nres_vc@vcGlyphStyle           = \"LineArrow\"\nres_vc@vcLineArrowThicknessF  = 3\nres_vc@vcMinDistanceF         = 0.03\nres_vc@vcRefLengthF           = 0.03\nres_vc@vcRefAnnoOn            = True\nres_vc@vcRefMagnitudeF           = 16\nres_vc@vcRefAnnoString1          = \"16m/s\"\nres_vc@vcRefAnnoSide             = \"Top\"\nres_vc@vcRefAnnoString2On        = False\nres_vc@vcRefAnnoPerimOn          = False\nres_vc@vcRefAnnoOrthogonalPosF   = -0.02\nres_vc@vcRefAnnoParallelPosF     = 0.999\n;res_vc@vcRefAnnoBackgroundColor = \"White\"\nres_vc@vcVectorDrawOrder         = \"PostDraw\"\n\ndo it = 0, nt-1\n  if (it .lt. 12) then\n    pdate=d1\n  else\n    pdate=d2\n  end if\n\n  ;print(time(it,0)+\" \"+time(it,1))\n  rundate = yyyyddd_to_yyyymmdd( time(it,0) )\n  runtime = hr( tointeger(time(it,1)/10000) )\n\n  site = readAsciiTable(obs_dir+\"/AQF5X_Hourly_\"+rundate+runtime+\".dat\",1,\"string\",1)\n  nrows = dimsizes(site)\n  sitename = str_get_field(site,1,\",\")\n  sitelat = stringtofloat(str_get_field(site,2,\",\"))\n  sitelon = stringtofloat(str_get_field(site,3,\",\"))\n  O3_obs = stringtofloat(str_get_field(site,4,\",\"))\n\n  obslon = sitelon(:,0)\n  obslat = sitelat(:,0)\n  obsO3 = O3_obs(:,0)\n\n  npts = nrows(0)\n\n  obsO3@_FillValue = -999.\n\n;--- levels for dividing\n  levels_O3  = ispan(0,80,4)\n\n  nlevels = dimsizes(levels_O3)\n\n  colors  = span_color_rgba(\"WhiteBlueGreenYellowRed\",nlevels+1)\n\n  num_distinct_markers = nlevels+1        ; number of distinct markers\n  lat_O3 = new((/num_distinct_markers,npts/),float)\n  lon_O3 = new((/num_distinct_markers,npts/),float)\n  lat_O3 = -999\n  lon_O3 = -999\n\n\n;\n; Group the points according to which range they fall in. At the\n; same time, create the label that we will use later in the labelbar\n;\n  do i = 0, num_distinct_markers-1\n    if (i.eq.0) then\n      indexes_O3 = ind(obsO3(:).lt.levels_O3(0))\n    end if\n    if (i.eq.num_distinct_markers-1) then\n      indexes_O3 = ind(obsO3(:).ge.max(levels_O3))\n    end if\n    if (i.gt.0.and.i.lt.num_distinct_markers-1) then\n      indexes_O3 = ind(obsO3(:).ge.levels_O3(i-1).and.obsO3(:).lt.levels_O3(i))\n    end if\n\n;\n; Now that we have the set of indexes whose values fall within\n; the given range, take the corresponding lat/lon values and store\n; them, so later we can color this set of markers with the appropriate\n; color.\n;\n    if (.not.any(ismissing(indexes_O3))) then\n      npts_range_O3 = dimsizes(indexes_O3)   ; # of points in this range.\n\n      lat_O3(i,0:npts_range_O3-1) = obslat(indexes_O3)\n      lon_O3(i,0:npts_range_O3-1) = obslon(indexes_O3)\n  ;print(\"O3: \"+npts_range_O3)\n    end if\n\n\n    delete(indexes_O3)            ; Necessary b/c \"indexes\" may be a different\n  end do\n\n  lat_O3@_FillValue = -999\n  lon_O3@_FillValue = -999\n\n  gsres               = True\n  gsres@gsMarkerIndex = 16          ; Use filled dots for markers.\n\n  hollowres           = True\n  hollowres@gsMarkerIndex    = 4\n  hollowres@gsMarkerColor    = \"black\"\n  hollowres@gsMarkerSizeF    = 0.008\n\n;;;;;;;;;   Plot Ozone\n  pname=plot_dir+\"/OBS-FORECAST_O3_\"+rundate+runtime\n  wks = gsn_open_wks(\"png\",pname)\n  gsn_define_colormap(wks, \"WhiteBlueGreenYellowRed\")\n\n  pmid_O3 = new(num_distinct_markers,graphic)\n  hollow_O3 = new(num_distinct_markers,graphic)\n\n  cnres@tiMainString =  pdate+\" \"+runtime+\" UTC O~B~3~N~ (ppbV)\"\n  cnres@cnLevelSelectionMode = \"ManualLevels\"\n  cnres@cnMinLevelValF          = 0.\n  cnres@cnMaxLevelValF          = 80\n  cnres@cnLevelSpacingF         = 4\n\n  ;plot = gsn_csm_contour_map(wks,o3(it,:,:),res)\n  map = gsn_csm_map(wks,mpres)\n  contour = gsn_csm_contour(wks,o3(it,:,:),cnres)\n  vector  = gsn_csm_vector(wks,UV10(0,it,:,:),UV10(1,it,:,:),res_vc)\n  overlay(map,contour)\n  overlay(map,vector)\n\n  pmid = new(num_distinct_markers,graphic)\n  hollow = new(num_distinct_markers,graphic)\n  do i = 0, num_distinct_markers-1\n    if (.not.ismissing(lat_O3(i,0)))\n      gsres@gsMarkerColor      = colors(i,:)\n      gsres@gsMarkerSizeF      = 0.008\n      gsres@gsMarkerThicknessF = 1\n       pmid(i) = gsn_add_polymarker(wks,vector,lon_O3(i,:),lat_O3(i,:),gsres)\n       hollow(i) = gsn_add_polymarker(wks,vector,lon_O3(i,:),lat_O3(i,:),hollowres)\n    end if\n  end do\n\n  draw(map)\n  frame(wks)\n  delete(wks)\n  delete(pmid_O3)\n  delete(hollow_O3)\n  system(\"composite -geometry 100x70+900+900 /groups/ESS/aalnaim/cmaq/mason-logo-green.png \"+pname+\".png \"+pname+\".png\")\n\n\n  delete(pmid)\n  delete(hollow)\n  delete(site)\n  delete(sitename)\n  delete(sitelat)\n  delete(sitelon)\n  delete(O3_obs)\n  delete(obslon)\n  delete(obslat)\n  delete(obsO3)\n  delete([/lon_O3,lat_O3/])\n\nend do\ndelete(res)\n\n;/\n\nend\nEOF\n\n\nncl /groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3_Airnow.ncl\n\nconvert -delay 100 /groups/ESS/aalnaim/cmaq/plots/OBS*.png /groups/ESS/aalnaim/cmaq/plots/Airnow_$YYYYMMDD_POST_correct.gif\n\nif [ $? -eq 0 ]; then\n    echo \"Generating AirNow images/gif Completed Successfully\"\n\techo \"Removing ncl file: geoweaver_plot_daily_O3_Airnow.ncl...\"\n\trm /groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3_Airnow.ncl\nelse\n    echo \"Generating AirNow images/gif Failed!\"\n    echo \"Removing ncl file: geoweaver_plot_daily_O3_Airnow.ncl...\"\n\trm /groups/ESS/aalnaim/cmaq/geoweaver_plot_daily_O3_Airnow.ncl\nfi\n",
  "lang" : "shell",
  "owner" : "111111",
  "confidential" : "FALSE"
}]
