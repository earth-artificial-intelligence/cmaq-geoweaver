[{
  "id" : "im9rct",
  "name" : "preprocess",
  "description" : null,
  "code" : "# Write first python in Geoweaver\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Required packages to run this process.\nrequired = {'pandas','pathlib'}\ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\nif missing:\n    print(\"Packages missing and will be installed: \", missing)\n    python = sys.executable\n    subprocess.check_call(\n        [python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n\n################################\n#  END OF PACKAGES VALIDATION  #\n################################\n\n## importing necessary libraries\n\nimport pandas as pd\nimport datetime\nimport os\nfrom pathlib import Path\nhome = str(Path.home())\n\n# defining function for shifting data\nmonth_i=[1,2,3,4,5,6,7,8,9,10,11,12]\ndef shift(file):\n    station=file['Station.ID'].unique()\n    file['date']=pd.to_datetime(file[[\"year\", \"month\", \"day\",\"hours\"]]) # creating date\n    file['dayofyear'] = pd.to_datetime(file['date']).dt.dayofyear # converting monthly days to yearly dasy\n    dfs = dict(tuple(file.groupby('Station.ID'))) # grouping the data by station\n#    print(dfs)\n    list_final=[]\n    for site in station:\n        list1=dfs[site]  # selecting dataset for each station\n        o3_max=list1.loc[list1.groupby(\"dayofyear\")[\"AirNOW_O3\"].idxmax()] # daily max values\n        o3_month=pd.DataFrame(o3_max.groupby('month',as_index=False)['hours'].mean()) # monthly average hour\n        no2_max=list1.loc[list1.groupby(\"dayofyear\")[\"CMAQ12KM_NO2\"].idxmax()] # daily amx values\n        no2_month=pd.DataFrame(no2_max.groupby('month',as_index=False)['hours'].mean()) # montly average hour\n        merge_hour=pd.concat([o3_month,no2_month],axis = 1) # merging two table\n        merge_hour.columns = ['month1','hours1', 'month2','hours2'] # renaming column name\n        merge_hour['hours_diff']=merge_hour['hours1']-merge_hour['hours2']\n        merge_hour.hours_diff = merge_hour.hours_diff.astype(int) # converting hours_diff to int\n        months = dict(tuple(list1.groupby('month')))   # grouping the data by month\n        diff=merge_hour['hours_diff'] # extracting hours difference field\n        mon=merge_hour['month1'] # extracting month field\n\n        for (m,n) in zip(mon,diff):\n            list2= months[m] # selecting dataset for each month and for each station\n            list3=list2.loc[list2['month'] == m] # subsetting dataset for each month\n            list3['CMAQ12KM_NO2_new'] = list3['CMAQ12KM_NO2'].shift(n) # shifting rows for each month\n            list_final.append(list3)\n    return list_final\n\n\n  \n# Importing and merging 2020 and 2021 dataset\ndf1 = pd.read_csv(f'{home}/Geoweaver/full_20_lstm.csv')\ndf2 = pd.read_csv(f'{home}/Geoweaver/full_21_lstm.csv')\n#merging two dataframe vertically\nmrg=df1.append(df2, ignore_index=True)\ndf3_rs=pd.read_csv(f'{home}/Geoweaver/merged_rs.csv')\n# merging\nfinal=pd.merge(mrg,df3_rs, on=['year', 'month','day','hours','Station.ID'])\n\n#shifting CMAQ NO2\nshift_df=shift(final)\ndata_frame = pd.concat(shift_df) # concatening the list\n\n# droping no data from all column and AirNOW_O3\ndata_new1 = data_frame.drop(['Unnamed: 0'],axis=1)\ndata_new=data_new1.dropna() \nfinal_df = data_new[data_new.AirNOW_O3!= -999]\nfinal_df.to_csv(f'{home}/Geoweaver/merged_2020_2021.csv')",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "106i1i",
  "name" : "XGBoost",
  "description" : null,
  "code" : "# Write first python in Geoweaver\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Required packages to run this process.\nrequired = {'pandas','sklearn','xgboost','numpy','matplotlib','pathlib'}\ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\nif missing:\n    print(\"Packages missing and will be installed: \", missing)\n    python = sys.executable\n    subprocess.check_call(\n        [python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n\n################################\n#  END OF PACKAGES VALIDATION  #\n# Importing data\nimport os\nfrom pathlib import Path\nimport pandas as pd\nhome = str(Path.home())\nfinal=pd.read_csv(f'{home}/Geoweaver/merged_2020_2021.csv')\n\n# defining training and testing variables\ntrain=final.loc[final['year']==2020]\ntest=final.loc[final['year']==2021]\n\n# processing training  data\nX = train.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear','datetime'],axis=1)\ny = train['AirNOW_O3']\nX.head()\n\n# processing test data\ntest_X = test.drop(['AirNOW_O3','Station.ID','YYYYMMDDHH','year','date','dayofyear','datetime'],axis=1)\ntest_y = test['AirNOW_O3']\ntest_X.head()\n\n\n## Voting XGBoost\nimport sklearn\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom matplotlib import pyplot\nfrom xgboost.sklearn import XGBRegressor\n\n\n# define the base models\nmodels = list()\nmodels.append(('cart1', XGBRegressor(max_depth=1)))\nmodels.append(('cart2', XGBRegressor(max_depth=2)))\nmodels.append(('cart3', XGBRegressor(max_depth=3)))\nmodels.append(('cart4', XGBRegressor(max_depth=4)))\nmodels.append(('cart5', XGBRegressor(max_depth=5)))\nmodels.append(('cart6', XGBRegressor(max_depth=6)))\n# define the voting ensemble\nensemble = VotingRegressor(estimators=models)\n# fit the model on all available data\nensemble.fit(X, y)\n\n# prediction\npred = ensemble.predict(test_X)\n# adding prediction values to test dataset\ntest['prediction'] = pred.tolist()\n\ntest.to_csv(f'{home}/Geoweaver/prediction_xgboost.csv')",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "jciipj",
  "name" : "AutoML",
  "description" : null,
  "code" : "# Write first python in Geoweaver\n\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Required packages to run this process.\nrequired = {'pandas','sklearn','h2o','numpy','matplotlib','pathlib'}\ninstalled = {pkg.key for pkg in pkg_resources.working_set}\nmissing = required - installed\n\nif missing:\n    print(\"Packages missing and will be installed: \", missing)\n    python = sys.executable\n    subprocess.check_call(\n        [python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n\n################################\n#  END OF PACKAGES VALIDATION  #\n# Importing data\nimport os\nfrom pathlib import Path\nimport pandas as pd\nhome = str(Path.home())\nfinal=pd.read_csv(f'{home}/Geoweaver/merged_2020_2021.csv')\n\n# defining training and testing variables\ntrain=final.loc[final['year']==2020]\ntest=final.loc[final['year']==2021]\n\n# processing training  data\ntrain = train.drop(['Station.ID','YYYYMMDDHH','year','date','dayofyear','CMAQ12KM_NO2'],axis=1)\ntest = test.drop(['Station.ID','YYYYMMDDHH','year','date','dayofyear','CMAQ12KM_NO2'],axis=1)\n\n## AutoML\nimport h2o\nfrom h2o.automl import H2OAutoML\n# Start the H2O cluster (locally)\nh2o.init()\n\n# Converting training and test data into h2o data format\ntrain = h2o.H2OFrame(train)\ntest = h2o.H2OFrame(test)\n\n# Identify predictors and response in training data\nx = train.columns\ny = \"AirNOW_O3\"\nx.remove(y)\n\n# Identify predictors and response in test data\n\ntest_x = test.columns\ntest_y = \"AirNOW_O3\"\ntest_x.remove(test_y)\n\n# Run AutoML for 20 base models\naml = H2OAutoML(max_models=2, seed=1)\naml.train(x=x, y=y, training_frame=train)\n\n# Make prediction\npreds = aml.leader.predict(test)\nprd_=preds['predict']\n\n# transforming back to pandas data frame\ndat = h2o.as_list(prd_)\norg = h2o.as_list(test)\n\n# Merging the prediction with test dataset\nprediction = pd.concat([org, dat], axis=1)\nprediction.to_csv(f'{home}/Geoweaver/prediction_autoML.csv')",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
}]
